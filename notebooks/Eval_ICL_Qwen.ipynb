{"cells":[{"cell_type":"markdown","metadata":{"id":"r9BCDB6BTV-d"},"source":["# ICL Evaluation for Code Generation (Qwen Only)\n","\n","Model: `Qwen/Qwen2.5-Coder-3B-Instruct`  \n","This notebook runs:\n","\n","- **Phase 1**: Prompt selection on **MBPP** (first 100 problems)\n","- **Phase 2 (template)**: Final evaluation on HumanEval using the best-shot prompt\n","\n","All prompts are designed to avoid Markdown code blocks so that code can be executed directly."],"id":"r9BCDB6BTV-d"},{"cell_type":"code","source":["%pip install transformers accelerate datasets tqdm sentencepiece human-eval evalplus --upgrade -q"],"metadata":{"id":"j0MftK_e_HhT"},"id":"j0MftK_e_HhT","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bzcep1vmTV-f","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1926ccac-2e6f-44cf-f4be-682784cdfbfb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'bigcode-evaluation-harness' already exists and is not an empty directory.\n"]}],"source":["!git clone https://github.com/arthur900530/bigcode-evaluation-harness.git"],"id":"Bzcep1vmTV-f"},{"cell_type":"code","source":["%cd bigcode-evaluation-harness\n","!pip install -e . --quiet\n","!pip install -q bitsandbytes>=0.41.0 --quiet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6_gutU9gyJSF","outputId":"6551a5b8-2025-4705-9b62-7e4ae68f456c"},"id":"6_gutU9gyJSF","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/bigcode-evaluation-harness\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["import os, re, json, math, textwrap, traceback\n","import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","from datasets import load_dataset\n","from human_eval.data import read_problems\n","\n","# Ensure math.comb is available (Python 3.8+)\n","if not hasattr(math, 'comb'):\n","    def comb(n, k):\n","        if k > n or k < 0:\n","            return 0\n","        if k == 0 or k == n:\n","            return 1\n","        k = min(k, n - k)\n","        result = 1\n","        for i in range(k):\n","            result = result * (n - i) // (i + 1)\n","        return result\n","    math.comb = comb\n","\n","MBPP_LIMIT = 100   # number of MBPP problems for Phase 1\n","SEED = 11667\n","\n","print(\"‚úÖ Config:\")\n","print(f\"  MBPP_LIMIT = {MBPP_LIMIT}\")\n","print(f\"  SEED       = {SEED}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-9HJbGN3rDzF","outputId":"574aedab-53c5-4b56-b0a8-f03f30b0718a"},"id":"-9HJbGN3rDzF","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Config:\n","  MBPP_LIMIT = 100\n","  SEED       = 11667\n"]}]},{"cell_type":"code","source":["!python main.py \\\n","  --model \"Qwen/Qwen2.5-Coder-3B-Instruct\" \\\n","  --tasks \"mbpp\" \\\n","  --top_p 0.95 \\\n","  --temperature 0.2 \\\n","  --do_sample True \\\n","  --n_samples 10 \\\n","  --batch_size 10 \\\n","  --max_length 2048 \\\n","  --max_length_generation 2048 \\\n","  --allow_code_execution \\\n","  --save_generations \\\n","  --limit 100 \\\n","  --prefix \"$PREFIX_5_SHOT\""],"metadata":{"id":"GGcMa8NPyeqE"},"id":"GGcMa8NPyeqE","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python main.py \\\n","  --model \"Qwen/Qwen2.5-Coder-3B-Instruct\" \\\n","  --tasks \"humanevalplus\" \\\n","  --top_p 0.95 \\\n","  --temperature 0.2 \\\n","  --do_sample True \\\n","  --n_samples 10 \\\n","  --batch_size 10 \\\n","  --max_length 2048 \\\n","  --max_length_generation 2048 \\\n","  --allow_code_execution \\\n","  --save_generations \\\n","  --prefix \"$PREFIX_5_SHOT\""],"metadata":{"id":"B1FmWUMH3VlA"},"id":"B1FmWUMH3VlA","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python main.py \\\n","  --model \"Qwen/Qwen2.5-Coder-3B-Instruct\" \\\n","  --tasks \"humanevalplus\" \\\n","  --top_p 0.95 \\\n","  --temperature 0.2 \\\n","  --do_sample True \\\n","  --n_samples 10 \\\n","  --batch_size 10 \\\n","  --max_length 2048 \\\n","  --max_length_generation 2048 \\\n","  --allow_code_execution \\\n","  --save_generations\n"],"metadata":{"id":"HcWB9B3K68t1"},"id":"HcWB9B3K68t1","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !huggingface-cli login\n","from huggingface_hub import notebook_login\n","notebook_login()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17,"referenced_widgets":["c28285cc178e4878a9a0d7ae7eaa314f","326f6c1e87cc4158a1d931ab1176e55f","f4b8934da18249589cf24375d977ba58","8aac99036e1641c8892698cf5ca31e04","4cd44205ab18476b9a56bf5b76eccb67","dd4c8f0baef0417f9bccb0c1d2058518","cc3ebbdccf874a4ab76fc4d3339ea9eb","978cbcb38a0b472abede6196826bbe9c","f2bd3861f5ae49efaf13eeebd3dbc322","70366e9028c14542a3bb552ccde8a68f","469dcf5abce44982bbf9328b0b87a600","535297623d154634838035d5853752e6","f4585c6c28a041fea79036dfcbb2ba9d","431401bb96a64938b269bdbdb186e0ee","4544a010807e45e78464ac892150a50d","8d427289c817446aa4eab7d548bd7725","cf1e4a40df344a03ad6345b735828ff3","26a62b3b6a0047b3a173dfd75e185c9b","ef6f5919177c426ebc70513179eeece6","63d82ecf96694c77bacb8bff1cac9dac"]},"id":"ZBF-JltCxkVf","outputId":"b5136ad4-868e-41e1-b80d-ac734752b3bb"},"id":"ZBF-JltCxkVf","execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c28285cc178e4878a9a0d7ae7eaa314f"}},"metadata":{}}]},{"cell_type":"code","source":["%%bash\n","PREFIX=\"$(cat prompts/mbpp_5shot.txt)\"\n","python main.py \\\n","  --model \"Qwen/Qwen2.5-Coder-3B-Instruct\" \\\n","  --tasks \"humanevalplus\" \\\n","  --top_p 0.95 \\\n","  --temperature 0.2 \\\n","  --do_sample True \\\n","  --n_samples 10 \\\n","  --batch_size 10 \\\n","  --max_length 2048 \\\n","  --max_length_generation 2048 \\\n","  --allow_code_execution \\\n","  --save_generations"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JxYMWm_fw_Yg","outputId":"2cfb6f47-e720-435c-bb63-a319b261c5c1"},"id":"JxYMWm_fw_Yg","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Process is terminated.\n"]}]},{"cell_type":"code","source":["%%bash\n","cat prompts/mbpp_5shot.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-2CJYM9Oy4Sv","outputId":"35ea5245-48d9-4458-d499-bd9e998f395f"},"id":"-2CJYM9Oy4Sv","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["def factorial(n):\n","    if n == 0 or n == 1:\n","        return 1\n","    return n * factorial(n - 1)\n","\n","def is_palindrome(s):\n","    s = s.lower().replace(\" \", \"\")\n","    return s == s[::-1]\n","\n","def fibonacci(n):\n","    if n <= 0:\n","        return []\n","    elif n == 1:\n","        return [0]\n","    elif n == 2:\n","        return [0, 1]\n","    seq = [0, 1]\n","    for i in range(2, n):\n","        seq.append(seq[-1] + seq[-2])\n","    return seq\n","\n","def find_max(lst):\n","    if not lst:\n","        return None\n","    m = lst[0]\n","    for x in lst[1:]:\n","        if x > m:\n","            m = x\n","    return m\n","\n","def reverse_list(lst):\n","    i, j = 0, len(lst) - 1\n","    while i < j:\n","        lst[i], lst[j] = lst[j], lst[i]\n","        i += 1\n","        j -= 1\n","    return lst\n","\n","# You are a Python coding assistant.\n","# Only output valid Python code implementing the required function.\n","# Do NOT use markdown or ```.\n","# Do NOT print explanations or comments outside the function body.\n","\n"]}]},{"cell_type":"code","source":["HARD_RULE = (\n","    \"# You are a Python coding assistant.\\n\"\n","    \"# Only output valid Python code implementing the required function.\\n\"\n","    \"# Do NOT use markdown or ```.\\n\"\n","    \"# Do NOT print explanations or comments outside the function body.\\n\\n\"\n",")\n","\n","CODE_EXAMPLE_1 = \"\"\"def factorial(n):\n","    if n == 0 or n == 1:\n","        return 1\n","    return n * factorial(n - 1)\n","\n","\"\"\"\n","\n","CODE_EXAMPLE_2 = \"\"\"def is_palindrome(s):\n","    s = s.lower().replace(\" \", \"\")\n","    return s == s[::-1]\n","\n","\"\"\"\n","\n","CODE_EXAMPLE_3 = \"\"\"def fibonacci(n):\n","    if n <= 0:\n","        return []\n","    elif n == 1:\n","        return [0]\n","    elif n == 2:\n","        return [0, 1]\n","    seq = [0, 1]\n","    for i in range(2, n):\n","        seq.append(seq[-1] + seq[-2])\n","    return seq\n","\n","\"\"\"\n","\n","CODE_EXAMPLE_4 = \"\"\"def find_max(lst):\n","    if not lst:\n","        return None\n","    m = lst[0]\n","    for x in lst[1:]:\n","        if x > m:\n","            m = x\n","    return m\n","\n","\"\"\"\n","\n","CODE_EXAMPLE_5 = \"\"\"def reverse_list(lst):\n","    i, j = 0, len(lst) - 1\n","    while i < j:\n","        lst[i], lst[j] = lst[j], lst[i]\n","        i += 1\n","        j -= 1\n","    return lst\n","\n","\"\"\"\n","\n","PREFIX_5_SHOT = \"\".join([\n","    CODE_EXAMPLE_1,\n","    CODE_EXAMPLE_2,\n","    CODE_EXAMPLE_3,\n","    CODE_EXAMPLE_4,\n","    CODE_EXAMPLE_5,\n","    HARD_RULE,\n","])"],"metadata":{"id":"0_VckdIxzChg"},"id":"0_VckdIxzChg","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","os.makedirs(\"prompts\", exist_ok=True)\n","\n","with open(\"prompts/mbpp_5shot.txt\", \"w\") as f:\n","    f.write(PREFIX_5_SHOT)"],"metadata":{"id":"siRS0Fjbwg0s"},"id":"siRS0Fjbwg0s","execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%bash\n","PREFIX=\"$(cat prompts/mbpp_5shot.txt)\"\n","python main.py \\\n","  --model \"Qwen/Qwen2.5-Coder-3B-Instruct\" \\\n","  --tasks \"mbpp\" \\\n","  --top_p 0.95 \\\n","  --temperature 0.2 \\\n","  --do_sample True \\\n","  --n_samples 10 \\\n","  --batch_size 10 \\\n","  --max_length 2048 \\\n","  --max_length_generation 2048 \\\n","  --allow_code_execution \\\n","  --save_generations \\\n","  --limit 100 \\\n","  --prefix \"$PREFIX\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hk3Uf1W6w5Wl","outputId":"e0c053ae-ffa1-4347-a843-f316e35f7cde"},"id":"Hk3Uf1W6w5Wl","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Process is terminated.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hS-aQ-dsTV-g","outputId":"98918d56-701e-4c4d-b793-155862898afb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Config:\n","  MBPP_LIMIT = 100\n","  SEED       = 11667\n"]}],"source":["import os, re, json, math, textwrap, traceback\n","import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","from datasets import load_dataset\n","from human_eval.data import read_problems\n","\n","MBPP_LIMIT = 100   # number of MBPP problems for Phase 1\n","SEED = 11667\n","\n","print(\"‚úÖ Config:\")\n","print(f\"  MBPP_LIMIT = {MBPP_LIMIT}\")\n","print(f\"  SEED       = {SEED}\")"],"id":"hS-aQ-dsTV-g"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219,"referenced_widgets":["71b303e81d334239b0336a55c393e4b9","502dbb13f2d64f58bc4a561be77155cc","04941351275b4c75b4e5425db2e4bf02","46cc4d9a431547c4904e13814d66145d","6065731d361348279ec4b06fb0367151","a70e68e786c54ba88af3a9bc7ba54169","2e22589ba6c64c71a42a85078aabc8fd","5b0d6b9ee537454a8e1b9e95a00dfb7b","c093ac5fc63d4c418e2552c657dc6014","ca407868df004d2d80e48e34a8d6066a","a4db0b1c7def437e9bff8e2c97d7e78b"]},"id":"I8sZd0F0TV-g","outputId":"95efae75-b03a-40c0-9027-6676e84ec4d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading model: Qwen/Qwen2.5-Coder-3B-Instruct\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71b303e81d334239b0336a55c393e4b9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["‚úÖ Model loaded and set to eval()\n"]}],"source":["model_name = \"Qwen/Qwen2.5-Coder-3B-Instruct\"\n","print(f\"Loading model: {model_name}\")\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    dtype=torch.float16,\n","    device_map=\"auto\",\n","    trust_remote_code=True\n",")\n","\n","model.eval()\n","print(\"‚úÖ Model loaded and set to eval()\")"],"id":"I8sZd0F0TV-g"},{"cell_type":"markdown","metadata":{"id":"K97oCL2mTV-g"},"source":["## Few-shot examples (pure Python code, no Markdown)"],"id":"K97oCL2mTV-g"},{"cell_type":"code","metadata":{"id":"5yVAxRurTV-g","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a190d447-137a-417a-a68f-3b95be6a8afc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Defined 5 pure-code few-shot examples\n"]}],"source":["# Pure code examples ‚Äì these look like functions from a Python file\n","\n","CODE_EXAMPLE_1 = \"\"\"def factorial(n):\n","    if n == 0 or n == 1:\n","        return 1\n","    return n * factorial(n - 1)\n","\n","\"\"\"\n","\n","CODE_EXAMPLE_2 = \"\"\"def is_palindrome(s):\n","    s = s.lower().replace(\" \", \"\")\n","    return s == s[::-1]\n","\n","\"\"\"\n","\n","CODE_EXAMPLE_3 = \"\"\"def fibonacci(n):\n","    if n <= 0:\n","        return []\n","    elif n == 1:\n","        return [0]\n","    elif n == 2:\n","        return [0, 1]\n","    fib = [0, 1]\n","    for i in range(2, n):\n","        fib.append(fib[i-1] + fib[i-2])\n","    return fib\n","\n","\"\"\"\n","\n","CODE_EXAMPLE_4 = \"\"\"def find_max(lst):\n","    if not lst:\n","        return None\n","    max_val = lst[0]\n","    for num in lst[1:]:\n","        if num > max_val:\n","            max_val = num\n","    return max_val\n","\n","\"\"\"\n","\n","CODE_EXAMPLE_5 = \"\"\"def reverse_list(lst):\n","    left, right = 0, len(lst) - 1\n","    while left < right:\n","        lst[left], lst[right] = lst[right], lst[left]\n","        left += 1\n","        right -= 1\n","    return lst\n","\n","\"\"\"\n","\n","ALL_CODE_EXAMPLES = [\n","    CODE_EXAMPLE_1,\n","    CODE_EXAMPLE_2,\n","    CODE_EXAMPLE_3,\n","    CODE_EXAMPLE_4,\n","    CODE_EXAMPLE_5,\n","]\n","\n","print(\"‚úÖ Defined 5 pure-code few-shot examples\")"],"id":"5yVAxRurTV-g"},{"cell_type":"markdown","metadata":{"id":"f2N3al_gTV-h"},"source":["## Prompt builder (shots: baseline / 0 / 1 / 3 / 5)"],"id":"f2N3al_gTV-h"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JspMltXLTV-h","outputId":"731c50b9-cba3-4510-fe46-9ef3fe2454be"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ MAIN_PROMPTS re-defined with:\n","  baseline: Baseline (task + signature)\n","  0shot: 0-shot (instruction + task + signature)\n","  1shot: 1-shot (code prefix + task + signature)\n","  3shot: 3-shot (code prefix + task + signature)\n","  5shot: 5-shot (code prefix + task + signature)\n"]}],"source":["# ========= Prompt config for MBPP + Qwen =========\n","\n","HARD_RULE = (\n","    \"# You are a Python coding assistant.\\n\"\n","    \"# Only output valid Python code implementing the required function.\\n\"\n","    \"# Do NOT use markdown or ```.\\n\"\n","    \"# Do NOT print explanations or comments outside the function body.\\n\\n\"\n",")\n","\n","def build_task_text_mbpp(entry):\n","    \"\"\"MBPP Ëá™Â∏¶ÁöÑËá™ÁÑ∂ËØ≠Ë®ÄÊèèËø∞\"\"\"\n","    return entry[\"text\"].strip()\n","\n","def get_signature(entry):\n","    \"\"\"\n","    ‰ªé MBPP ÁöÑÂèÇËÄÉËß£ÈáåÊäΩÂá∫ÂáΩÊï∞Á≠æÂêçÔºàÁ¨¨‰∏ÄË°åÔºâ\n","    e.g. 'def remove_first_and_last(s, ch):'\n","    \"\"\"\n","    first_line = entry[\"code\"].strip().split(\"\\n\")[0]\n","    sig = first_line.strip().rstrip(\":\") + \":\"\n","    return sig + \"\\n\"\n","\n","def build_core_prompt(task_text: str, entry) -> str:\n","    \"\"\"\n","    ÈÄöÁî®Ê†∏ÂøÉÁªìÊûÑÔºö\n","    - È°∂ÈÉ®ÊòØËßÑÂàôÔºàHARD_RULEÔºâ\n","    - ÁÑ∂ÂêéÊòØ # Task: <Ëá™ÁÑ∂ËØ≠Ë®ÄÊèèËø∞>\n","    - ÁÑ∂ÂêéÊòØ ÂáΩÊï∞Á≠æÂêçÔºàÁ©∫ body Á≠âÊ®°ÂûãË°•ÂÖ®Ôºâ\n","    \"\"\"\n","    one_line_task = task_text.replace(\"\\n\", \" \")\n","    sig = get_signature(entry)\n","    core = (\n","        HARD_RULE +\n","        f\"# Task: {one_line_task}\\n\"\n","        f\"# Implement the following function to solve the task.\\n\\n\"\n","        f\"{sig}\"\n","    )\n","    return core\n","\n","# ---- few-shot ‰ª£Á†ÅÁ§∫‰æãÔºàÁ∫Ø codeÔºå‰∏çË¶Å markdown / Êåá‰ª§Ôºâ----\n","\n","# ‰Ω†‰πãÂâçÂ∑≤ÁªèÂÆö‰πâËøáÁ±ª‰ººÁöÑ CODE_EXAMPLE_1/2/3/4/5ÔºåËøôÈáåÁ°ÆËÆ§‰∏ãÊòØÁ∫ØÂáΩÊï∞Ôºö\n","CODE_EXAMPLE_1 = \"\"\"def factorial(n):\n","    if n == 0 or n == 1:\n","        return 1\n","    return n * factorial(n - 1)\n","\n","\"\"\"\n","\n","CODE_EXAMPLE_2 = \"\"\"def is_palindrome(s):\n","    s = s.lower().replace(\" \", \"\")\n","    return s == s[::-1]\n","\n","\"\"\"\n","\n","CODE_EXAMPLE_3 = \"\"\"def fibonacci(n):\n","    if n <= 0:\n","        return []\n","    elif n == 1:\n","        return [0]\n","    elif n == 2:\n","        return [0, 1]\n","    seq = [0, 1]\n","    for i in range(2, n):\n","        seq.append(seq[-1] + seq[-2])\n","    return seq\n","\n","\"\"\"\n","\n","CODE_EXAMPLE_4 = \"\"\"def find_max(lst):\n","    if not lst:\n","        return None\n","    m = lst[0]\n","    for x in lst[1:]:\n","        if x > m:\n","            m = x\n","    return m\n","\n","\"\"\"\n","\n","CODE_EXAMPLE_5 = \"\"\"def reverse_list(lst):\n","    i, j = 0, len(lst) - 1\n","    while i < j:\n","        lst[i], lst[j] = lst[j], lst[i]\n","        i += 1\n","        j -= 1\n","    return lst\n","\n","\"\"\"\n","\n","ALL_CODE_EXAMPLES = [\n","    CODE_EXAMPLE_1,\n","    CODE_EXAMPLE_2,\n","    CODE_EXAMPLE_3,\n","    CODE_EXAMPLE_4,\n","    CODE_EXAMPLE_5,\n","]\n","\n","# ---- ‰∏çÂêå shot ÁöÑ prompt ÊûÑÈÄ† ----\n","\n","def prompt_baseline(task_text: str, entry) -> str:\n","    # Ê≤°Êúâ few-shotÔºåÂè™Áî® task + signature\n","    return build_core_prompt(task_text, entry)\n","\n","def prompt_0shot(task_text: str, entry) -> str:\n","    # Âêå baselineÔºåÂè™ÊòØÈ¢ùÂ§ñÂä†‰∏ÄÂè•‚ÄúComplete the function‚ÄùÊèêÁ§∫\n","    core = build_core_prompt(task_text, entry)\n","    return \"# Complete the function below.\\n\\n\" + core\n","\n","def prompt_1shot(task_text: str, entry) -> str:\n","    prefix = CODE_EXAMPLE_1\n","    core = build_core_prompt(task_text, entry)\n","    return prefix + \"\\n\" + core\n","\n","def prompt_3shot(task_text: str, entry) -> str:\n","    prefix = CODE_EXAMPLE_1 + CODE_EXAMPLE_2 + CODE_EXAMPLE_3\n","    core = build_core_prompt(task_text, entry)\n","    return prefix + \"\\n\" + core\n","\n","def prompt_5shot(task_text: str, entry) -> str:\n","    prefix = \"\".join(ALL_CODE_EXAMPLES)\n","    core = build_core_prompt(task_text, entry)\n","    return prefix + \"\\n\" + core\n","\n","MAIN_PROMPTS = {\n","    \"baseline\": (\"Baseline (task + signature)\", prompt_baseline),\n","    \"0shot\":   (\"0-shot (instruction + task + signature)\", prompt_0shot),\n","    \"1shot\":   (\"1-shot (code prefix + task + signature)\", prompt_1shot),\n","    \"3shot\":   (\"3-shot (code prefix + task + signature)\", prompt_3shot),\n","    \"5shot\":   (\"5-shot (code prefix + task + signature)\", prompt_5shot),\n","}\n","\n","print(\"‚úÖ MAIN_PROMPTS re-defined with:\")\n","for k, (name, _) in MAIN_PROMPTS.items():\n","    print(f\"  {k}: {name}\")\n"],"id":"JspMltXLTV-h"},{"cell_type":"markdown","metadata":{"id":"3EFTMS1yTV-h"},"source":["## Generation + Markdown-safe code extraction"],"id":"3EFTMS1yTV-h"},{"cell_type":"code","metadata":{"id":"ZPaxlKmxTV-h"},"execution_count":null,"outputs":[],"source":["def generate(model, tokenizer, prompt: str, max_new_tokens: int = 2048, num_samples: int = 1) -> list:\n","    \"\"\"\n","    Generate code from prompt.\n","    Parameters match bigcode-evaluation-harness defaults:\n","    - do_sample=True\n","    - temperature=0.2\n","    - top_p=0.95\n","    - max_length_generation=2048\n","\n","    Args:\n","        num_samples: Number of samples to generate (for pass@k calculation)\n","    Returns:\n","        List of generated strings (if num_samples > 1) or single string (if num_samples == 1)\n","    \"\"\"\n","    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n","\n","    if num_samples == 1:\n","        # Single sample (for pass@1)\n","        with torch.no_grad():\n","            outputs = model.generate(\n","                **inputs,\n","                max_new_tokens=max_new_tokens,\n","                do_sample=True,\n","                temperature=0.2,\n","                top_p=0.95,\n","                pad_token_id=tokenizer.eos_token_id,\n","            )\n","        return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    else:\n","        # Multiple samples (for pass@k)\n","        generated_texts = []\n","        with torch.no_grad():\n","            outputs = model.generate(\n","                **inputs,\n","                max_new_tokens=max_new_tokens,\n","                do_sample=True,\n","                temperature=0.2,\n","                top_p=0.95,\n","                pad_token_id=tokenizer.eos_token_id,\n","                num_return_sequences=num_samples,\n","            )\n","        for output in outputs:\n","            generated_texts.append(tokenizer.decode(output, skip_special_tokens=True))\n","        return generated_texts\n","\n","def strip_prompt(full_output: str, prompt: str) -> str:\n","    if prompt in full_output:\n","        return full_output.split(prompt, 1)[1].strip()\n","    return full_output.strip()\n","\n","def extract_code_from_markdown(text: str) -> str:\n","    \"\"\"Robustly extract Python code from possibly-markdown output.\"\"\"\n","    if not isinstance(text, str):\n","        return \"\"\n","\n","    s = text.strip()\n","\n","    # 1) Prefer fenced code blocks\n","    patterns = [\n","        r\"```python\\s*\\n(.*?)\\n```\",\n","        r\"```py\\s*\\n(.*?)\\n```\",\n","        r\"```\\s*\\n(.*?)\\n```\",\n","        r\"```python\\s*(.*?)```\",\n","        r\"```\\s*(.*?)```\",\n","    ]\n","    for pat in patterns:\n","        m = re.search(pat, s, flags=re.DOTALL | re.IGNORECASE)\n","        if m:\n","            code = m.group(1).strip()\n","            if len(code) > 0:\n","                s = code\n","                break\n","\n","    # 2) Remove any leading markers like ### Instruction/Output/Response\n","    s = re.sub(r\"^###\\s*(Instruction|Output|Response):\\s*\", \"\", s, flags=re.MULTILINE)\n","    s = re.sub(r\"^(Instruction|Output|Response):\\s*\", \"\", s, flags=re.MULTILINE)\n","\n","    # 3) If we can find a def ...(): block, prefer it\n","    m_def = re.search(r\"(def\\s+\\w+\\([^)]*\\):[\\s\\S]*)\", s)\n","    if m_def:\n","        s = m_def.group(1).strip()\n","\n","    # 4) Cut off if model started generating another instruction marker\n","    s = s.split(\"```\")[0]\n","    s = s.split(\"### Instruction:\")[0]\n","    s = s.split(\"### Output:\")[0]\n","    s = s.split(\"### Response:\")[0]\n","\n","    return s.strip()"],"id":"ZPaxlKmxTV-h"},{"cell_type":"markdown","metadata":{"id":"BUOS_IqcTV-h"},"source":["## MBPP dataset + correctness checker"],"id":"BUOS_IqcTV-h"},{"cell_type":"code","metadata":{"id":"qPUfUTh6TV-h","colab":{"base_uri":"https://localhost:8080/","height":342,"referenced_widgets":["8eb3192da96140359835571899f4e95d","1803c90ea7f54523b1c4fb409da945d6","2f274a6b2f04402992abd5de6b0bb8d9","9ae62982eb1f492c9ab0b6d083f8016c","5ded20cfe16f4abcbfc18dac0834faa7","169864c23ace444f9ff88dd720f9051e","8497ed2228ad4b159e23c1179cecbc7e","1c4ee54b54354759b94813a17a45d1ab","e2c8967c67684fa8b0a0ecfa9dbd7c99","9508e514df894984a81a3b2b21a6ad14","947c4e75e1b5477e8fa4c43e9eaf2e52","cc8517b98aba4856944488144f121758","6af2da7cb3a04e47ae174f33f95164da","e1603163e8ad4d3ab16ec44b8bcd0baf","1297aa3e248148838aa71b9e86d774e1","d6898f910a6a4a9eb2f7be868010c558","7f54946eeef243238b9bb889f88c129f","257e98ae8b6f481faa291f09aababe29","8d57b17003834456807da7cd477f4c09","9fa9921a72c24e01adb5e8365b291e92","404fb9c9c0124266a8f054174585c432","bba124162b014bd2a0ca5f4710f267ec","8571b97c80c34809bf61001b984cb0aa","2a3cb264e9fb46f68465aa2b148e597e","8dce0bf5e0964fa3aec0f1ba39a0441b","12d062fde022413185e99ca3e3200ad5","888cf2c2d7ca4bd3b58ded188f04738d","79bbd91cc32a44ed9774e1116a73f8dd","24c023c387614f87bd8fddb6b23d69d7","6945968149274cd19ce7883cc3db94d5","8e01d4d873cd4c1495045c614649d813","11bd8da508cf4ecb8cd695f0d5b96d10","67aeda7412114e579c51c9d92b92109c","53d172f803f2435ea63331b18cf47319","d21a9846bfe54152bc3beb8172b4ebc1","fcb34ef344c641a69ca1e425a277a65a","a43d05fcae864d3b972a6e0f32895c31","d4441853dd984e2181979cbac3bc388c","ff5d2c96d8484923af583c41c86d00d2","109bbfa17b7f477faf7c6955b9800e21","122a313bcdec4693ab0099f1d987ace0","dbab3733a7ed43c0b036b947a610ba0e","e98c6370c18d4df79dbdf7b7f7e3e9d8","0a23082cb474402ebcf7de70759a7706","7a390f2be0804fabb25042bb24cd1e25","336a7704082f4812a25d7ccff0e0a67c","5ef0080b1d5941f696ef1f919ee4c91c","ba8222d3b33a4fedb37c1d6e64426cdd","7f0720632cf64aa78bc5241b1c06cf3a","ddae58a6684444d78f18148db3567d1c","4a0564c7940e4c689709c3b98fdaa0e5","fbd1c2ef5b874a60aa294a35faf614d5","439da3ebb3df447b8d95933655a8f3d9","f59432f1cae34d7bb38fff2a3d9b710e","cd7dc8f9ebfb4919bbae87a57a161aac","1e7569de931d458f9590d96e4b653f79","1d29f75a5a134fd2ad6c32e6632d15b2","81169fe56fac4e02974691c91ff9107e","0695c50e36534374b82a806eadb24cc1","3d338ff02cfa4142870116b2e98bc76e","dfe18f1bc6d04cb1ac53a2d00baa88bd","94c0b13775ee40a7bea672e292b2239c","9c098effed85450aafadee64060e1c79","e6d2b9f92d924bfb85baca93ac702538","f4190714d7044b439e97968c4cabf57c","97dc3319d6d847a1b1d8ec3be72bc95e","599782e809d24e589e4b3a8b54603cb7","cc5b1d45c9b4433c9c65184b7a05f4ff","41d777c4ccc143faa3b957c181e97523","85c29be123c643ec8cd4d0b928429231","c3dcc4c93d7c481bbcd4b7600688d5c0","7d07a17fbe5746d496d9e19e9cf1a1e7","25e2513947654bf8940952250574d550","f6732948c7394249ba8292e4c1d38efb","723a49be944d4a33949075c9ed171990","f8adeafd67704ccfbf4b86ae04747e6f","a8806232057c4e06ad0291496cad8725","2f115986dcb94f2b857d5b700c90d578","e116f17534124278925209d4e119f1ba","c47ca54a4575440b8130719b687621c1","c8b9487571f2454dad8ed05205d82e26","4b6e0354611749b3aeb7dd1b61fab431","693c6db7c33d43d097f2c7f671f52644","4c8b56f191b6437295f1d29ce87d93cd","16867d2fb935455eba3e063ff17336e2","d3631949f6c547798ff865fff3c2b963","bb3a180d3d4949ea9e3147d22e5a5c11","7a51a914caa44ec6a4880006096b72f1","d1ab45fc7d964a8980ac7601ad24e6b8","149961570e0c4ad0971cf5c17bd3cb3a","43792da408484038ac3558221dbc7e3f","de086d3664be4444baf6c217e78810c7","6a602986fbbf4eefac8ea1c00ed96b4f","f417266830d848fc8e2384b5916ce198","2192447935574202a891271720f648d3","0a350d4fa4e541bf9e3cd236469302e5","051e0d5388144532adf996e703dc8375","003db91e63fc46e8b4b4ca8f66a8b61f","8d1417231fbb4df59d5b927bce0381bc"]},"outputId":"9145f605-123e-4afe-a0ec-0589562b1e35"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["README.md: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8eb3192da96140359835571899f4e95d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["full/train-00000-of-00001.parquet:   0%|          | 0.00/87.2k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc8517b98aba4856944488144f121758"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["full/test-00000-of-00001.parquet:   0%|          | 0.00/116k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8571b97c80c34809bf61001b984cb0aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["full/validation-00000-of-00001.parquet:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53d172f803f2435ea63331b18cf47319"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["full/prompt-00000-of-00001.parquet:   0%|          | 0.00/7.88k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a390f2be0804fabb25042bb24cd1e25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/374 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e7569de931d458f9590d96e4b653f79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating test split:   0%|          | 0/500 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"599782e809d24e589e4b3a8b54603cb7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating validation split:   0%|          | 0/90 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f115986dcb94f2b857d5b700c90d578"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating prompt split:   0%|          | 0/10 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1ab45fc7d964a8980ac7601ad24e6b8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["‚úÖ Loaded MBPP test subset: 100 problems\n","‚úÖ MBPP checker ready\n"]}],"source":["mbpp = load_dataset(\"google-research-datasets/mbpp\", split=\"test\").select(range(MBPP_LIMIT))\n","print(f\"‚úÖ Loaded MBPP test subset: {len(mbpp)} problems\")\n","\n","def check_mbpp_correct(code: str, entry) -> bool:\n","    \"\"\"Exec generated code + MBPP tests, return True if all pass.\"\"\"\n","    tests = entry[\"test_list\"]\n","    setup = entry[\"test_setup_code\"]\n","    if not tests:\n","        return False\n","\n","    code_clean = extract_code_from_markdown(code)\n","    if not code_clean or len(code_clean) < 8:\n","        return False\n","\n","    full = code_clean + \"\\n\" + setup + \"\\n\" + \"\\n\".join(tests)\n","    local_env = {}\n","    try:\n","        exec(full, {}, local_env)\n","        return True\n","    except Exception as e:\n","        # Uncomment for debugging\n","        # print(\"Error:\", e)\n","        # print(\"Code snippet:\", code_clean[:200])\n","        return False\n","\n","print(\"‚úÖ MBPP checker ready\")"],"id":"qPUfUTh6TV-h"},{"cell_type":"markdown","metadata":{"id":"JGz1YcJrTV-i"},"source":["## Quick sanity test on a few MBPP problems"],"id":"JGz1YcJrTV-i"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i7_7UlDWTV-i","outputId":"1f5bd205-be02-489b-82ae-ebfa4078ea2b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üí° Tip: run sanity_test_mbpp(model, tokenizer, 3, '3shot') before the full sweep.\n"]}],"source":["from tqdm.auto import tqdm\n","\n","def sanity_test_mbpp(model, tokenizer, n_problems: int = 5, prompt_key: str = \"3shot\"):\n","    name, prompt_fn = MAIN_PROMPTS[prompt_key]\n","    print(f\"Running sanity test on {n_problems} MBPP problems with prompt: {name}\")\n","\n","    correct = 0\n","    for i in range(n_problems):\n","        entry = mbpp[i]\n","        task_text = build_task_text_mbpp(entry)\n","        prompt = prompt_fn(task_text, entry)\n","        full_out = generate(model, tokenizer, prompt, max_new_tokens=256)\n","        gen_part = strip_prompt(full_out, prompt)\n","        code = extract_code_from_markdown(gen_part)\n","\n","        ok = check_mbpp_correct(code, entry)\n","        correct += int(ok)\n","\n","        print(f\"\\nProblem {i+1}:\")\n","        print(\"Task:\", task_text[:120].replace(\"\\n\", \" \") + (\"...\" if len(task_text) > 120 else \"\"))\n","        print(\"Generated code (first 200 chars):\")\n","        print(code[:200] + (\"...\" if len(code) > 200 else \"\"))\n","        print(\"Pass:\", \"‚úÖ\" if ok else \"‚ùå\")\n","\n","    print(f\"\\nSanity accuracy: {correct}/{n_problems} = {correct/n_problems:.2%}\")\n","\n","# Run this once to check everything is wired correctly\n","# sanity_test_mbpp(model, tokenizer, n_problems=3, prompt_key=\"3shot\")\n","print(\"üí° Tip: run sanity_test_mbpp(model, tokenizer, 3, '3shot') before the full sweep.\")"],"id":"i7_7UlDWTV-i"},{"cell_type":"code","source":["sanity_test_mbpp(model, tokenizer, 3, '3shot')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y34iB_BhT_KH","outputId":"16a733e3-d2a9-4b5b-db91-84a35d7f2d25"},"id":"y34iB_BhT_KH","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Running sanity test on 3 MBPP problems with prompt: 3-shot (code prefix + task + signature)\n","\n","Problem 1:\n","Task: Write a python function to remove first and last occurrence of a given character from the string.\n","Generated code (first 200 chars):\n","def remove_Occ(s, ch):\n","    # Find the first occurrence of the character\n","    first_occurrence = s.find(ch)\n","    # Find the last occurrence of the character\n","    last_occurrence = s.rfind(ch)\n","    \n","    # I...\n","Pass: ‚ùå\n","[[3, 1, 4], [2, 6, 5], [1, 5, 9]]\n","\n","Problem 2:\n","Task: Write a function to sort a given matrix in ascending order according to the sum of its rows.\n","Generated code (first 200 chars):\n","def sort_matrix(M):\n","    M.sort(key=lambda x: sum(x))\n","    return M\n","\n","# Example usage:\n","matrix = [\n","    [3, 1, 4],\n","    [1, 5, 9],\n","    [2, 6, 5]\n","]\n","sorted_matrix = sort_matrix(matrix)\n","print(sorted_matrix)  #...\n","Pass: ‚úÖ\n","\n","Problem 3:\n","Task: Write a function to count the most common words in a dictionary.\n","Generated code (first 200 chars):\n","def most_common_words(word_dict):\n","    # Count the frequency of each word in the dictionary\n","    word_counts = Counter(word_dict.values())\n","    \n","    # Find the most common word(s)\n","    most_common = word_...\n","Pass: ‚ùå\n","\n","Sanity accuracy: 1/3 = 33.33%\n"]}]},{"cell_type":"markdown","metadata":{"id":"CD_TBGxOTV-i"},"source":["## Phase 1: Prompt selection on MBPP (full sweep)"],"id":"CD_TBGxOTV-i"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["6cfb2d07e807454aa85fb7fd10a5416b","9d5c504797ab45e2b5c9a70e62325024","c088b9330f6442fd820514bbc018f1d1","85d5d83019934fd88ced202a024a8652","36eff46eda6b49e19174387df7c97699","780f19308b25487d8ee0cc9bd61066a5","af8f015b7b8543fe94f55d4a0ba84a8c","e4c861075f7a458486a7e0c34c65b489","5a456cc8b2f248549ba03c1d81eb3b59","a2c5f6fedc4a4f49bf3add032581ba7d","84eb3b42b01444a68d707292b190fe75","88e4d35be0ac4f6e989c02e39e66779a","a6fcb49ace1a41c1ba16ebb56f83d1f9","3bd94718f5f8422eacccb3304f30e10e","78e12288dbed469d80fa3f5e91112d99","2017b289c6ca4e26be3e1e6dd0fc77a5","77feaf7395834f1caede664ab9ef4c51","6a7a925c0a8e464aae03f4df7e9829ad","5c79a4fc1a934fb097a4c6cb82324f6b","ae8ed2304f324c3c8b80379ebcf5b189","09abc65091b44febb5b098320d43d44b","4bc08140244d45a4b266b1cfa919b960","2bbe892a8f3c47758931bf6d44d41988","7c0feba307b847e3bf63702cf970c518","30dd29628f9a486f8fdd158ec6743db1","d8d77dad722a4d2ebb58b92d43516677","f841637e8c524b338795092be212ea66","581ca9b377ef4515b02e86af636b8321","04e2d6cbe82143b7b29975047f2afbd2","5757200d3d1e410ab0021ff13f14cd34","b51711041fac4271ba3d6f860c8c866e","89c91021e51d4866baf7d417b469e4e7","820d4a4c071d4ac8b60bdb3a595e2ea7","4fd09d4b029041e19104708b3d4af4f1","e350f05235ba4feb9688442128f5b909","f853200d5af0429e9ccaea4861750f2b","9f78b764fa2b4e93ab1cc6056c9e65da","7d87637cc356432f89fc3c4305afc4c7","9e708f6d2b944a5bb4b8fbd0f6b92cec","8ac7d4b25f8f43d7af06d2cabcd9f78b","d87eb678f037498fbece9f8c5bb4cc02","afa7a234bd924d7fa0449ae70b1bf1c6","ea028f1a513e44a3b57b1c115b1a7bd0","83141bab00c4488098c5124c692af174","43182452ae8b486cb1a3bfaf2d0e3054","34399e55790444c3b87bc5985ae45f12","08e105a87eab4aa6a183cf0370a4e1eb","c4bb3397d01e4818ad5cfbb81e1dacd6","918427fa55294d35a5e00ba2ed22ede9","7eff79f3870440679951d256b5d23a56","a603ef3a77354a3d95b7eab6cd9d1c8f","a9caf37422af4797b7abca9628f7e471","fc6beb0c01e14900a2408fd5fce82212","c8b9faaf1f284d75bac9d94d0e535a87","b17e25cde53244c3b72b6f1f9d255958"]},"id":"iYffJU6oTV-i","outputId":"04732ded-c481-4468-d566-cab940657b57"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","Evaluating config: baseline ‚Äî Baseline (task + signature)\n","============================================================\n"]},{"output_type":"display_data","data":{"text/plain":["baseline:   0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cfb2d07e807454aa85fb7fd10a5416b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["True\n","False\n","[1, 3, 4, 'apple', 'banana', 'cherry']\n","Equilateral Triangle\n","Not Equilateral Triangle\n","Not Equilateral Triangle\n","True\n","True\n","{'a': 1, 'b': 3, 'c': 4, 'd': 5}\n","HelloWorld\n","ConvertThisString\n","[['apple', 'banana', 'cherry'], ['cat', 'dog', 'elephant'], ['giraffe', 'lion', 'zebra']]\n","  ‚Üí Baseline (task + signature): 0.2000 (20/100)\n","\n","============================================================\n","Evaluating config: 0shot ‚Äî 0-shot (instruction + task + signature)\n","============================================================\n"]},{"output_type":"display_data","data":{"text/plain":["0shot:   0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88e4d35be0ac4f6e989c02e39e66779a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Not Equilateral\n","{'a': 1, 'b': [2, 3], 'c': 4, 'd': 5}\n","True\n","  ‚Üí 0-shot (instruction + task + signature): 0.2000 (20/100)\n","\n","============================================================\n","Evaluating config: 1shot ‚Äî 1-shot (code prefix + task + signature)\n","============================================================\n"]},{"output_type":"display_data","data":{"text/plain":["1shot:   0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bbe892a8f3c47758931bf6d44d41988"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[[3, 1, 4], [2, 6, 5], [1, 5, 9]]\n","False\n","True\n","False\n","True\n","True\n","True\n","False\n","False\n","True\n","True\n","True\n","False\n","False\n","1\n","1\n","6.0\n","156.25\n","0\n","[['apple', 'banana', 'cherry'], ['cat', 'dog', 'elephant'], ['giraffe', 'lion', 'zebra']]\n","  ‚Üí 1-shot (code prefix + task + signature): 0.2600 (26/100)\n","\n","============================================================\n","Evaluating config: 3shot ‚Äî 3-shot (code prefix + task + signature)\n","============================================================\n"]},{"output_type":"display_data","data":{"text/plain":["3shot:   0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fd09d4b029041e19104708b3d4af4f1"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[[3, 1, 4], [2, 6, 5], [1, 5, 9]]\n","20\n","28\n","40\n","False\n","2\n","[1, 3, 4, 'apple', 'banana', 'cherry']\n","Not Equilateral Triangle\n","True\n","True\n","False\n","False\n","False\n","1\n","-8\n","None\n","7\n","3\n","6\n","7\n","3\n","0\n","1\n","3\n","4\n","6\n","6.0\n","156.25\n","0\n","[['apple', 'banana', 'cherry'], ['cat', 'dog', 'elephant'], ['giraffe', 'lion', 'zebra']]\n","  ‚Üí 3-shot (code prefix + task + signature): 0.3200 (32/100)\n","\n","============================================================\n","Evaluating config: 5shot ‚Äî 5-shot (code prefix + task + signature)\n","============================================================\n"]},{"output_type":"display_data","data":{"text/plain":["5shot:   0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43182452ae8b486cb1a3bfaf2d0e3054"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[[3, 1, 4], [2, 6, 5], [1, 5, 9]]\n","False\n","2\n","2\n","30\n","110\n","[1, 3, 4, 'apple', 'banana', 'cherry']\n","Not Equilateral Triangle\n","ƒ¶\n","≈´\n","»î\n","  ‚Üí 5-shot (code prefix + task + signature): 0.3500 (35/100)\n","\n","=== MBPP Prompt Selection Results ===\n","5shot   | 5-shot (code prefix + task + signature) | acc=0.3500 (35/100)\n","3shot   | 3-shot (code prefix + task + signature) | acc=0.3200 (32/100)\n","1shot   | 1-shot (code prefix + task + signature) | acc=0.2600 (26/100)\n","baseline | Baseline (task + signature)    | acc=0.2000 (20/100)\n","0shot   | 0-shot (instruction + task + signature) | acc=0.2000 (20/100)\n","\n","üèÜ Best config on MBPP:\n","  key       = 5shot\n","  name      = 5-shot (code prefix + task + signature)\n","  accuracy  = 0.3500 (35/100)\n","\n","üíæ Saved MBPP selection results to results/qwen_mbpp_prompt_selection.json\n"]}],"source":["def eval_shots_on_mbpp(model, tokenizer):\n","    results = []\n","    for key, (name, prompt_fn) in MAIN_PROMPTS.items():\n","        print(\"\\n\" + \"=\"*60)\n","        print(f\"Evaluating config: {key} ‚Äî {name}\")\n","        print(\"=\"*60)\n","\n","        correct = 0\n","        total = len(mbpp)\n","        for i, entry in enumerate(tqdm(mbpp, desc=f\"{key}\", leave=False)):\n","            task_text = build_task_text_mbpp(entry)\n","            prompt = prompt_fn(task_text, entry)\n","            full_out = generate(model, tokenizer, prompt, max_new_tokens=256)\n","            gen_part = strip_prompt(full_out, prompt)\n","            code = extract_code_from_markdown(gen_part)\n","\n","            if check_mbpp_correct(code, entry):\n","                correct += 1\n","\n","        acc = correct / total\n","        results.append((key, name, acc, correct, total))\n","        print(f\"  ‚Üí {name}: {acc:.4f} ({correct}/{total})\")\n","\n","    # Sort by accuracy desc\n","    results.sort(key=lambda x: x[2], reverse=True)\n","    return results\n","\n","mbpp_results = eval_shots_on_mbpp(model, tokenizer)\n","\n","print(\"\\n=== MBPP Prompt Selection Results ===\")\n","for key, name, acc, correct, total in mbpp_results:\n","    print(f\"{key:7s} | {name:30s} | acc={acc:.4f} ({correct}/{total})\")\n","\n","# pick best\n","best_key, best_name, best_acc, best_correct, best_total = mbpp_results[0]\n","print(\"\\nüèÜ Best config on MBPP:\")\n","print(f\"  key       = {best_key}\")\n","print(f\"  name      = {best_name}\")\n","print(f\"  accuracy  = {best_acc:.4f} ({best_correct}/{best_total})\")\n","\n","os.makedirs(\"results\", exist_ok=True)\n","mbpp_summary = {\n","    \"best\": {\n","        \"key\": best_key,\n","        \"name\": best_name,\n","        \"accuracy\": float(best_acc),\n","        \"correct\": int(best_correct),\n","        \"total\": int(best_total),\n","    },\n","    \"all_results\": [\n","        {\n","            \"key\": k,\n","            \"name\": n,\n","            \"accuracy\": float(a),\n","            \"correct\": int(c),\n","            \"total\": int(t),\n","        }\n","        for (k, n, a, c, t) in mbpp_results\n","    ],\n","}\n","with open(\"results/qwen_mbpp_prompt_selection.json\", \"w\") as f:\n","    json.dump(mbpp_summary, f, indent=2)\n","\n","print(\"\\nüíæ Saved MBPP selection results to results/qwen_mbpp_prompt_selection.json\")\n","\n","# store best prompt fn for later use (Phase 2)\n","best_prompt_fn = MAIN_PROMPTS[best_key][1]"],"id":"iYffJU6oTV-i"},{"cell_type":"markdown","metadata":{"id":"ejy077l1TV-j"},"source":["## Phase 2: HumanEval evaluation with best-shot prompt"],"id":"ejy077l1TV-j"},{"cell_type":"code","metadata":{"id":"jgeHtewkTV-j"},"execution_count":null,"outputs":[],"source":["humaneval_problems = read_problems()\n","print(f\"‚úÖ Loaded {len(humaneval_problems)} HumanEval problems\")\n","\n","def check_humaneval(code: str, problem: dict) -> bool:\n","    \"\"\"Simple HumanEval checker using exec() and provided test code.\"\"\"\n","    code_clean = extract_code_from_markdown(code)\n","    if not code_clean or len(code_clean) < 8:\n","        return False\n","\n","    prompt_sig = problem[\"prompt\"]   # includes def + docstring, etc.\n","    test_code = problem[\"test\"]\n","\n","    # Avoid duplicating the signature block if the model echoed it\n","    if prompt_sig in code_clean:\n","        body = code_clean.replace(prompt_sig, \"\")\n","    else:\n","        body = code_clean\n","\n","    full = prompt_sig + body + \"\\n\" + test_code\n","    try:\n","        exec(full, {})\n","        return True\n","    except Exception:\n","        return False\n","\n","\n","# ---- Adapter: Convert HumanEval problem to MBPP-like entry ----\n","\n","def make_fake_entry_for_humaneval(problem: dict) -> dict:\n","    \"\"\"\n","    Create a fake MBPP-like entry from HumanEval problem.\n","    This allows us to reuse MBPP prompt functions.\n","\n","    get_signature() expects entry[\"code\"] to be a function definition line.\n","    We extract the first line (function signature) from problem[\"prompt\"].\n","    \"\"\"\n","    # Extract function signature from problem[\"prompt\"] (first line)\n","    prompt_lines = problem[\"prompt\"].strip().split(\"\\n\")\n","    first_line = prompt_lines[0] if prompt_lines else \"\"\n","\n","    # Ensure it ends with colon (get_signature adds it, but just in case)\n","    if first_line and not first_line.rstrip().endswith(\":\"):\n","        first_line = first_line.rstrip() + \":\"\n","\n","    # Create fake entry with the structure MBPP prompt functions expect\n","    fake_entry = {\n","        \"code\": first_line + \"\\n\",  # get_signature() will extract from this\n","        \"text\": problem.get(\"entry_point\", \"\"),  # Not used, but for compatibility\n","    }\n","    return fake_entry\n","\n","def build_task_text_from_humaneval(problem: dict) -> str:\n","    \"\"\"\n","    Extract task description from HumanEval problem.\n","    HumanEval doesn't have explicit \"text\" field, so we use the docstring.\n","    \"\"\"\n","    # Extract docstring from prompt (usually the second line)\n","    prompt_lines = problem[\"prompt\"].strip().split(\"\\n\")\n","    if len(prompt_lines) > 1:\n","        # Try to extract docstring (between triple quotes)\n","        docstring = \"\\n\".join(prompt_lines[1:])\n","        # Remove quotes if present\n","        docstring = docstring.strip().strip('\"\"\"').strip(\"'''\").strip()\n","        return docstring\n","    return \"Complete the function\"  # Fallback\n","\n","\n","# ---- Use the best prompt_fn from MBPP selection ----\n","\n","def calculate_pass_at_k(n, c, k):\n","    \"\"\"\n","    Calculate pass@k metric.\n","    n: total number of samples\n","    c: number of correct samples\n","    k: k for pass@k\n","    \"\"\"\n","    if n - c < k:\n","        return 1.0\n","    return 1.0 - (math.comb(n - c, k) / math.comb(n, k))\n","\n","def eval_humaneval(model, tokenizer, prompt_fn, calculate_pass10: bool = True):\n","    \"\"\"\n","    Evaluate HumanEval using the best prompt function from MBPP selection.\n","\n","    Args:\n","        model: The model to evaluate\n","        tokenizer: The tokenizer\n","        prompt_fn: The best prompt function from MAIN_PROMPTS (takes task_text, entry)\n","        calculate_pass10: If True, also calculate pass@10 (requires 10 samples per problem)\n","    \"\"\"\n","    correct_pass1 = 0\n","    correct_pass10 = 0\n","    total = len(humaneval_problems)\n","    n_samples = 10 if calculate_pass10 else 1\n","\n","    print(f\"üöÄ Evaluating HumanEval with best prompt from MBPP selection\")\n","    print(f\"   Total problems: {total}\")\n","    if calculate_pass10:\n","        print(f\"   Generating {n_samples} samples per problem for pass@10 calculation\")\n","\n","    # Use tqdm for progress bar\n","    from tqdm.auto import tqdm\n","\n","    for i, (task_id, problem) in enumerate(tqdm(humaneval_problems.items(), desc=\"HumanEval\")):\n","        # Create fake entry for prompt_fn\n","        fake_entry = make_fake_entry_for_humaneval(problem)\n","        task_text = build_task_text_from_humaneval(problem)\n","\n","        # Use the same prompt function as MBPP\n","        prompt = prompt_fn(task_text, fake_entry)\n","\n","        # Generate samples\n","        if calculate_pass10:\n","            full_outs = generate(model, tokenizer, prompt, max_new_tokens=2048, num_samples=n_samples)\n","            # Check each sample\n","            passed_samples = 0\n","            for full_out in full_outs:\n","                gen_part = strip_prompt(full_out, prompt)\n","                code = extract_code_from_markdown(gen_part)\n","                if check_humaneval(code, problem):\n","                    passed_samples += 1\n","\n","            # Pass@1: first sample passes\n","            if check_humaneval(extract_code_from_markdown(strip_prompt(full_outs[0], prompt)), problem):\n","                correct_pass1 += 1\n","\n","            # Pass@10: at least one sample passes (out of 10)\n","            if passed_samples > 0:\n","                correct_pass10 += 1\n","        else:\n","            # Only pass@1\n","            full_out = generate(model, tokenizer, prompt, max_new_tokens=2048, num_samples=1)\n","            gen_part = strip_prompt(full_out, prompt)\n","            code = extract_code_from_markdown(gen_part)\n","            if check_humaneval(code, problem):\n","                correct_pass1 += 1\n","\n","        # Update progress bar description with current accuracy\n","        if (i + 1) % 10 == 0:\n","            current_acc1 = correct_pass1 / (i + 1)\n","            if calculate_pass10:\n","                current_acc10 = correct_pass10 / (i + 1)\n","                tqdm.write(f\"  Progress: {i+1}/{total} ‚Äî pass@1={current_acc1:.2%}, pass@10={current_acc10:.2%}\")\n","            else:\n","                tqdm.write(f\"  Progress: {i+1}/{total} ‚Äî pass@1={current_acc1:.2%}\")\n","\n","    acc_pass1 = correct_pass1 / total\n","    results = {\n","        \"pass@1\": acc_pass1,\n","        \"pass@1_correct\": correct_pass1,\n","        \"pass@1_total\": total,\n","    }\n","\n","    if calculate_pass10:\n","        acc_pass10 = correct_pass10 / total\n","        results[\"pass@10\"] = acc_pass10\n","        results[\"pass@10_correct\"] = correct_pass10\n","        results[\"pass@10_total\"] = total\n","        print(f\"\\n‚úÖ HumanEval pass@1: {acc_pass1:.4f} ({correct_pass1}/{total})\")\n","        print(f\"‚úÖ HumanEval pass@10: {acc_pass10:.4f} ({correct_pass10}/{total})\")\n","    else:\n","        print(f\"\\n‚úÖ HumanEval pass@1: {acc_pass1:.4f} ({correct_pass1}/{total})\")\n","\n","    # Auto shutdown GPU after evaluation (to save resources)\n","    import os\n","    if os.getenv(\"COLAB_GPU\") or torch.cuda.is_available():\n","        print(\"\\nüí§ Shutting down GPU to save resources...\")\n","        torch.cuda.empty_cache()\n","        print(\"   GPU cache cleared. GPU will be released when runtime ends.\")\n","\n","    return results\n","\n","\n","# ---- Run AFTER Phase 1, when best_prompt_fn is defined ----\n","# Running HumanEval evaluation with best prompt from MBPP selection\n","# Using 5-shot (best config from MBPP: 0.3500 accuracy)\n","\n","# Use 5-shot as the best prompt (from MBPP results: 35/100 = 0.3500)\n","best_key = \"5shot\"\n","best_name = MAIN_PROMPTS[best_key][0]\n","best_prompt_fn = MAIN_PROMPTS[best_key][1]\n","\n","print(f\"‚úÖ Using best prompt from MBPP: {best_key} - {best_name}\")\n","print(f\"   (MBPP accuracy: 0.3500 (35/100))\")\n","\n","humaneval_results = eval_humaneval(\n","    model, tokenizer, best_prompt_fn, calculate_pass10=True\n",")\n","\n","os.makedirs(\"results\", exist_ok=True)\n","with open(\"results/qwen_humaneval_best_prompt.json\", \"w\") as f:\n","    json.dump({\n","        \"pass@1\": float(humaneval_results[\"pass@1\"]),\n","        \"pass@1_correct\": int(humaneval_results[\"pass@1_correct\"]),\n","        \"pass@1_total\": int(humaneval_results[\"pass@1_total\"]),\n","        \"pass@10\": float(humaneval_results.get(\"pass@10\", 0)),\n","        \"pass@10_correct\": int(humaneval_results.get(\"pass@10_correct\", 0)),\n","        \"pass@10_total\": int(humaneval_results.get(\"pass@10_total\", 0)),\n","        \"best_prompt_key\": best_key,\n","        \"best_prompt_name\": best_name,\n","    }, f, indent=2)\n","print(\"üíæ Saved HumanEval results to results/qwen_humaneval_best_prompt.json\")\n","\n","# Auto download result file (important: Colab files are lost when runtime disconnects)\n","try:\n","    from google.colab import files\n","    print(\"\\nüì• Auto-downloading HumanEval results...\")\n","    files.download(\"results/qwen_humaneval_best_prompt.json\")\n","    print(\"‚úÖ HumanEval results downloaded!\")\n","except ImportError:\n","    print(\"‚ö†Ô∏è  Not in Colab, skipping auto-download\")\n","except Exception as e:\n","    print(f\"‚ö†Ô∏è  Auto-download failed: {e}\")\n","    print(\"   Please manually download results/qwen_humaneval_best_prompt.json\")\n"],"id":"jgeHtewkTV-j"},{"cell_type":"code","source":["   %pip uninstall -y evalplus"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a3rxMnR7r7yI","outputId":"dc66427b-1459-43b6-88de-014910e5083a"},"id":"a3rxMnR7r7yI","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: evalplus 0.3.1\n","Uninstalling evalplus-0.3.1:\n","  Successfully uninstalled evalplus-0.3.1\n"]}]},{"cell_type":"code","source":["     %pip install --no-cache-dir \"git+https://github.com/evalplus/evalplus.git\""],"metadata":{"id":"IPbAWcu3rfOU"},"id":"IPbAWcu3rfOU","execution_count":null,"outputs":[]},{"cell_type":"code","source":[" %pip show evalplus"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZFKE8d_CrwY3","outputId":"cbe1e181-c15e-42fc-9216-256038353372"},"id":"ZFKE8d_CrwY3","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Name: evalplus\n","Version: 0.4.0.dev44\n","Summary: \"EvalPlus for rigourous evaluation of LLM-synthesized code\"\n","Home-page: https://github.com/evalplus/evalplus\n","Author: \n","Author-email: \n","License: Apache-2.0\n","Location: /usr/local/lib/python3.12/dist-packages\n","Requires: anthropic, appdirs, boto3, datasets, fire, google-generativeai, multipledispatch, numpy, ollama, openai, psutil, rich, tempdir, termcolor, tqdm, transformers, tree-sitter-python, tree_sitter, wget\n","Required-by: \n"]}]},{"cell_type":"code","source":["import evalplus.evaluate as ev\n","print(ev.__file__)\n","print([name for name in dir(ev) if \"eval\" in name.lower()])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TzX88udbs7Ki","outputId":"595add12-cce0-4167-ef52-7d753f42dbbc"},"id":"TzX88udbs7Ki","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.12/dist-packages/evalplus/evaluate.py\n","['PERF_EVAL_TIMEOUT_SECOND', 'compatible_eval_result', 'evaluate', 'get_human_eval_plus', 'get_human_eval_plus_hash']\n"]}]},{"cell_type":"code","source":["import os, re, json, math, textwrap, traceback\n","import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","from datasets import load_dataset\n","\n","# Re-define necessary functions/variables from earlier cells (e.g., 3de27163, ZPaxlKmxTV-h)\n","# to ensure they are in scope for this execution.\n","\n","# Adapter functions (from 3de27163)\n","def make_fake_entry_for_humaneval(problem: dict) -> dict:\n","    \"\"\"\n","    Create a fake MBPP-like entry from HumanEval problem.\n","    This allows us to reuse MBPP prompt functions.\n","\n","    get_signature() expects entry[\"code\"] to be a function definition line.\n","    We need to extract the 'def ...:' line from problem[\"prompt\"].\n","    \"\"\"\n","    signature_line = \"\"\n","    for line in problem[\"prompt\"].strip().split(\"\\n\"):\n","        if line.strip().startswith(\"def \"):\n","            signature_line = line.strip()\n","            break\n","    if not signature_line:\n","        signature_line = problem[\"prompt\"].strip().split(\"\\n\")[0].strip()\n","    fake_entry = {\n","        \"code\": signature_line + \"\\n\",\n","        \"text\": problem.get(\"entry_point\", \"\"),\n","    }\n","    return fake_entry\n","\n","def build_task_text_from_humaneval(problem: dict) -> str:\n","    \"\"\"\n","    Extract task description from HumanEval problem.\n","    HumanEval doesn't have explicit \"text\" field, so we use the docstring.\n","    \"\"\"\n","    prompt_lines = problem[\"prompt\"].strip().split(\"\\n\")\n","    def_found = False\n","    docstring_lines = []\n","    for line in prompt_lines:\n","        if line.strip().startswith(\"def \"):\n","            def_found = True\n","            continue\n","        if def_found:\n","            docstring_lines.append(line)\n","    if docstring_lines:\n","        docstring = \"\\n\".join(docstring_lines)\n","        docstring = docstring.strip().strip('\"\"\"').strip(\"'''\").strip()\n","        return docstring\n","    return \"Complete the function\"\n","\n","# Prompt builder dependencies (from JspMltXLTV-h / 3de27163)\n","HARD_RULE = (\n","    \"# You are a Python coding assistant.\\n\"\n","    \"# Only output valid Python code implementing the required function.\\n\"\n","    \"# Do NOT use markdown or ```.\\n\"\n","    \"# Do NOT print explanations or comments outside the function body.\\n\\n\"\n",")\n","\n","def get_signature(entry):\n","    first_line = entry[\"code\"].strip().split(\"\\n\")[0]\n","    sig = first_line.strip().rstrip(\":\") + \":\"\n","    return sig + \"\\n\"\n","\n","def build_core_prompt(task_text: str, entry) -> str:\n","    one_line_task = task_text.replace(\"\\n\", \" \")\n","    sig = get_signature(entry)\n","    core = (\n","        HARD_RULE +\n","        f\"# Task: {one_line_task}\\n\"\n","        f\"# Implement the following function to solve the task.\\n\\n\"\n","        f\"{sig}\"\n","    )\n","    return core\n","\n","CODE_EXAMPLE_1 = \"\"\"def factorial(n):\n","    if n == 0 or n == 1:\n","        return 1\n","    return n * factorial(n - 1)\n","\n","\"\"\"\n","\n","CODE_EXAMPLE_2 = \"\"\"def is_palindrome(s):\n","    s = s.lower().replace(\" \", \"\")\n","    return s == s[::-1]\n","\n","\"\"\"\n","\n","CODE_EXAMPLE_3 = \"\"\"def fibonacci(n):\n","    if n <= 0:\n","        return []\n","    elif n == 1:\n","        return [0]\n","    elif n == 2:\n","        return [0, 1]\n","    seq = [0, 1]\n","    for i in range(2, n):\n","        seq.append(seq[-1] + seq[-2])\n","    return seq\n","\n","\"\"\"\n","\n","CODE_EXAMPLE_4 = \"\"\"def find_max(lst):\n","    if not lst:\n","        return None\n","    m = lst[0]\n","    for x in lst[1:]:\n","        if x > m:\n","            m = x\n","    return m\n","\n","\"\"\"\n","\n","CODE_EXAMPLE_5 = \"\"\"def reverse_list(lst):\n","    i, j = 0, len(lst) - 1\n","    while i < j:\n","        lst[i], lst[j] = lst[j], lst[i]\n","        i += 1\n","        j -= 1\n","    return lst\n","\n","\"\"\"\n","\n","ALL_CODE_EXAMPLES = [\n","    CODE_EXAMPLE_1,\n","    CODE_EXAMPLE_2,\n","    CODE_EXAMPLE_3,\n","    CODE_EXAMPLE_4,\n","    CODE_EXAMPLE_5,\n","]\n","\n","def prompt_baseline(task_text: str, entry) -> str:\n","    return build_core_prompt(task_text, entry)\n","\n","def prompt_0shot(task_text: str, entry) -> str:\n","    core = build_core_prompt(task_text, entry)\n","    return \"# Complete the function below.\\n\\n\" + core\n","\n","def prompt_1shot(task_text: str, entry) -> str:\n","    prefix = CODE_EXAMPLE_1\n","    core = build_core_prompt(task_text, entry)\n","    return prefix + \"\\n\" + core\n","\n","def prompt_3shot(task_text: str, entry) -> str:\n","    prefix = CODE_EXAMPLE_1 + CODE_EXAMPLE_2 + CODE_EXAMPLE_3\n","    core = build_core_prompt(task_text, entry)\n","    return prefix + \"\\n\" + core\n","\n","def prompt_5shot(task_text: str, entry) -> str:\n","    prefix = \"\".join(ALL_CODE_EXAMPLES)\n","    core = build_core_prompt(task_text, entry)\n","    return prefix + \"\\n\" + core\n","\n","MAIN_PROMPTS = {\n","    \"baseline\": (\"Baseline (task + signature)\", prompt_baseline),\n","    \"0shot\":   (\"0-shot (instruction + task + signature)\", prompt_0shot),\n","    \"1shot\":   (\"1-shot (code prefix + task + signature)\", prompt_1shot),\n","    \"3shot\":   (\"3-shot (code prefix + task + signature)\", prompt_3shot),\n","    \"5shot\":   (\"5-shot (code prefix + task + signature)\", prompt_5shot),\n","}\n","\n","# Helper functions for generation and extraction (from ZPaxlKmxTV-h)\n","def generate(model, tokenizer, prompt: str, max_new_tokens: int = 2048, num_samples: int = 1) -> list:\n","    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n","    if num_samples == 1:\n","        with torch.no_grad():\n","            outputs = model.generate(\n","                **inputs,\n","                max_new_tokens=max_new_tokens,\n","                do_sample=True,\n","                temperature=0.2,\n","                top_p=0.95,\n","                pad_token_id=tokenizer.eos_token_id,\n","            )\n","        return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    else:\n","        generated_texts = []\n","        with torch.no_grad():\n","            outputs = model.generate(\n","                **inputs,\n","                max_new_tokens=max_new_tokens,\n","                do_sample=True,\n","                temperature=0.2,\n","                top_p=0.95,\n","                pad_token_id=tokenizer.eos_token_id,\n","                num_return_sequences=num_samples,\n","            )\n","        for output in outputs:\n","            generated_texts.append(tokenizer.decode(output, skip_special_tokens=True))\n","        return generated_texts\n","\n","def strip_prompt(full_output: str, prompt: str) -> str:\n","    if prompt in full_output:\n","        return full_output.split(prompt, 1)[1].strip()\n","    return full_output.strip()\n","\n","def extract_code_from_markdown(text: str) -> str:\n","    if not isinstance(text, str):\n","        return \"\"\n","    s = text.strip()\n","    patterns = [\n","        r\"```python\\s*\\n(.*?)\\n```\",\n","        r\"```py\\s*\\n(.*?)\\n```\",\n","        r\"```\\s*\\n(.*?)\\n```\",\n","        r\"```python\\s*(.*?)```\",\n","        r\"```\\s*(.*?)```\",\n","    ]\n","    for pat in patterns:\n","        m = re.search(pat, s, flags=re.DOTALL | re.IGNORECASE)\n","        if m:\n","            code = m.group(1).strip()\n","            if len(code) > 0:\n","                s = code\n","                break\n","    s = re.sub(r\"^###\\s*(Instruction|Output|Response):\\s*\", \"\", s, flags=re.MULTILINE)\n","    s = re.sub(r\"^(Instruction|Output|Response):\\s*\", \"\", s, flags=re.MULTILINE)\n","    m_def = re.search(r\"(def\\s+\\w+\\([^)]*\\):[\\s\\S]*)\", s)\n","    if m_def:\n","        s = m_def.group(1).strip()\n","    s = s.split(\"```\")[0]\n","    s = s.split(\"### Instruction:\")[0]\n","    s = s.split(\"### Output:\")[0]\n","    s = s.split(\"### Response:\")[0]\n","    return s.strip()"],"metadata":{"id":"sOT6dZXszeHo"},"id":"sOT6dZXszeHo","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ============================================================\n","# Phase 5: TRUE HumanEval+ Evaluation (evalplus enhanced tests)\n","# ============================================================\n","from evalplus.data import get_human_eval_plus\n","from evalplus.evaluate import evaluate\n","from time import time\n","\n","humaneval_plus_problems = get_human_eval_plus()\n","assert humaneval_plus_problems, \"‚ùå Failed to load HumanEval+ problems!\"\n","print(f\"‚úÖ Loaded {len(humaneval_plus_problems)} HumanEval+ problems (enhanced tests)\")\n","print(\"=\" * 60)\n","print(\"üìä Phase 5: HumanEval+ Evaluation (evalplus)\")\n","print(\"=\" * 60)\n","\n","best_key = \"5shot\"\n","best_name, best_prompt_fn = MAIN_PROMPTS[best_key]\n","print(f\"‚úÖ Using best prompt: {best_key} ‚Äî {best_name}\\n\")\n","\n","def check_humaneval_plus_local(code: str, problem: dict) -> bool:\n","    code_clean = extract_code_from_markdown(code)\n","    if not code_clean or len(code_clean) < 8:\n","        return False\n","\n","    prompt_sig = problem[\"prompt\"]\n","    test_code = problem[\"test\"]\n","    body = code_clean.replace(prompt_sig, \"\") if prompt_sig in code_clean else code_clean\n","\n","    try:\n","        exec(prompt_sig + body + \"\\n\" + test_code, {})\n","        return True\n","    except Exception:\n","        return False\n","\n","MAX_SAMPLES = 10   # pass@10 ÁõÆÊ†á\n","BATCH_SIZE = 3     # ÊØèËΩÆÊúÄÂ§öÈááÊ†∑Êï∞\n","generations = {}\n","\n","print(\"üöÄ Generating model solutions (progressive sampling)...\")\n","for idx, (task_id, problem) in enumerate(tqdm(humaneval_plus_problems.items(), desc=\"Generating\"), 1):\n","    start = time()\n","    fake_entry = make_fake_entry_for_humaneval(problem)\n","    task_text = build_task_text_from_humaneval(problem)\n","    prompt = best_prompt_fn(task_text, fake_entry)\n","\n","    samples = []\n","    pass_found = False\n","    success_code = \"\"\n","    attempts = 0\n","\n","    while attempts < MAX_SAMPLES and not pass_found:\n","        to_generate = min(BATCH_SIZE, MAX_SAMPLES - attempts)\n","        full_outs = generate(\n","            model,\n","            tokenizer,\n","            prompt,\n","            max_new_tokens=2048,\n","            num_samples=to_generate,\n","        )\n","        if to_generate == 1:\n","            full_outs = [full_outs]\n","\n","        for full_out in full_outs:\n","            gen_part = strip_prompt(full_out, prompt)\n","            code = extract_code_from_markdown(gen_part)\n","            samples.append(code)\n","            attempts += 1\n","\n","            if check_humaneval_plus_local(code, problem):\n","                pass_found = True\n","                success_code = code\n","                break\n","\n","    if pass_found and len(samples) < MAX_SAMPLES:\n","        samples.extend([success_code] * (MAX_SAMPLES - len(samples)))\n","    elif len(samples) < MAX_SAMPLES:\n","        samples.extend([\"\"] * (MAX_SAMPLES - len(samples)))\n","\n","    generations[task_id] = samples\n","    tqdm.write(\n","        f\"[{idx}/{len(humaneval_plus_problems)}] \"\n","        f\"attempts={attempts}, pass_found={pass_found}, \"\n","        f\"time={time()-start:.1f}s\"\n","    )\n","\n","print(\"\\nüß™ Running evalplus enhanced tests...\")\n","results = evaluate(\n","    problems=humaneval_plus_problems,\n","    samples=generations,\n","    k=[1, 10],\n","    timeout=3,\n",")\n","\n","print(\"\\nüéØ TRUE HumanEval+ Results\")\n","print(f\"  ‚ñ∏ pass@1:  {results['pass@1']:.4f}\")\n","print(f\"  ‚ñ∏ pass@10: {results['pass@10']:.4f}\\n\")\n","\n","os.makedirs(\"results\", exist_ok=True)\n","with open(\"results/qwen_humaneval_plus_best_prompt.json\", \"w\") as f:\n","    json.dump(\n","        {\n","            \"pass@1\": float(results[\"pass@1\"]),\n","            \"pass@10\": float(results[\"pass@10\"]),\n","            \"best_prompt_key\": best_key,\n","            \"best_prompt_name\": best_name,\n","        },\n","        f,\n","        indent=2,\n","    )\n","print(\"üíæ Saved TRUE HumanEval+ results to results/qwen_humaneval_plus_best_prompt.json\")"],"metadata":{"id":"XfCbNDns7Ovs"},"id":"XfCbNDns7Ovs","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3de27163","outputId":"e75230ae-fb7d-4ad5-f980-009c9747517a"},"source":["from human_eval.data import read_problems\n","\n","# ---- Adapter functions: Convert HumanEval problem to MBPP-like entry ----\n","\n","def make_fake_entry_for_humaneval(problem: dict) -> dict:\n","    \"\"\"\n","    Create a fake MBPP-like entry from HumanEval problem.\n","    This allows us to reuse MBPP prompt functions.\n","\n","    get_signature() expects entry[\"code\"] to be a function definition line.\n","    We need to extract the 'def ...:' line from problem[\"prompt\"].\n","    \"\"\"\n","    # Extract the function signature (the 'def ...:' line) from problem[\"prompt\"]\n","    signature_line = \"\"\n","    for line in problem[\"prompt\"].strip().split(\"\\n\"):\n","        if line.strip().startswith(\"def \"):\n","            signature_line = line.strip()\n","            break\n","\n","    # If no 'def' line is found (shouldn't happen for HumanEval), fall back.\n","    if not signature_line:\n","        signature_line = problem[\"prompt\"].strip().split(\"\\n\")[0].strip()\n","\n","    # The get_signature function already adds the trailing colon if missing,\n","    # so we just need to provide the 'def ...' line.\n","    fake_entry = {\n","        \"code\": signature_line + \"\\n\",  # get_signature() will extract from this\n","        \"text\": problem.get(\"entry_point\", \"\"),  # Not directly used by prompt builder but good for compatibility\n","    }\n","    return fake_entry\n","\n","def build_task_text_from_humaneval(problem: dict) -> str:\n","    \"\"\"\n","    Extract task description from HumanEval problem.\n","    HumanEval doesn't have explicit \"text\" field, so we use the docstring.\n","    \"\"\"\n","    # Extract docstring from prompt (usually the second line)\n","    prompt_lines = problem[\"prompt\"].strip().split(\"\\n\")\n","    # Find the line that starts with 'def', and take everything after it as docstring/task text\n","    def_found = False\n","    docstring_lines = []\n","    for line in prompt_lines:\n","        if line.strip().startswith(\"def \"):\n","            def_found = True\n","            continue\n","        if def_found:\n","            docstring_lines.append(line)\n","\n","    if docstring_lines:\n","        docstring = \"\\n\".join(docstring_lines)\n","        # Remove quotes if present\n","        docstring = docstring.strip().strip('\"\"\"').strip(\"'''\").strip()\n","        return docstring\n","    return \"Complete the function\"  # Fallback\n","\n","# ==============================================================\n","# Start of definitions needed for best_prompt_fn (copied from earlier cells)\n","# ==============================================================\n","\n","HARD_RULE = (\n","    \"# You are a Python coding assistant.\\n\"\n","    \"# Only output valid Python code implementing the required function.\\n\"\n","    \"# Do NOT use markdown or ```.\\n\"\n","    \"# Do NOT print explanations or comments outside the function body.\\n\\n\"\n",")\n","\n","def get_signature(entry):\n","    \"\"\"\n","    e.g. 'def remove_first_and_last(s, ch):'\n","    \"\"\"\n","    first_line = entry[\"code\"].strip().split(\"\\n\")[0]\n","    sig = first_line.strip().rstrip(\":\") + \":\"\n","    return sig + \"\\n\"\n","\n","def build_core_prompt(task_text: str, entry) -> str:\n","    one_line_task = task_text.replace(\"\\n\", \" \")\n","    sig = get_signature(entry)\n","    core = (\n","        HARD_RULE +\n","        f\"# Task: {one_line_task}\\n\"\n","        f\"# Implement the following function to solve the task.\\n\\n\"\n","        f\"{sig}\"\n","    )\n","    return core\n","\n","CODE_EXAMPLE_1 = \"\"\"def factorial(n):\n","    if n == 0 or n == 1:\n","        return 1\n","    return n * factorial(n - 1)\n","\n","\"\"\"\n","\n","CODE_EXAMPLE_2 = \"\"\"def is_palindrome(s):\n","    s = s.lower().replace(\" \", \"\")\n","    return s == s[::-1]\n","\n","\"\"\"\n","\n","CODE_EXAMPLE_3 = \"\"\"def fibonacci(n):\n","    if n <= 0:\n","        return []\n","    elif n == 1:\n","        return [0]\n","    elif n == 2:\n","        return [0, 1]\n","    seq = [0, 1]\n","    for i in range(2, n):\n","        seq.append(seq[-1] + seq[-2])\n","    return seq\n","\n","\"\"\"\n","\n","CODE_EXAMPLE_4 = \"\"\"def find_max(lst):\n","    if not lst:\n","        return None\n","    m = lst[0]\n","    for x in lst[1:]:\n","        if x > m:\n","            m = x\n","    return m\n","\n","\"\"\"\n","\n","CODE_EXAMPLE_5 = \"\"\"def reverse_list(lst):\n","    i, j = 0, len(lst) - 1\n","    while i < j:\n","        lst[i], lst[j] = lst[j], lst[i]\n","        i += 1\n","        j -= 1\n","    return lst\n","\n","\"\"\"\n","\n","ALL_CODE_EXAMPLES = [\n","    CODE_EXAMPLE_1,\n","    CODE_EXAMPLE_2,\n","    CODE_EXAMPLE_3,\n","    CODE_EXAMPLE_4,\n","    CODE_EXAMPLE_5,\n","]\n","\n","\n","def prompt_baseline(task_text: str, entry) -> str:\n","    return build_core_prompt(task_text, entry)\n","\n","def prompt_0shot(task_text: str, entry) -> str:\n","    core = build_core_prompt(task_text, entry)\n","    return \"# Complete the function below.\\n\\n\" + core\n","\n","def prompt_1shot(task_text: str, entry) -> str:\n","    prefix = CODE_EXAMPLE_1\n","    core = build_core_prompt(task_text, entry)\n","    return prefix + \"\\n\" + core\n","\n","def prompt_3shot(task_text: str, entry) -> str:\n","    prefix = CODE_EXAMPLE_1 + CODE_EXAMPLE_2 + CODE_EXAMPLE_3\n","    core = build_core_prompt(task_text, entry)\n","    return prefix + \"\\n\" + core\n","\n","def prompt_5shot(task_text: str, entry) -> str:\n","    prefix = \"\".join(ALL_CODE_EXAMPLES)\n","    core = build_core_prompt(task_text, entry)\n","    return prefix + \"\\n\" + core\n","\n","MAIN_PROMPTS = {\n","    \"baseline\": (\"Baseline (task + signature)\", prompt_baseline),\n","    \"0shot\":   (\"0-shot (instruction + task + signature)\", prompt_0shot),\n","    \"1shot\":   (\"1-shot (code prefix + task + signature)\", prompt_1shot),\n","    \"3shot\":   (\"3-shot (code prefix + task + signature)\", prompt_3shot),\n","    \"5shot\":   (\"5-shot (code prefix + task + signature)\", prompt_5shot),\n","}\n","\n","# Use 5-shot as the best prompt (hardcoded based on MBPP results)\n","best_key = \"5shot\"\n","best_prompt_fn = MAIN_PROMPTS[best_key][1]\n","\n","# ==============================================================\n","# End of definitions needed for best_prompt_fn\n","# ==============================================================\n","\n","print(\"\\n--- Sample HumanEval Prompt ---\")\n","\n","# Get the first HumanEval problem as an example\n","humaneval_problems = read_problems()\n","sample_task_id = list(humaneval_problems.keys())[0]\n","sample_problem = humaneval_problems[sample_task_id]\n","\n","# Create a fake MBPP-like entry for the prompt function\n","fake_entry = make_fake_entry_for_humaneval(sample_problem)\n","task_text = build_task_text_from_humaneval(sample_problem)\n","\n","# Build the prompt using the best_prompt_fn\n","final_humaneval_prompt = best_prompt_fn(task_text, fake_entry)\n","\n","print(final_humaneval_prompt)\n","print(\"-----------------------------\")"],"id":"3de27163","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Sample HumanEval Prompt ---\n","def factorial(n):\n","    if n == 0 or n == 1:\n","        return 1\n","    return n * factorial(n - 1)\n","\n","def is_palindrome(s):\n","    s = s.lower().replace(\" \", \"\")\n","    return s == s[::-1]\n","\n","def fibonacci(n):\n","    if n <= 0:\n","        return []\n","    elif n == 1:\n","        return [0]\n","    elif n == 2:\n","        return [0, 1]\n","    seq = [0, 1]\n","    for i in range(2, n):\n","        seq.append(seq[-1] + seq[-2])\n","    return seq\n","\n","def find_max(lst):\n","    if not lst:\n","        return None\n","    m = lst[0]\n","    for x in lst[1:]:\n","        if x > m:\n","            m = x\n","    return m\n","\n","def reverse_list(lst):\n","    i, j = 0, len(lst) - 1\n","    while i < j:\n","        lst[i], lst[j] = lst[j], lst[i]\n","        i += 1\n","        j -= 1\n","    return lst\n","\n","\n","# You are a Python coding assistant.\n","# Only output valid Python code implementing the required function.\n","# Do NOT use markdown or ```.\n","# Do NOT print explanations or comments outside the function body.\n","\n","# Task: Check if in given list of numbers, are any two numbers closer to each other than     given threshold.     >>> has_close_elements([1.0, 2.0, 3.0], 0.5)     False     >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)     True\n","# Implement the following function to solve the task.\n","\n","def has_close_elements(numbers: List[float], threshold: float) -> bool:\n","\n","-----------------------------\n"]}]},{"cell_type":"code","source":["# Load HumanEval+ (if needed for report)\n","\n","# Ensure evalplus is installed\n","!pip install evalplus --upgrade -q\n","\n","import importlib\n","import sys\n","\n","# Clear all evalplus related modules from sys.modules to ensure a fresh import\n","for mod in list(sys.modules.keys()):\n","    if mod.startswith('evalplus'):\n","        del sys.modules[mod]\n","\n","# Re-import evalplus to get the latest version's API\n","import evalplus\n","\n","try:\n","    # Try to import from evalplus.data\n","    from evalplus.data import get_human_eval_plus # Corrected function name\n","    humaneval_plus_problems = get_human_eval_plus()\n","    print(f\"‚úÖ Loaded {len(humaneval_plus_problems)} HumanEval+ problems from evalplus.data\")\n","except ImportError:\n","    # If not found in evalplus.data, try directly from evalplus (or alternative location)\n","    try:\n","        # Some versions might have it directly under evalplus\n","        from evalplus import get_human_eval_plus # Corrected function name\n","        humaneval_plus_problems = get_human_eval_plus()\n","        print(f\"‚úÖ Loaded {len(humaneval_plus_problems)} HumanEval+ problems from evalplus\")\n","    except ImportError:\n","        # Fallback to human-eval base if evalplus+ specific problems can't be loaded\n","        from human_eval.data import read_problems\n","        humaneval_plus_problems = read_problems()\n","        print(f\"‚ö†Ô∏è  Could not find 'get_human_eval_plus' in evalplus library. Loaded {len(humaneval_plus_problems)} HumanEval problems instead.\")\n","\n","# Print dir(evalplus.data) and dir(evalplus) for inspection if needed\n","print(\"\\n--- Inspecting evalplus.data module ---\")\n","print(dir(evalplus.data))\n","print(\"\\n--- Inspecting evalplus module ---\")\n","print(dir(evalplus))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ljk9FuOz_NIN","outputId":"38fa0523-d54b-4270-ff35-d0397f3a4808"},"id":"ljk9FuOz_NIN","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Loaded 164 HumanEval+ problems from evalplus.data\n","\n","--- Inspecting evalplus.data module ---\n","['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'get_evalperf_data', 'get_human_eval_plus', 'get_human_eval_plus_hash', 'get_mbpp_plus', 'get_mbpp_plus_hash', 'humaneval', 'json', 'load_dataset', 'load_solutions', 'mbpp', 'utils', 'write_directory', 'write_jsonl']\n","\n","--- Inspecting evalplus module ---\n","['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '__version_tuple__', '_version', 'data']\n"]}]},{"cell_type":"code","source":["## Phase 3: InstructHumanEval evaluation"],"metadata":{"id":"7nhAElzyqYk6"},"id":"7nhAElzyqYk6","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load InstructHumanEval\n","# ---- Adapter functions: Convert InstructHumanEval problem to MBPP-like entry ----\n","# (These are needed even if HumanEval cell wasn't run after restarting runtime)\n","\n","def make_fake_entry_for_humaneval(problem: dict) -> dict:\n","    \"\"\"Create a fake MBPP-like entry from HumanEval problem.\"\"\"\n","    prompt_lines = problem[\"prompt\"].strip().split(\"\\n\")\n","    first_line = prompt_lines[0] if prompt_lines else \"\"\n","    fake_entry = {\n","        \"code\": first_line,\n","        \"text\": problem.get(\"instruction\", \"\"),\n","    }\n","    return fake_entry\n","\n","def build_task_text_from_humaneval(problem: dict) -> str:\n","    \"\"\"Extract task description from HumanEval problem.\"\"\"\n","    prompt_lines = problem[\"prompt\"].strip().split(\"\\n\")\n","    if len(prompt_lines) > 1:\n","        docstring = \"\\n\".join(prompt_lines[1:])\n","        docstring = docstring.strip().strip('\"\"\"').strip(\"'''\").strip()\n","        return docstring\n","    return \"Complete the function\"\n","try:\n","    from evalplus.data import get_instruct_humaneval\n","    instruct_humaneval_problems = get_instruct_humaneval()\n","    print(f\"‚úÖ Loaded {len(instruct_humaneval_problems)} InstructHumanEval problems\")\n","except ImportError:\n","    print(\"‚ö†Ô∏è  evalplus not installed. Install with: pip install evalplus\")\n","    instruct_humaneval_problems = None\n","\n","def check_instruct_humaneval(code: str, problem: dict) -> bool:\n","    \"\"\"Check InstructHumanEval using exec() - same as HumanEval but uses instruction.\"\"\"\n","    code_clean = extract_code_from_markdown(code)\n","    if not code_clean or len(code_clean) < 8:\n","        return False\n","\n","    # InstructHumanEval has \"instruction\" (natural language) and \"prompt\" (function signature)\n","    prompt_sig = problem[\"prompt\"]   # function signature\n","    test_code = problem[\"test\"]\n","\n","    # Avoid duplicating the signature if model echoed it\n","    if prompt_sig in code_clean:\n","        body = code_clean.replace(prompt_sig, \"\")\n","    else:\n","        body = code_clean\n","\n","    full = prompt_sig + body + \"\\n\" + test_code\n","    try:\n","        exec(full, {})\n","        return True\n","    except Exception:\n","        return False\n","\n","# Note: build_instruct_humaneval_prompt is no longer needed\n","# We now use the same prompt_fn from MBPP selection (via make_fake_entry_for_humaneval)\n","\n","def eval_instruct_humaneval(model, tokenizer, prompt_fn, calculate_pass10: bool = True):\n","    \"\"\"\n","    Evaluate InstructHumanEval using the best prompt function from MBPP selection.\n","\n","    Args:\n","        model: The model to evaluate\n","        tokenizer: The tokenizer\n","        prompt_fn: The best prompt function from MAIN_PROMPTS (takes task_text, entry)\n","        calculate_pass10: If True, also calculate pass@10 (requires 10 samples per problem)\n","    \"\"\"\n","    if instruct_humaneval_problems is None:\n","        print(\"‚ùå InstructHumanEval not loaded. Skipping.\")\n","        return None\n","\n","    correct_pass1 = 0\n","    correct_pass10 = 0\n","    total = len(instruct_humaneval_problems)\n","    n_samples = 10 if calculate_pass10 else 1\n","\n","    print(f\"üöÄ Evaluating InstructHumanEval with best prompt from MBPP selection\")\n","    print(f\"   Total problems: {total}\")\n","    if calculate_pass10:\n","        print(f\"   Generating {n_samples} samples per problem for pass@10 calculation\")\n","\n","    # Use tqdm for progress bar\n","    from tqdm.auto import tqdm\n","\n","    for i, (task_id, problem) in enumerate(tqdm(instruct_humaneval_problems.items(), desc=\"InstructHumanEval\")):\n","        # Create fake entry for prompt_fn (same as HumanEval)\n","        fake_entry = make_fake_entry_for_humaneval(problem)\n","        # For InstructHumanEval, use the instruction field as task text\n","        task_text = problem.get(\"instruction\", \"Complete the function\")\n","\n","        # Use the same prompt function as MBPP\n","        prompt = prompt_fn(task_text, fake_entry)\n","\n","        # Generate samples\n","        if calculate_pass10:\n","            full_outs = generate(model, tokenizer, prompt, max_new_tokens=2048, num_samples=n_samples)\n","            # Check each sample\n","            passed_samples = 0\n","            for full_out in full_outs:\n","                gen_part = strip_prompt(full_out, prompt)\n","                code = extract_code_from_markdown(gen_part)\n","                if check_instruct_humaneval(code, problem):\n","                    passed_samples += 1\n","\n","            # Pass@1: first sample passes\n","            if check_instruct_humaneval(extract_code_from_markdown(strip_prompt(full_outs[0], prompt)), problem):\n","                correct_pass1 += 1\n","\n","            # Pass@10: at least one sample passes (out of 10)\n","            if passed_samples > 0:\n","                correct_pass10 += 1\n","        else:\n","            # Only pass@1\n","            full_out = generate(model, tokenizer, prompt, max_new_tokens=2048, num_samples=1)\n","            gen_part = strip_prompt(full_out, prompt)\n","            code = extract_code_from_markdown(gen_part)\n","            if check_instruct_humaneval(code, problem):\n","                correct_pass1 += 1\n","\n","        # Update progress bar description with current accuracy\n","        if (i + 1) % 10 == 0:\n","            current_acc1 = correct_pass1 / (i + 1)\n","            if calculate_pass10:\n","                current_acc10 = correct_pass10 / (i + 1)\n","                tqdm.write(f\"  Progress: {i+1}/{total} ‚Äî pass@1={current_acc1:.2%}, pass@10={current_acc10:.2%}\")\n","            else:\n","                tqdm.write(f\"  Progress: {i+1}/{total} ‚Äî pass@1={current_acc1:.2%}\")\n","\n","    acc_pass1 = correct_pass1 / total\n","    results = {\n","        \"pass@1\": acc_pass1,\n","        \"pass@1_correct\": correct_pass1,\n","        \"pass@1_total\": total,\n","    }\n","\n","    if calculate_pass10:\n","        acc_pass10 = correct_pass10 / total\n","        results[\"pass@10\"] = acc_pass10\n","        results[\"pass@10_correct\"] = correct_pass10\n","        results[\"pass@10_total\"] = total\n","        print(f\"\\n‚úÖ InstructHumanEval pass@1: {acc_pass1:.4f} ({correct_pass1}/{total})\")\n","        print(f\"‚úÖ InstructHumanEval pass@10: {acc_pass10:.4f} ({correct_pass10}/{total})\")\n","    else:\n","        print(f\"\\n‚úÖ InstructHumanEval pass@1: {acc_pass1:.4f} ({correct_pass1}/{total})\")\n","\n","    # Auto shutdown GPU after evaluation (to save resources)\n","    import os\n","    if os.getenv(\"COLAB_GPU\") or torch.cuda.is_available():\n","        print(\"\\nüí§ Shutting down GPU to save resources...\")\n","        torch.cuda.empty_cache()\n","        print(\"   GPU cache cleared. GPU will be released when runtime ends.\")\n","\n","    return results\n","\n","# Run AFTER Phase 1, when best_prompt_fn is defined\n","# Running InstructHumanEval evaluation with best prompt from MBPP selection\n","# Using 5-shot (best config from MBPP: 0.3500 accuracy)\n","\n","# Use 5-shot as the best prompt (from MBPP results: 35/100 = 0.3500)\n","best_key = \"5shot\"\n","best_name = MAIN_PROMPTS[best_key][0]\n","best_prompt_fn = MAIN_PROMPTS[best_key][1]\n","\n","print(f\"‚úÖ Using best prompt from MBPP: {best_key} - {best_name}\")\n","print(f\"   (MBPP accuracy: 0.3500 (35/100))\")\n","\n","instruct_humaneval_results = eval_instruct_humaneval(\n","    model, tokenizer, best_prompt_fn, calculate_pass10=True\n",")\n","\n","if instruct_humaneval_results is not None:\n","    os.makedirs(\"results\", exist_ok=True)\n","    with open(\"results/qwen_instruct_humaneval_best_prompt.json\", \"w\") as f:\n","        json.dump({\n","            \"pass@1\": float(instruct_humaneval_results[\"pass@1\"]),\n","            \"pass@1_correct\": int(instruct_humaneval_results[\"pass@1_correct\"]),\n","            \"pass@1_total\": int(instruct_humaneval_results[\"pass@1_total\"]),\n","            \"pass@10\": float(instruct_humaneval_results.get(\"pass@10\", 0)),\n","            \"pass@10_correct\": int(instruct_humaneval_results.get(\"pass@10_correct\", 0)),\n","            \"pass@10_total\": int(instruct_humaneval_results.get(\"pass@10_total\", 0)),\n","            \"best_prompt_key\": best_key,\n","            \"best_prompt_name\": best_name,\n","        }, f, indent=2)\n","    print(\"üíæ Saved InstructHumanEval results to results/qwen_instruct_humaneval_best_prompt.json\")\n","\n","# Auto download result file (important: Colab files are lost when runtime disconnects)\n","try:\n","    from google.colab import files\n","    print(\"\\nüì• Auto-downloading InstructHumanEval results...\")\n","    files.download(\"results/qwen_instruct_humaneval_best_prompt.json\")\n","    print(\"‚úÖ InstructHumanEval results downloaded!\")\n","except ImportError:\n","    print(\"‚ö†Ô∏è  Not in Colab, skipping auto-download\")\n","except Exception as e:\n","    print(f\"‚ö†Ô∏è  Auto-download failed: {e}\")\n","    print(\"   Please manually download results/qwen_instruct_humaneval_best_prompt.json\")\n","\n","# Auto shutdown GPU after all evaluations complete\n","print(\"\\n\" + \"=\"*60)\n","print(\"üéâ All evaluations complete!\")\n","print(\"=\"*60)\n","\n","# Download all results as a zip file (including HumanEval+)\n","print(\"\\nüì¶ Creating and downloading all results as zip...\")\n","try:\n","    from google.colab import files\n","    import zipfile\n","    from pathlib import Path\n","    from datetime import datetime\n","\n","    results_dir = \"results\"\n","    result_files = list(Path(results_dir).glob(\"*.json\"))\n","\n","    if result_files:\n","        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","        zip_filename = f\"qwen_icl_evaluation_results_{timestamp}.zip\"\n","\n","        print(f\"   Found {len(result_files)} result file(s):\")\n","        for rf in sorted(result_files):\n","            print(f\"     - {rf.name}\")\n","\n","        with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n","            for result_file in result_files:\n","                zipf.write(result_file, result_file.name)\n","\n","        print(f\"\\nüì• Downloading {zip_filename}...\")\n","        files.download(zip_filename)\n","        print(\"‚úÖ All results downloaded as zip file!\")\n","        print(\"   Includes: MBPP, HumanEval, HumanEval+, InstructHumanEval\")\n","    else:\n","        print(\"‚ö†Ô∏è  No result files found\")\n","except Exception as e:\n","    print(f\"‚ö†Ô∏è  Auto-download failed: {e}\")\n","    print(\"   Please manually download results/ directory\")\n","\n","# Clean up GPU\n","print(\"\\nüí§ Cleaning up GPU resources...\")\n","torch.cuda.empty_cache()\n","print(\"‚úÖ GPU cache cleared\")\n","\n","# Auto disconnect runtime after all evaluations complete\n","print(\"\\n\" + \"=\"*60)\n","print(\"üåô All evaluations complete! Preparing to disconnect...\")\n","print(\"=\"*60)\n","print(\"‚úÖ All results have been downloaded.\")\n","print(\"üí§ Disconnecting runtime to save GPU resources...\")\n","\n","try:\n","    # Method 1: Try to use Colab's runtime management\n","    import os\n","    import time\n","\n","    # Wait a moment to ensure all downloads complete\n","    time.sleep(2)\n","\n","    # Method 2: Use JavaScript to trigger runtime disconnect (Colab-specific)\n","    try:\n","        from IPython.display import HTML, Javascript\n","        print(\"   Attempting to auto-disconnect runtime...\")\n","        # This JavaScript will try to disconnect the Colab runtime\n","        js_code = \"\"\"\n","        <script>\n","        // Try to disconnect Colab runtime\n","        if (typeof google !== 'undefined' && google.colab) {\n","            google.colab.kernel.proxyPort(0, {'cache': false});\n","        }\n","        // Alternative: Close the browser tab (may not work due to browser security)\n","        setTimeout(function() {\n","            window.close();\n","        }, 2000);\n","        </script>\n","        \"\"\"\n","        display(HTML(js_code))\n","        print(\"   ‚úÖ Disconnect signal sent\")\n","    except Exception as e:\n","        print(f\"   ‚ö†Ô∏è  JavaScript disconnect failed: {e}\")\n","\n","    # Method 3: Force runtime disconnect by killing the process\n","    print(\"   üí° If auto-disconnect doesn't work, runtime will auto-disconnect after ~90 min of inactivity\")\n","    print(\"   üí° Or manually: Runtime ‚Üí Disconnect and delete runtime\")\n","\n","    # Final attempt: Kill the Python process (will disconnect runtime)\n","    time.sleep(1)\n","    print(\"   üîÑ Attempting final disconnect...\")\n","    os._exit(0)  # This will terminate the runtime\n","\n","except Exception as e:\n","    print(f\"   ‚ö†Ô∏è  Auto-disconnect not available: {e}\")\n","    print(\"   üí° Please manually disconnect: Runtime ‚Üí Disconnect and delete runtime\")\n","    print(\"   üí° Or wait ~90 minutes for auto-disconnect\")\n","\n","print(\"\\nüò¥ Good night! All results are saved and downloaded.\")\n","print(\"   Runtime should disconnect automatically.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":545},"id":"dxet5nHUqaHd","outputId":"a6f024b3-49db-4625-9dc0-bec72fd8f577"},"id":"dxet5nHUqaHd","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚ö†Ô∏è  evalplus not installed. Install with: pip install evalplus\n","‚úÖ Using best prompt from MBPP: 5shot - 5-shot (code prefix + task + signature)\n","   (MBPP accuracy: 0.3500 (35/100))\n","‚ùå InstructHumanEval not loaded. Skipping.\n","\n","üì• Auto-downloading InstructHumanEval results...\n","‚ö†Ô∏è  Auto-download failed: Cannot find file: results/qwen_instruct_humaneval_best_prompt.json\n","   Please manually download results/qwen_instruct_humaneval_best_prompt.json\n","\n","============================================================\n","üéâ All evaluations complete!\n","============================================================\n","\n","üì¶ Creating and downloading all results as zip...\n","‚ö†Ô∏è  No result files found\n","\n","üí§ Cleaning up GPU resources...\n","‚úÖ GPU cache cleared\n","\n","============================================================\n","üåô All evaluations complete! Preparing to disconnect...\n","============================================================\n","‚úÖ All results have been downloaded.\n","üí§ Disconnecting runtime to save GPU resources...\n","   Attempting to auto-disconnect runtime...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","        <script>\n","        // Try to disconnect Colab runtime\n","        if (typeof google !== 'undefined' && google.colab) {\n","            google.colab.kernel.proxyPort(0, {'cache': false});\n","        }\n","        // Alternative: Close the browser tab (may not work due to browser security)\n","        setTimeout(function() {\n","            window.close();\n","        }, 2000);\n","        </script>\n","        "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["   ‚úÖ Disconnect signal sent\n","   üí° If auto-disconnect doesn't work, runtime will auto-disconnect after ~90 min of inactivity\n","   üí° Or manually: Runtime ‚Üí Disconnect and delete runtime\n"]}]},{"cell_type":"code","source":["# Step 1: Create 5-shot prefix file for MultiPL-E evaluation\n","# This will be used by bigcode-evaluation-harness\n","\n","print(\"üìù Creating 5-shot prefix file for MultiPL-E evaluation...\")\n","\n","# Create prompts directory\n","os.makedirs(\"prompts\", exist_ok=True)\n","\n","# Generate 5-shot pure code prefix (same as MBPP)\n","MBPP_PREFIX_5SHOT = \"\".join(ALL_CODE_EXAMPLES)\n","\n","# Save to file for bigcode-evaluation-harness\n","prefix_file = \"prompts/mbpp_5shot.txt\"\n","with open(prefix_file, \"w\") as f:\n","    f.write(MBPP_PREFIX_5SHOT)\n","\n","print(f\"‚úÖ Created {prefix_file}\")\n","print(f\"   Size: {len(MBPP_PREFIX_5SHOT)} characters\")\n","print(f\"   Contains: {len(ALL_CODE_EXAMPLES)} pure code examples\")\n","print(\"\\nüí° This prefix file will be used for MultiPL-E evaluation\")\n","# Install bigcode-evaluation-harness (if not already installed)\n","import os\n","\n","if not os.path.exists(\"bigcode-evaluation-harness\"):\n","    print(\"üì¶ Installing bigcode-evaluation-harness...\")\n","    print(\"   This will take a few minutes...\")\n","    os.system(\"git clone https://github.com/bigcode-project/bigcode-evaluation-harness.git\")\n","    os.chdir(\"bigcode-evaluation-harness\")\n","    os.system(\"pip install -e .\")\n","    os.chdir(\"..\")\n","    print(\"‚úÖ bigcode-evaluation-harness installed\")\n","else:\n","    print(\"‚úÖ bigcode-evaluation-harness already exists\")\n","    print(\"üí° If you need to reinstall, delete the directory first\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1dwu3V4JGUAk","outputId":"8d556365-bb59-492d-ef9b-98ab327fe6dc"},"id":"1dwu3V4JGUAk","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üìù Creating 5-shot prefix file for MultiPL-E evaluation...\n","‚úÖ Created prompts/mbpp_5shot.txt\n","   Size: 693 characters\n","   Contains: 5 pure code examples\n","\n","üí° This prefix file will be used for MultiPL-E evaluation\n","üì¶ Installing bigcode-evaluation-harness...\n","   This will take a few minutes...\n","‚úÖ bigcode-evaluation-harness installed\n"]}]},{"cell_type":"code","source":["# Re-clone bigcode-evaluation-harness from arthur900530 fork\n","# This will remove the existing directory and clone the fork\n","\n","import os\n","import subprocess\n","import shutil\n","\n","harness_dir = \"bigcode-evaluation-harness\"\n","fork_repo = \"https://github.com/arthur900530/bigcode-evaluation-harness.git\"\n","\n","print(\"üîÑ Re-cloning bigcode-evaluation-harness from arthur900530 fork...\")\n","\n","# Remove existing directory if it exists\n","if os.path.exists(harness_dir):\n","    print(f\"   Removing existing directory: {harness_dir}\")\n","    try:\n","        shutil.rmtree(harness_dir)\n","        print(\"   ‚úÖ Directory removed\")\n","    except Exception as e:\n","        print(f\"   ‚ö†Ô∏è  Error removing directory: {e}\")\n","        print(\"   Trying alternative method...\")\n","        # Try using system command as fallback\n","        if os.name == 'nt':  # Windows\n","            subprocess.run([\"rmdir\", \"/s\", \"/q\", harness_dir], shell=True, check=False)\n","        else:  # Linux/Mac\n","            subprocess.run([\"rm\", \"-rf\", harness_dir], check=False)\n","        print(\"   ‚úÖ Directory removed (alternative method)\")\n","\n","# Clone the fork\n","print(f\"\\nüì¶ Cloning from {fork_repo}...\")\n","try:\n","    result = subprocess.run(\n","        [\"git\", \"clone\", fork_repo, harness_dir],\n","        capture_output=True,\n","        text=True,\n","        check=True\n","    )\n","    print(\"‚úÖ Cloned successfully!\")\n","\n","    # Install the package\n","    print(\"\\nüì¶ Installing bigcode-evaluation-harness package...\")\n","    original_dir = os.getcwd()\n","    os.chdir(harness_dir)\n","\n","    try:\n","        result = subprocess.run(\n","            [sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \".\"],\n","            capture_output=True,\n","            text=True,\n","            check=True\n","        )\n","        print(\"‚úÖ Installed successfully\")\n","    except subprocess.CalledProcessError as e:\n","        print(f\"‚ö†Ô∏è  Warning: pip install failed: {e.stderr}\")\n","        print(\"   Continuing anyway...\")\n","\n","    os.chdir(original_dir)\n","\n","    print(\"\\n‚úÖ Setup complete! You can now run the C++ evaluation cell.\")\n","\n","except subprocess.CalledProcessError as e:\n","    print(f\"‚ùå Failed to clone: {e.stderr}\")\n","    print(\"   Please check your internet connection and try again.\")\n","except FileNotFoundError:\n","    print(\"‚ùå git not found. Please install git first.\")\n","except Exception as e:\n","    print(f\"‚ùå Error: {e}\")\n","    import traceback\n","    traceback.print_exc()"],"metadata":{"id":"7W1t-oe_nZMc"},"id":"7W1t-oe_nZMc","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setup: Install C++ Compiler (Required for MultiPL-E C++ evaluation)\n","# This cell checks for and installs C++ compiler if needed\n","\n","import os\n","import subprocess\n","import sys\n","import platform\n","\n","print(\"üîß Setting up C++ compiler for MultiPL-E evaluation...\")\n","print(f\"   Platform: {platform.system()}\")\n","\n","# Check if C++ compiler is available\n","cpp_compiler_found = False\n","compiler_name = None\n","\n","# Check for g++ (GNU C++ compiler)\n","try:\n","    result = subprocess.run(\n","        [\"g++\", \"--version\"],\n","        capture_output=True,\n","        text=True,\n","        timeout=5\n","    )\n","    if result.returncode == 0:\n","        cpp_compiler_found = True\n","        compiler_name = \"g++\"\n","        print(f\"‚úÖ Found {compiler_name}: {result.stdout.split(chr(10))[0]}\")\n","except (FileNotFoundError, subprocess.TimeoutExpired):\n","    pass\n","\n","# Check for cl (MSVC on Windows)\n","if not cpp_compiler_found:\n","    try:\n","        result = subprocess.run(\n","            [\"cl\"],\n","            capture_output=True,\n","            text=True,\n","            timeout=5\n","        )\n","        if \"Microsoft\" in result.stderr or \"Microsoft\" in result.stdout:\n","            cpp_compiler_found = True\n","            compiler_name = \"cl (MSVC)\"\n","            print(f\"‚úÖ Found {compiler_name}\")\n","    except (FileNotFoundError, subprocess.TimeoutExpired):\n","        pass\n","\n","# Install compiler if not found (Linux/Colab only)\n","if not cpp_compiler_found:\n","    if platform.system() == \"Linux\" or os.path.exists(\"/etc/debian_version\"):\n","        print(\"üì¶ Installing C++ compiler (build-essential g++)...\")\n","        try:\n","            result = subprocess.run(\n","                [\"apt-get\", \"update\", \"-qq\"],\n","                capture_output=True,\n","                text=True,\n","                timeout=60\n","            )\n","            result = subprocess.run(\n","                [\"apt-get\", \"install\", \"-y\", \"-qq\", \"build-essential\", \"g++\"],\n","                capture_output=True,\n","                text=True,\n","                timeout=120\n","            )\n","            if result.returncode == 0:\n","                print(\"‚úÖ C++ compiler installed successfully\")\n","                # Verify installation\n","                result = subprocess.run(\n","                    [\"g++\", \"--version\"],\n","                    capture_output=True,\n","                    text=True,\n","                    timeout=5\n","                )\n","                if result.returncode == 0:\n","                    print(f\"   Version: {result.stdout.split(chr(10))[0]}\")\n","                    cpp_compiler_found = True\n","        except (FileNotFoundError, subprocess.TimeoutExpired, subprocess.CalledProcessError) as e:\n","            print(f\"‚ö†Ô∏è  Could not install C++ compiler automatically: {e}\")\n","            print(\"   Please install manually:\")\n","            print(\"   - Linux: sudo apt-get install build-essential g++\")\n","            print(\"   - Windows: Install Visual Studio Build Tools or MinGW\")\n","            print(\"   - macOS: xcode-select --install\")\n","    elif platform.system() == \"Windows\":\n","        print(\"‚ö†Ô∏è  C++ compiler not found on Windows\")\n","        print(\"   Please install one of the following:\")\n","        print(\"   1. Visual Studio Build Tools: https://visualstudio.microsoft.com/downloads/\")\n","        print(\"   2. MinGW-w64: https://www.mingw-w64.org/downloads/\")\n","        print(\"   3. Or use WSL (Windows Subsystem for Linux)\")\n","    else:\n","        print(\"‚ö†Ô∏è  C++ compiler not found\")\n","        print(\"   Please install a C++ compiler manually for your platform\")\n","\n","if cpp_compiler_found:\n","    print(\"\\n‚úÖ C++ compiler setup complete! Ready for MultiPL-E C++ evaluation.\")\n","else:\n","    print(\"\\n‚ö†Ô∏è  Warning: C++ compiler not available. MultiPL-E C++ evaluation may fail.\")\n","    print(\"   The evaluation will still attempt to run, but code execution will fail.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ofalBxZxGb1A","outputId":"125e48f0-ad50-47fa-e322-6e08a057e205"},"id":"ofalBxZxGb1A","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîß Setting up C++ compiler for MultiPL-E evaluation...\n","   Platform: Linux\n","‚úÖ Found g++: g++ (Ubuntu 11.4.0-1ubuntu1~22.04.2) 11.4.0\n","\n","‚úÖ C++ compiler setup complete! Ready for MultiPL-E C++ evaluation.\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/arthur900530/bigcode-evaluation-harness.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Xfl69NmnDLn","outputId":"57eb3a42-dafc-45e1-c925-c5174e6f7686"},"id":"4Xfl69NmnDLn","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'bigcode-evaluation-harness' already exists and is not an empty directory.\n"]}]},{"cell_type":"code","source":["# MultiPL-E C++ Evaluation - Fixed Version\n","# This will automatically install bigcode-evaluation-harness and run the evaluation\n","\n","import os\n","import subprocess\n","import sys\n","\n","# Fixed parameters\n","MODEL = \"Qwen/Qwen2.5-Coder-3B-Instruct\"\n","\n","# Task name detection:\n","# - 'multiple-cpp': Standard name (used in newer/older versions)\n","# - 'multiple-cljcpp': Alternative name (used in some versions, but has a bug mapping to humaneval-cljcpp)\n","# We'll try both and use whichever works\n","TASK_OPTIONS = [\"multiple-cpp\", \"multiple-cljcpp\"]\n","TASK = None  # Will be determined below\n","TOP_P = \"0.95\"\n","TEMPERATURE = \"0.2\"\n","DO_SAMPLE = \"True\"\n","N_SAMPLES = \"10\"\n","BATCH_SIZE = \"10\"\n","MAX_LENGTH = \"2048\"\n","MAX_LENGTH_GENERATION = \"2048\"\n","SEED = \"11667\"\n","\n","print(\"üöÄ Evaluating MultiPL-E C++...\")\n","print(\"   This will take ~30-60 minutes...\")\n","print(\"   Using 5-shot prompt from MBPP selection\")\n","\n","# Read the 5-shot prefix\n","with open(\"prompts/mbpp_5shot.txt\", \"r\", encoding=\"utf-8\") as f:\n","    prefix_content = f.read()\n","\n","# Check and install bigcode-evaluation-harness if needed\n","original_dir = os.getcwd()\n","harness_dir = \"bigcode-evaluation-harness\"\n","\n","if not os.path.exists(harness_dir):\n","    print(f\"\\nüì¶ Installing bigcode-evaluation-harness...\")\n","    print(\"   This will take a few minutes...\")\n","    try:\n","        # Try official repo first, fallback to fork if needed\n","        repo_url = \"https://github.com/bigcode-project/bigcode-evaluation-harness.git\"\n","        result = subprocess.run(\n","            [\"git\", \"clone\", repo_url],\n","            capture_output=True,\n","            text=True,\n","            check=True\n","        )\n","        print(\"‚úÖ Cloned successfully\")\n","    except subprocess.CalledProcessError as e:\n","        print(f\"‚ö†Ô∏è  Official repo failed, trying fork...\")\n","        try:\n","            repo_url = \"https://github.com/arthur900530/bigcode-evaluation-harness.git\"\n","            result = subprocess.run(\n","                [\"git\", \"clone\", repo_url],\n","                capture_output=True,\n","                text=True,\n","                check=True\n","            )\n","            print(\"‚úÖ Cloned from fork successfully\")\n","        except subprocess.CalledProcessError as e2:\n","            print(f\"‚ùå Failed to clone: {e2.stderr}\")\n","            raise RuntimeError(\"Failed to install bigcode-evaluation-harness\")\n","    except FileNotFoundError:\n","        print(\"‚ùå git not found. Please install git first.\")\n","        raise RuntimeError(\"git is required but not found\")\n","\n","    # Install the package\n","    os.chdir(harness_dir)\n","    try:\n","        print(\"   Installing bigcode-evaluation-harness package...\")\n","        result = subprocess.run(\n","            [sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \".\"],\n","            capture_output=True,\n","            text=True,\n","            check=True\n","        )\n","        print(\"‚úÖ Installed successfully\")\n","    except subprocess.CalledProcessError as e:\n","        print(f\"‚ö†Ô∏è  Warning: pip install failed: {e.stderr}\")\n","        print(\"   Continuing anyway...\")\n","\n","    # Install bitsandbytes (required for some models)\n","    try:\n","        print(\"   Installing bitsandbytes>=0.41.0...\")\n","        result = subprocess.run(\n","            [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"bitsandbytes>=0.41.0\"],\n","            capture_output=True,\n","            text=True,\n","            check=True\n","        )\n","        print(\"‚úÖ bitsandbytes installed\")\n","    except subprocess.CalledProcessError as e:\n","        print(f\"‚ö†Ô∏è  Warning: bitsandbytes install failed: {e.stderr}\")\n","        print(\"   Continuing anyway (may not be needed for CPU-only)...\")\n","\n","    os.chdir(original_dir)\n","else:\n","    print(\"‚úÖ bigcode-evaluation-harness already exists\")\n","    # Try to update to latest version (might fix task name issues)\n","    print(\"   Attempting to update to latest version...\")\n","    try:\n","        os.chdir(harness_dir)\n","        update_result = subprocess.run(\n","            [\"git\", \"pull\"],\n","            capture_output=True,\n","            text=True,\n","            timeout=30\n","        )\n","        if update_result.returncode == 0:\n","            print(\"   ‚úÖ Updated to latest version\")\n","            # Reinstall in case dependencies changed\n","            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \".\"], check=False)\n","        else:\n","            print(\"   ‚ö†Ô∏è  Update failed or already up to date\")\n","        os.chdir(original_dir)\n","    except Exception as e:\n","        print(f\"   ‚ö†Ô∏è  Could not update: {e}\")\n","        os.chdir(original_dir)\n","\n","# Save prefix to a file in bigcode-evaluation-harness directory\n","os.makedirs(f\"{harness_dir}/prompts\", exist_ok=True)\n","prefix_file = f\"{harness_dir}/prompts/mbpp_5shot.txt\"\n","with open(prefix_file, \"w\", encoding=\"utf-8\") as f:\n","    f.write(prefix_content)\n","\n","# Change to bigcode-evaluation-harness directory\n","os.chdir(harness_dir)\n","\n","# Check if main.py exists\n","if not os.path.exists(\"main.py\"):\n","    print(f\"‚ùå Error: main.py not found in {os.getcwd()}\")\n","    print(\"   Listing directory contents:\")\n","    for item in os.listdir(\".\"):\n","        print(f\"     - {item}\")\n","    os.chdir(original_dir)\n","    raise FileNotFoundError(f\"main.py not found in {harness_dir}. Please check the installation.\")\n","\n","print(f\"\\n‚úÖ Found main.py at: {os.path.join(os.getcwd(), 'main.py')}\")\n","\n","# Try to detect which C++ task name is available\n","print(\"\\nüîç Detecting available C++ task name...\")\n","for task_option in TASK_OPTIONS:\n","    try:\n","        # Quick test to see if task is valid\n","        test_result = subprocess.run(\n","            [sys.executable, \"main.py\", \"--tasks\", task_option, \"--limit\", \"1\", \"--model\", MODEL],\n","            capture_output=True,\n","            text=True,\n","            timeout=10\n","        )\n","        if \"invalid choice\" not in test_result.stderr.lower() and test_result.returncode != 2:\n","            TASK = task_option\n","            print(f\"   ‚úÖ Found working task: {TASK}\")\n","            break\n","    except:\n","        continue\n","\n","# If still not found, check help output\n","if TASK is None:\n","    try:\n","        help_result = subprocess.run(\n","            [sys.executable, \"main.py\", \"--tasks\", \"invalid_task_for_help\"],\n","            capture_output=True,\n","            text=True,\n","            timeout=5\n","        )\n","        # Look for cpp-related tasks in error message\n","        if \"multiple-cpp\" in help_result.stderr:\n","            TASK = \"multiple-cpp\"\n","            print(f\"   ‚úÖ Found task in help: {TASK}\")\n","        elif \"multiple-cljcpp\" in help_result.stderr:\n","            TASK = \"multiple-cljcpp\"\n","            print(f\"   ‚úÖ Found task in help: {TASK}\")\n","    except:\n","        pass\n","\n","if TASK is None:\n","    TASK = \"multiple-cpp\"\n","    print(f\"   ‚ö†Ô∏è  Could not auto-detect, using default: {TASK}\")\n","\n","print(f\"\\nüí° Using task: {TASK}\")\n","\n","\n","# Build the command - pass prefix content directly (not using bash $(cat))\n","cmd = [\n","    sys.executable, \"main.py\",\n","    \"--model\", MODEL,\n","    \"--tasks\", TASK,\n","    \"--top_p\", TOP_P,\n","    \"--temperature\", TEMPERATURE,\n","    \"--do_sample\", DO_SAMPLE,\n","    \"--n_samples\", N_SAMPLES,\n","    \"--batch_size\", BATCH_SIZE,\n","    \"--max_length\", MAX_LENGTH,\n","    \"--max_length_generation\", MAX_LENGTH_GENERATION,\n","    \"--allow_code_execution\",\n","    \"--save_generations\",\n","    \"--prefix\", prefix_content,  # Pass prefix content directly\n","    \"--seed\", SEED\n","]\n","\n","print(f\"\\nüìù Command: python main.py --model {MODEL} --tasks {TASK} ...\")\n","print(f\"   Prefix length: {len(prefix_content)} characters\")\n","print(f\"   Working directory: {os.getcwd()}\")\n","print(\"\\n‚è≥ Starting evaluation (this will take 30-60 minutes)...\\n\")\n","\n","try:\n","    # Run the command and show output in real-time\n","    process = subprocess.Popen(\n","        cmd,\n","        stdout=subprocess.PIPE,\n","        stderr=subprocess.STDOUT,\n","        universal_newlines=True,\n","        bufsize=1\n","    )\n","\n","    # Print output line by line\n","    for line in process.stdout:\n","        print(line, end='')\n","\n","    process.wait()\n","\n","    if process.returncode == 0:\n","        print(\"\\n‚úÖ C++ evaluation completed successfully!\")\n","    else:\n","        print(f\"\\n‚ùå Evaluation failed with return code {process.returncode}\")\n","        # If task name error, show available tasks\n","        if \"invalid choice\" in str(process.returncode) or \"error\" in str(process.returncode).lower():\n","            print(\"\\nüí° Checking available tasks...\")\n","            try:\n","                help_result = subprocess.run(\n","                    [sys.executable, \"main.py\", \"--tasks\", \"invalid_task_for_help\"],\n","                    capture_output=True,\n","                    text=True,\n","                    timeout=5\n","                )\n","                # Extract task list from error message\n","                if \"choose from\" in help_result.stderr:\n","                    tasks_line = help_result.stderr.split(\"choose from\")[-1]\n","                    cpp_tasks = [t for t in tasks_line.split(\",\") if \"cpp\" in t.lower()]\n","                    if cpp_tasks:\n","                        print(f\"   Found C++ related tasks: {cpp_tasks}\")\n","                        print(f\"   Try using one of these instead of '{TASK}'\")\n","            except:\n","                pass\n","\n","except Exception as e:\n","    print(f\"\\n‚ùå Error running evaluation: {e}\")\n","    import traceback\n","    traceback.print_exc()\n","    # If it's a task name error, provide helpful message\n","    if \"invalid choice\" in str(e).lower() or \"not found\" in str(e).lower():\n","        print(\"\\nüí° Tip: The task name might be incorrect.\")\n","        print(\"   Available dataset configs include: humaneval-cpp\")\n","        print(\"   You may need to:\")\n","        print(\"   1. Update bigcode-evaluation-harness: cd bigcode-evaluation-harness && git pull\")\n","        print(\"   2. Or check available tasks: python main.py --tasks help\")\n","finally:\n","    os.chdir(original_dir)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eID1dj3zmUgW","outputId":"33549684-741b-4b31-b3b0-ca016fc933c6"},"id":"eID1dj3zmUgW","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üöÄ Evaluating MultiPL-E C++...\n","   This will take ~30-60 minutes...\n","   Using 5-shot prompt from MBPP selection\n","‚úÖ bigcode-evaluation-harness already exists\n","   Attempting to update to latest version...\n","   ‚úÖ Updated to latest version\n","\n","‚úÖ Found main.py at: /content/bigcode-evaluation-harness/main.py\n","\n","üîç Detecting available C++ task name...\n","   ‚ö†Ô∏è  Could not auto-detect, using default: multiple-cpp\n","\n","üí° Using task: multiple-cpp\n","\n","üìù Command: python main.py --model Qwen/Qwen2.5-Coder-3B-Instruct --tasks multiple-cpp ...\n","   Prefix length: 693 characters\n","   Working directory: /content/bigcode-evaluation-harness\n","\n","‚è≥ Starting evaluation (this will take 30-60 minutes)...\n","\n","2025-11-29 03:29:22.573002: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1764386962.594237   14491 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1764386962.600732   14491 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1764386962.616922   14491 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1764386962.616952   14491 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1764386962.616954   14491 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1764386962.616956   14491 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","Selected Tasks: ['multiple-cpp']\n","Loading model in fp32\n","\n","Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\n","Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  1.18s/it]\n","Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.52it/s]\n","Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.36it/s]\n","\n","Generating test split:   0%|          | 0/161 [00:00<?, ? examples/s]\n","Generating test split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 161/161 [00:00<00:00, 3337.52 examples/s]\n","number of problems for this task is 161\n","\n","  0%|          | 0/161 [00:00<?, ?it/s]\n","  1%|          | 1/161 [00:10<26:57, 10.11s/it]\n","  1%|          | 2/161 [00:27<37:56, 14.32s/it]\n","  2%|‚ñè         | 3/161 [00:32<26:11,  9.94s/it]\n","  2%|‚ñè         | 4/161 [00:39<22:52,  8.74s/it]\n","  3%|‚ñé         | 5/161 [00:48<23:24,  9.01s/it]\n","  4%|‚ñé         | 6/161 [01:06<31:03, 12.02s/it]\n","  4%|‚ñç         | 7/161 [01:21<33:36, 13.09s/it]\n","  5%|‚ñç         | 8/161 [01:30<29:35, 11.60s/it]\n","  6%|‚ñå         | 9/161 [01:37<25:54, 10.23s/it]\n","  6%|‚ñå         | 10/161 [01:49<26:58, 10.72s/it]\n","  7%|‚ñã         | 11/161 [02:08<33:23, 13.36s/it]\n","  7%|‚ñã         | 12/161 [02:16<29:04, 11.71s/it]\n","  8%|‚ñä         | 13/161 [02:25<26:51, 10.89s/it]\n","  9%|‚ñä         | 14/161 [02:30<22:29,  9.18s/it]\n","  9%|‚ñâ         | 15/161 [02:37<20:25,  8.40s/it]\n"," 10%|‚ñâ         | 16/161 [02:44<19:10,  7.94s/it]\n"," 11%|‚ñà         | 17/161 [02:49<17:18,  7.21s/it]\n"," 11%|‚ñà         | 18/161 [03:02<21:05,  8.85s/it]\n"," 12%|‚ñà‚ñè        | 19/161 [03:09<19:47,  8.36s/it]\n"," 12%|‚ñà‚ñè        | 20/161 [03:33<30:51, 13.13s/it]\n"," 13%|‚ñà‚ñé        | 21/161 [03:51<33:41, 14.44s/it]\n"," 14%|‚ñà‚ñé        | 22/161 [04:06<34:21, 14.83s/it]\n"," 14%|‚ñà‚ñç        | 23/161 [04:14<29:13, 12.71s/it]\n"," 15%|‚ñà‚ñç        | 24/161 [04:24<27:04, 11.86s/it]\n"," 16%|‚ñà‚ñå        | 25/161 [04:32<24:09, 10.66s/it]\n"," 16%|‚ñà‚ñå        | 26/161 [04:42<23:36, 10.49s/it]\n"," 17%|‚ñà‚ñã        | 27/161 [04:51<22:35, 10.12s/it]\n"," 17%|‚ñà‚ñã        | 28/161 [04:58<20:29,  9.25s/it]\n"," 18%|‚ñà‚ñä        | 29/161 [05:03<17:29,  7.95s/it]\n"," 19%|‚ñà‚ñä        | 30/161 [05:11<17:13,  7.89s/it]\n"," 19%|‚ñà‚ñâ        | 31/161 [05:18<16:40,  7.70s/it]\n"," 20%|‚ñà‚ñâ        | 32/161 [05:32<20:16,  9.43s/it]\n"," 20%|‚ñà‚ñà        | 33/161 [05:51<26:10, 12.27s/it]\n"," 21%|‚ñà‚ñà        | 34/161 [05:56<21:45, 10.28s/it]\n"," 22%|‚ñà‚ñà‚ñè       | 35/161 [06:04<19:40,  9.37s/it]\n"," 22%|‚ñà‚ñà‚ñè       | 36/161 [06:13<19:37,  9.42s/it]\n"," 23%|‚ñà‚ñà‚ñé       | 37/161 [06:27<21:56, 10.62s/it]\n"," 24%|‚ñà‚ñà‚ñé       | 38/161 [06:37<21:20, 10.41s/it]\n"," 24%|‚ñà‚ñà‚ñç       | 39/161 [06:53<24:54, 12.25s/it]\n"," 25%|‚ñà‚ñà‚ñç       | 40/161 [07:05<24:29, 12.14s/it]\n"," 25%|‚ñà‚ñà‚ñå       | 41/161 [07:11<20:42, 10.35s/it]\n"," 26%|‚ñà‚ñà‚ñå       | 42/161 [07:20<19:32,  9.85s/it]\n"," 27%|‚ñà‚ñà‚ñã       | 43/161 [07:27<17:42,  9.01s/it]\n"," 27%|‚ñà‚ñà‚ñã       | 44/161 [07:37<18:16,  9.37s/it]\n"," 28%|‚ñà‚ñà‚ñä       | 45/161 [07:54<22:21, 11.56s/it]\n"," 29%|‚ñà‚ñà‚ñä       | 46/161 [08:03<20:39, 10.78s/it]\n"," 29%|‚ñà‚ñà‚ñâ       | 47/161 [08:09<18:04,  9.51s/it]\n"," 30%|‚ñà‚ñà‚ñâ       | 48/161 [08:24<20:46, 11.03s/it]\n"," 30%|‚ñà‚ñà‚ñà       | 49/161 [08:35<20:41, 11.08s/it]\n"," 31%|‚ñà‚ñà‚ñà       | 50/161 [08:40<17:13,  9.31s/it]\n"," 32%|‚ñà‚ñà‚ñà‚ñè      | 51/161 [09:47<48:55, 26.69s/it]\n"," 32%|‚ñà‚ñà‚ñà‚ñè      | 52/161 [09:53<37:13, 20.49s/it]\n"," 33%|‚ñà‚ñà‚ñà‚ñé      | 53/161 [10:03<31:03, 17.25s/it]\n"," 34%|‚ñà‚ñà‚ñà‚ñé      | 54/161 [10:12<26:13, 14.71s/it]\n"," 34%|‚ñà‚ñà‚ñà‚ñç      | 55/161 [10:23<23:48, 13.48s/it]\n"," 35%|‚ñà‚ñà‚ñà‚ñç      | 56/161 [10:36<23:24, 13.38s/it]\n"," 35%|‚ñà‚ñà‚ñà‚ñå      | 57/161 [10:54<25:46, 14.87s/it]\n"," 36%|‚ñà‚ñà‚ñà‚ñå      | 58/161 [11:00<20:51, 12.15s/it]\n"," 37%|‚ñà‚ñà‚ñà‚ñã      | 59/161 [11:08<18:49, 11.08s/it]\n"," 37%|‚ñà‚ñà‚ñà‚ñã      | 60/161 [11:16<16:39,  9.89s/it]\n"," 38%|‚ñà‚ñà‚ñà‚ñä      | 61/161 [11:29<18:07, 10.87s/it]\n"," 39%|‚ñà‚ñà‚ñà‚ñä      | 62/161 [11:40<18:18, 11.09s/it]\n"," 39%|‚ñà‚ñà‚ñà‚ñâ      | 63/161 [11:50<17:13, 10.54s/it]\n"," 40%|‚ñà‚ñà‚ñà‚ñâ      | 64/161 [11:57<15:17,  9.45s/it]\n"," 40%|‚ñà‚ñà‚ñà‚ñà      | 65/161 [12:14<19:06, 11.94s/it]\n"," 41%|‚ñà‚ñà‚ñà‚ñà      | 66/161 [12:34<22:24, 14.15s/it]\n"," 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 67/161 [12:46<21:33, 13.76s/it]\n"," 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 68/161 [12:59<20:49, 13.43s/it]\n"," 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 69/161 [13:08<18:31, 12.08s/it]\n"," 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 70/161 [13:28<21:57, 14.48s/it]\n"," 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 71/161 [13:40<20:32, 13.69s/it]\n"," 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 72/161 [13:59<22:34, 15.22s/it]\n"," 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 73/161 [14:08<19:55, 13.59s/it]\n"," 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 74/161 [14:20<18:51, 13.01s/it]\n"," 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 75/161 [14:26<15:24, 10.75s/it]\n"," 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 76/161 [14:37<15:28, 10.92s/it]\n"," 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 77/161 [14:46<14:40, 10.48s/it]\n"," 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 78/161 [14:58<15:03, 10.88s/it]\n"," 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 79/161 [15:41<27:49, 20.36s/it]\n"," 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 80/161 [15:49<22:35, 16.73s/it]\n"," 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 81/161 [16:00<19:55, 14.94s/it]\n"," 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 82/161 [16:09<17:22, 13.19s/it]\n"," 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 83/161 [16:16<14:56, 11.49s/it]\n"," 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 84/161 [16:26<13:57, 10.88s/it]\n"," 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 85/161 [16:57<21:23, 16.89s/it]\n"," 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 86/161 [17:12<20:28, 16.38s/it]\n"," 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 87/161 [17:25<19:09, 15.54s/it]\n"," 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 88/161 [17:43<19:32, 16.07s/it]\n"," 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 89/161 [17:55<17:44, 14.78s/it]\n"," 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 90/161 [18:07<16:30, 13.95s/it]\n"," 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 91/161 [18:32<20:26, 17.52s/it]\n"," 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 92/161 [18:55<21:50, 19.00s/it]\n"," 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 93/161 [19:14<21:28, 18.94s/it]\n"," 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 94/161 [19:39<23:23, 20.95s/it]\n"," 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 95/161 [19:45<18:06, 16.46s/it]\n"," 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 96/161 [19:57<16:11, 14.95s/it]\n"," 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 97/161 [20:08<14:51, 13.93s/it]\n"," 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 98/161 [20:19<13:37, 12.97s/it]\n"," 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 99/161 [20:26<11:42, 11.32s/it]\n"," 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 100/161 [20:40<12:12, 12.02s/it]\n"," 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 101/161 [20:55<12:45, 12.75s/it]\n"," 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 102/161 [21:08<12:50, 13.06s/it]\n"," 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 103/161 [21:38<17:25, 18.02s/it]\n"," 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 104/161 [21:47<14:37, 15.39s/it]\n"," 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 105/161 [22:04<14:49, 15.89s/it]\n"," 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 106/161 [22:21<14:42, 16.04s/it]\n"," 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 107/161 [22:36<14:10, 15.75s/it]\n"," 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 108/161 [22:58<15:33, 17.62s/it]\n"," 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 109/161 [23:15<15:04, 17.39s/it]\n"," 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 110/161 [23:29<14:00, 16.49s/it]\n"," 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 111/161 [23:50<14:54, 17.89s/it]\n"," 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 112/161 [24:00<12:41, 15.53s/it]\n"," 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 113/161 [24:13<11:44, 14.67s/it]\n"," 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 114/161 [24:24<10:46, 13.76s/it]\n"," 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 115/161 [24:41<11:15, 14.67s/it]\n"," 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 116/161 [24:55<10:54, 14.54s/it]\n"," 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 117/161 [25:13<11:15, 15.35s/it]\n"," 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 118/161 [25:23<09:57, 13.90s/it]\n"," 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 119/161 [25:32<08:33, 12.22s/it]\n"," 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 120/161 [25:42<07:58, 11.68s/it]\n"," 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 121/161 [25:59<08:57, 13.43s/it]\n"," 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 122/161 [26:51<16:07, 24.82s/it]\n"," 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 123/161 [27:17<16:00, 25.27s/it]\n"," 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 124/161 [27:32<13:34, 22.03s/it]\n"," 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 125/161 [28:00<14:25, 24.05s/it]\n"," 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 126/161 [28:15<12:25, 21.31s/it]\n"," 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 127/161 [29:43<23:23, 41.28s/it]\n"," 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 128/161 [34:12<1:00:13, 109.51s/it]\n"," 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 129/161 [34:21<42:23, 79.50s/it]   \n"," 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 130/161 [34:35<30:54, 59.81s/it]\n"," 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 131/161 [34:44<22:11, 44.39s/it]\n"," 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 132/161 [35:01<17:28, 36.16s/it]\n"," 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 133/161 [35:10<13:08, 28.17s/it]\n"," 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 134/161 [35:32<11:46, 26.16s/it]\n"," 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 135/161 [35:51<10:26, 24.11s/it]\n"," 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 136/161 [36:04<08:42, 20.91s/it]\n"," 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 137/161 [36:10<06:32, 16.35s/it]\n"," 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 138/161 [36:28<06:24, 16.73s/it]\n"," 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 139/161 [37:01<07:58, 21.77s/it]\n"," 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 140/161 [37:13<06:35, 18.85s/it]\n"," 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 141/161 [37:27<05:47, 17.37s/it]\n"," 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 142/161 [37:51<06:07, 19.34s/it]\n"," 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 143/161 [38:19<06:33, 21.84s/it]\n"," 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 144/161 [38:32<05:28, 19.31s/it]\n"," 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 145/161 [38:50<05:00, 18.81s/it]\n"," 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 146/161 [39:16<05:15, 21.00s/it]\n"," 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 147/161 [39:32<04:32, 19.47s/it]\n"," 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 148/161 [39:44<03:43, 17.22s/it]\n"," 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 149/161 [39:53<02:57, 14.75s/it]\n"," 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 150/161 [40:03<02:27, 13.37s/it]\n"," 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 151/161 [40:22<02:30, 15.02s/it]\n"," 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 152/161 [40:33<02:03, 13.74s/it]\n"," 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 153/161 [40:43<01:42, 12.84s/it]\n"," 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 154/161 [41:02<01:41, 14.53s/it]\n"," 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 155/161 [41:14<01:22, 13.82s/it]\n"," 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 156/161 [41:28<01:08, 13.74s/it]\n"," 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 157/161 [41:37<00:50, 12.60s/it]\n"," 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 158/161 [41:56<00:42, 14.30s/it]\n"," 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 159/161 [42:09<00:27, 13.94s/it]\n"," 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 160/161 [42:24<00:14, 14.30s/it]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 161/161 [42:33<00:00, 12.85s/it]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 161/161 [42:33<00:00, 15.86s/it]\n","generations were saved at generations_multiple-cpp.json\n","Evaluating generations...\n","Saved 161 problems in /tmp for evaluation, each problem has 10 completions\n","\n","  0%|          | 0/161 [00:00<?, ?it/s]\n","  1%|          | 1/161 [00:02<05:37,  2.11s/it]\n","  1%|          | 2/161 [00:04<05:45,  2.17s/it]\n","  2%|‚ñè         | 3/161 [00:05<04:55,  1.87s/it]\n","  2%|‚ñè         | 4/161 [00:07<04:37,  1.77s/it]\n","  3%|‚ñé         | 5/161 [00:09<05:00,  1.93s/it]\n","  4%|‚ñé         | 6/161 [00:11<04:42,  1.82s/it]\n","  4%|‚ñç         | 7/161 [00:13<04:59,  1.95s/it]\n","  5%|‚ñç         | 8/161 [00:15<04:41,  1.84s/it]\n","  6%|‚ñå         | 9/161 [00:16<04:28,  1.77s/it]\n","  6%|‚ñå         | 10/161 [00:18<04:19,  1.72s/it]\n","  7%|‚ñã         | 11/161 [00:20<04:49,  1.93s/it]\n","  7%|‚ñã         | 12/161 [00:22<04:28,  1.80s/it]\n","  8%|‚ñä         | 13/161 [00:23<04:18,  1.74s/it]\n","  9%|‚ñä         | 14/161 [00:25<04:05,  1.67s/it]\n","  9%|‚ñâ         | 15/161 [00:26<04:01,  1.65s/it]\n"," 10%|‚ñâ         | 16/161 [00:28<03:53,  1.61s/it]\n"," 11%|‚ñà         | 17/161 [00:30<03:51,  1.61s/it]\n"," 11%|‚ñà         | 18/161 [00:31<03:50,  1.61s/it]\n"," 12%|‚ñà‚ñè        | 19/161 [00:33<03:48,  1.61s/it]\n"," 12%|‚ñà‚ñè        | 20/161 [00:35<03:55,  1.67s/it]\n"," 13%|‚ñà‚ñé        | 21/161 [00:36<03:51,  1.65s/it]\n"," 14%|‚ñà‚ñé        | 22/161 [00:38<03:47,  1.64s/it]\n"," 14%|‚ñà‚ñç        | 23/161 [00:40<03:53,  1.69s/it]\n"," 15%|‚ñà‚ñç        | 24/161 [00:41<03:44,  1.64s/it]\n"," 16%|‚ñà‚ñå        | 25/161 [00:43<03:37,  1.60s/it]\n"," 16%|‚ñà‚ñå        | 26/161 [00:44<03:36,  1.60s/it]\n"," 17%|‚ñà‚ñã        | 27/161 [00:46<03:38,  1.63s/it]\n"," 17%|‚ñà‚ñã        | 28/161 [00:47<03:32,  1.60s/it]\n"," 18%|‚ñà‚ñä        | 29/161 [00:49<03:31,  1.60s/it]\n"," 19%|‚ñà‚ñä        | 30/161 [00:51<03:29,  1.60s/it]\n"," 19%|‚ñà‚ñâ        | 31/161 [00:52<03:28,  1.61s/it]\n"," 20%|‚ñà‚ñâ        | 32/161 [00:54<03:23,  1.58s/it]\n"," 20%|‚ñà‚ñà        | 33/161 [00:56<03:27,  1.62s/it]\n"," 21%|‚ñà‚ñà        | 34/161 [00:57<03:25,  1.61s/it]\n"," 22%|‚ñà‚ñà‚ñè       | 35/161 [00:59<03:23,  1.61s/it]\n"," 22%|‚ñà‚ñà‚ñè       | 36/161 [01:00<03:17,  1.58s/it]\n"," 23%|‚ñà‚ñà‚ñé       | 37/161 [01:02<03:20,  1.62s/it]\n"," 24%|‚ñà‚ñà‚ñé       | 38/161 [01:03<03:11,  1.56s/it]\n"," 24%|‚ñà‚ñà‚ñç       | 39/161 [01:19<11:45,  5.78s/it]\n"," 25%|‚ñà‚ñà‚ñç       | 40/161 [01:21<09:26,  4.68s/it]\n"," 25%|‚ñà‚ñà‚ñå       | 41/161 [01:23<07:34,  3.79s/it]\n"," 26%|‚ñà‚ñà‚ñå       | 42/161 [01:25<06:16,  3.17s/it]\n"," 27%|‚ñà‚ñà‚ñã       | 43/161 [01:26<05:14,  2.67s/it]\n"," 27%|‚ñà‚ñà‚ñã       | 44/161 [01:28<04:35,  2.35s/it]\n"," 28%|‚ñà‚ñà‚ñä       | 45/161 [01:30<04:24,  2.28s/it]\n"," 29%|‚ñà‚ñà‚ñä       | 46/161 [01:31<03:59,  2.08s/it]\n"," 29%|‚ñà‚ñà‚ñâ       | 47/161 [01:33<03:40,  1.94s/it]\n"," 30%|‚ñà‚ñà‚ñâ       | 48/161 [01:35<03:24,  1.81s/it]\n"," 30%|‚ñà‚ñà‚ñà       | 49/161 [01:36<03:12,  1.72s/it]\n"," 31%|‚ñà‚ñà‚ñà       | 50/161 [01:38<03:07,  1.69s/it]\n"," 32%|‚ñà‚ñà‚ñà‚ñè      | 51/161 [01:40<03:22,  1.84s/it]\n"," 32%|‚ñà‚ñà‚ñà‚ñè      | 52/161 [01:41<03:13,  1.77s/it]\n"," 33%|‚ñà‚ñà‚ñà‚ñé      | 53/161 [01:43<03:06,  1.72s/it]\n"," 34%|‚ñà‚ñà‚ñà‚ñé      | 54/161 [01:45<03:07,  1.75s/it]\n"," 34%|‚ñà‚ñà‚ñà‚ñç      | 55/161 [01:47<03:20,  1.89s/it]\n"," 35%|‚ñà‚ñà‚ñà‚ñç      | 56/161 [01:49<03:12,  1.84s/it]\n"," 35%|‚ñà‚ñà‚ñà‚ñå      | 57/161 [01:50<03:00,  1.74s/it]\n"," 36%|‚ñà‚ñà‚ñà‚ñå      | 58/161 [01:52<02:54,  1.70s/it]\n"," 37%|‚ñà‚ñà‚ñà‚ñã      | 59/161 [01:54<02:50,  1.67s/it]\n"," 37%|‚ñà‚ñà‚ñà‚ñã      | 60/161 [01:55<02:46,  1.65s/it]\n"," 38%|‚ñà‚ñà‚ñà‚ñä      | 61/161 [01:57<02:44,  1.64s/it]\n"," 39%|‚ñà‚ñà‚ñà‚ñä      | 62/161 [01:58<02:41,  1.63s/it]\n"," 39%|‚ñà‚ñà‚ñà‚ñâ      | 63/161 [02:00<02:39,  1.62s/it]\n"," 40%|‚ñà‚ñà‚ñà‚ñâ      | 64/161 [02:02<02:37,  1.62s/it]\n"," 40%|‚ñà‚ñà‚ñà‚ñà      | 65/161 [02:03<02:35,  1.62s/it]\n"," 41%|‚ñà‚ñà‚ñà‚ñà      | 66/161 [02:05<02:53,  1.83s/it]\n"," 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 67/161 [02:07<02:48,  1.79s/it]\n"," 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 68/161 [02:09<02:41,  1.74s/it]\n"," 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 69/161 [02:10<02:36,  1.70s/it]\n"," 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 70/161 [02:13<02:45,  1.82s/it]\n"," 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 71/161 [02:15<02:54,  1.94s/it]\n"," 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 72/161 [02:17<03:02,  2.05s/it]\n"," 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 73/161 [02:19<03:02,  2.07s/it]\n"," 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 74/161 [02:22<03:09,  2.17s/it]\n"," 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 75/161 [02:23<02:52,  2.00s/it]\n"," 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 76/161 [02:25<02:55,  2.07s/it]\n"," 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 77/161 [02:27<02:39,  1.90s/it]\n"," 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 78/161 [02:29<02:30,  1.81s/it]\n"," 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 79/161 [02:30<02:26,  1.78s/it]\n"," 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 80/161 [02:32<02:20,  1.73s/it]\n"," 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 81/161 [02:34<02:27,  1.85s/it]\n"," 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 82/161 [02:35<02:17,  1.74s/it]\n"," 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 83/161 [02:37<02:12,  1.70s/it]\n"," 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 84/161 [02:39<02:08,  1.68s/it]\n"," 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 85/161 [02:41<02:10,  1.72s/it]\n"," 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 86/161 [02:42<02:08,  1.71s/it]\n"," 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 87/161 [02:44<02:04,  1.68s/it]\n"," 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 88/161 [02:46<02:03,  1.69s/it]\n"," 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 89/161 [02:48<02:17,  1.91s/it]\n"," 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 90/161 [02:50<02:09,  1.82s/it]\n"," 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 91/161 [02:52<02:15,  1.94s/it]\n"," 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 92/161 [02:53<02:02,  1.78s/it]\n"," 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 93/161 [02:56<02:20,  2.06s/it]\n"," 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 94/161 [02:58<02:11,  1.96s/it]\n"," 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 95/161 [02:59<02:02,  1.85s/it]\n"," 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 96/161 [03:01<01:55,  1.78s/it]\n"," 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 97/161 [03:03<02:00,  1.88s/it]\n"," 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 98/161 [03:05<01:53,  1.80s/it]\n"," 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 99/161 [03:06<01:47,  1.74s/it]\n"," 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 100/161 [03:08<01:54,  1.88s/it]\n"," 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 101/161 [03:10<01:46,  1.77s/it]\n"," 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 102/161 [03:11<01:41,  1.72s/it]\n"," 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 103/161 [03:14<01:53,  1.96s/it]\n"," 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 104/161 [03:15<01:42,  1.79s/it]\n"," 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 105/161 [03:18<01:47,  1.92s/it]\n"," 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 106/161 [03:20<01:52,  2.04s/it]\n"," 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 107/161 [03:22<01:43,  1.91s/it]\n"," 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 108/161 [03:23<01:36,  1.82s/it]\n"," 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 109/161 [03:25<01:32,  1.79s/it]\n"," 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 110/161 [03:27<01:39,  1.94s/it]\n"," 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 111/161 [03:29<01:33,  1.87s/it]\n"," 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 112/161 [03:31<01:27,  1.80s/it]\n"," 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 113/161 [03:32<01:27,  1.83s/it]\n"," 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 114/161 [03:34<01:22,  1.76s/it]\n"," 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 115/161 [03:36<01:20,  1.75s/it]\n"," 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 116/161 [03:37<01:15,  1.68s/it]\n"," 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 117/161 [03:39<01:12,  1.66s/it]\n"," 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 118/161 [03:41<01:19,  1.85s/it]\n"," 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 119/161 [03:43<01:14,  1.78s/it]\n"," 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 120/161 [03:45<01:18,  1.91s/it]\n"," 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 121/161 [03:48<01:23,  2.09s/it]\n"," 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 122/161 [03:52<01:45,  2.70s/it]\n"," 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 123/161 [03:54<01:38,  2.58s/it]\n"," 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 124/161 [03:56<01:25,  2.32s/it]\n"," 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 125/161 [03:57<01:18,  2.17s/it]\n"," 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 126/161 [04:00<01:16,  2.18s/it]\n"," 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 127/161 [04:02<01:15,  2.22s/it]\n"," 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 128/161 [04:04<01:13,  2.22s/it]\n"," 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 129/161 [04:06<01:05,  2.04s/it]\n"," 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 130/161 [04:08<01:06,  2.15s/it]\n"," 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 131/161 [04:10<00:59,  1.99s/it]\n"," 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 132/161 [04:12<00:59,  2.06s/it]\n"," 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 133/161 [04:14<00:58,  2.10s/it]\n"," 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 134/161 [04:17<00:59,  2.20s/it]\n"," 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 135/161 [04:18<00:50,  1.96s/it]\n"," 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 136/161 [04:20<00:51,  2.07s/it]\n"," 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 137/161 [04:22<00:44,  1.87s/it]\n"," 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 138/161 [04:23<00:41,  1.79s/it]\n"," 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 139/161 [04:26<00:43,  1.98s/it]\n"," 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 140/161 [04:27<00:39,  1.87s/it]\n"," 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 141/161 [04:29<00:34,  1.73s/it]\n"," 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 142/161 [04:31<00:35,  1.85s/it]\n"," 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 143/161 [04:33<00:36,  2.02s/it]\n"," 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 144/161 [04:35<00:32,  1.89s/it]\n"," 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 145/161 [04:37<00:31,  1.96s/it]\n"," 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 146/161 [04:39<00:27,  1.85s/it]\n"," 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 147/161 [04:40<00:25,  1.81s/it]\n"," 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 148/161 [04:42<00:22,  1.72s/it]\n"," 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 149/161 [04:43<00:19,  1.63s/it]\n"," 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 150/161 [04:45<00:17,  1.62s/it]\n"," 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 151/161 [04:47<00:16,  1.65s/it]\n"," 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 152/161 [04:49<00:16,  1.82s/it]\n"," 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 153/161 [04:51<00:15,  2.00s/it]\n"," 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 154/161 [04:53<00:13,  1.88s/it]\n"," 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 155/161 [04:55<00:11,  1.98s/it]\n"," 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 156/161 [04:57<00:09,  1.93s/it]\n"," 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 157/161 [04:59<00:07,  1.83s/it]\n"," 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 158/161 [05:00<00:05,  1.80s/it]\n"," 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 159/161 [05:02<00:03,  1.74s/it]\n"," 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 160/161 [05:03<00:01,  1.70s/it]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 161/161 [05:05<00:00,  1.67s/it]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 161/161 [05:05<00:00,  1.90s/it]\n","{\n","  \"multiple-cpp\": {\n","    \"pass@1\": 0.6285714285714286,\n","    \"pass@10\": 0.7701863354037267\n","  },\n","  \"config\": {\n","    \"prefix\": \"def factorial(n):\\n    if n == 0 or n == 1:\\n        return 1\\n    return n * factorial(n - 1)\\n\\ndef is_palindrome(s):\\n    s = s.lower().replace(\\\" \\\", \\\"\\\")\\n    return s == s[::-1]\\n\\ndef fibonacci(n):\\n    if n <= 0:\\n        return []\\n    elif n == 1:\\n        return [0]\\n    elif n == 2:\\n        return [0, 1]\\n    seq = [0, 1]\\n    for i in range(2, n):\\n        seq.append(seq[-1] + seq[-2])\\n    return seq\\n\\ndef find_max(lst):\\n    if not lst:\\n        return None\\n    m = lst[0]\\n    for x in lst[1:]:\\n        if x > m:\\n            m = x\\n    return m\\n\\ndef reverse_list(lst):\\n    i, j = 0, len(lst) - 1\\n    while i < j:\\n        lst[i], lst[j] = lst[j], lst[i]\\n        i += 1\\n        j -= 1\\n    return lst\\n\\n\",\n","    \"do_sample\": true,\n","    \"temperature\": 0.2,\n","    \"top_k\": 0,\n","    \"top_p\": 0.95,\n","    \"n_samples\": 10,\n","    \"eos\": \"<|endoftext|>\",\n","    \"seed\": 11667,\n","    \"model\": \"Qwen/Qwen2.5-Coder-3B-Instruct\",\n","    \"modeltype\": \"causal\",\n","    \"peft_model\": null,\n","    \"revision\": null,\n","    \"use_auth_token\": false,\n","    \"trust_remote_code\": false,\n","    \"tasks\": \"multiple-cpp\",\n","    \"instruction_tokens\": null,\n","    \"batch_size\": 10,\n","    \"max_length_generation\": 2048,\n","    \"precision\": \"fp32\",\n","    \"load_in_8bit\": false,\n","    \"load_in_4bit\": false,\n","    \"left_padding\": false,\n","    \"limit\": null,\n","    \"limit_start\": 0,\n","    \"save_every_k_tasks\": -1,\n","    \"postprocess\": true,\n","    \"allow_code_execution\": true,\n","    \"generation_only\": false,\n","    \"load_generations_path\": null,\n","    \"load_data_path\": null,\n","    \"metric_output_path\": \"evaluation_results.json\",\n","    \"save_generations\": true,\n","    \"load_generations_intermediate_paths\": null,\n","    \"save_generations_path\": \"generations.json\",\n","    \"save_references\": false,\n","    \"save_references_path\": \"references.json\",\n","    \"prompt\": \"prompt\",\n","    \"max_memory_per_gpu\": null,\n","    \"check_references\": false\n","  }\n","}\n","\n","‚úÖ C++ evaluation completed successfully!\n"]}]},{"cell_type":"code","source":["# MultiPL-E C++ Evaluation - Fixed Version\n","# This will automatically install bigcode-evaluation-harness and run the evaluation\n","\n","import os\n","import subprocess\n","import sys\n","\n","# Fixed parameters\n","MODEL = \"Qwen/Qwen2.5-Coder-3B-Instruct\"\n","\n","# Task name detection:\n","# - 'multiple-cpp': Standard name (used in newer/older versions)\n","# - 'multiple-cljcpp': Alternative name (used in some versions, but has a bug mapping to humaneval-cljcpp)\n","# We'll try both and use whichever works\n","TASK_OPTIONS = [\"multiple-cpp\", \"multiple-cljcpp\"]\n","TASK = None  # Will be determined below\n","TOP_P = \"0.95\"\n","TEMPERATURE = \"0.2\"\n","DO_SAMPLE = \"True\"\n","N_SAMPLES = \"10\"\n","BATCH_SIZE = \"10\"\n","MAX_LENGTH = \"2048\"\n","MAX_LENGTH_GENERATION = \"2048\"\n","SEED = \"11667\"\n","\n","print(\"üöÄ Evaluating MultiPL-E C++...\")\n","print(\"   This will take ~30-60 minutes...\")\n","print(\"   Using 5-shot prompt from MBPP selection\")\n","\n","# Read the 5-shot prefix\n","with open(\"prompts/mbpp_5shot.txt\", \"r\", encoding=\"utf-8\") as f:\n","    prefix_content = f.read()\n","\n","# Check and install bigcode-evaluation-harness if needed\n","original_dir = os.getcwd()\n","harness_dir = \"bigcode-evaluation-harness\"\n","\n","if not os.path.exists(harness_dir):\n","    print(f\"\\nüì¶ Installing bigcode-evaluation-harness...\")\n","    print(\"   This will take a few minutes...\")\n","    try:\n","        # Try official repo first, fallback to fork if needed\n","        repo_url = \"https://github.com/bigcode-project/bigcode-evaluation-harness.git\"\n","        result = subprocess.run(\n","            [\"git\", \"clone\", repo_url],\n","            capture_output=True,\n","            text=True,\n","            check=True\n","        )\n","        print(\"‚úÖ Cloned successfully\")\n","    except subprocess.CalledProcessError as e:\n","        print(f\"‚ö†Ô∏è  Official repo failed, trying fork...\")\n","        try:\n","            repo_url = \"https://github.com/arthur900530/bigcode-evaluation-harness.git\"\n","            result = subprocess.run(\n","                [\"git\", \"clone\", repo_url],\n","                capture_output=True,\n","                text=True,\n","                check=True\n","            )\n","            print(\"‚úÖ Cloned from fork successfully\")\n","        except subprocess.CalledProcessError as e2:\n","            print(f\"‚ùå Failed to clone: {e2.stderr}\")\n","            raise RuntimeError(\"Failed to install bigcode-evaluation-harness\")\n","    except FileNotFoundError:\n","        print(\"‚ùå git not found. Please install git first.\")\n","        raise RuntimeError(\"git is required but not found\")\n","\n","    # Install the package\n","    os.chdir(harness_dir)\n","    try:\n","        print(\"   Installing bigcode-evaluation-harness package...\")\n","        result = subprocess.run(\n","            [sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \".\"],\n","            capture_output=True,\n","            text=True,\n","            check=True\n","        )\n","        print(\"‚úÖ Installed successfully\")\n","    except subprocess.CalledProcessError as e:\n","        print(f\"‚ö†Ô∏è  Warning: pip install failed: {e.stderr}\")\n","        print(\"   Continuing anyway...\")\n","\n","    # Install bitsandbytes (required for some models)\n","    try:\n","        print(\"   Installing bitsandbytes>=0.41.0...\")\n","        result = subprocess.run(\n","            [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"bitsandbytes>=0.41.0\"],\n","            capture_output=True,\n","            text=True,\n","            check=True\n","        )\n","        print(\"‚úÖ bitsandbytes installed\")\n","    except subprocess.CalledProcessError as e:\n","        print(f\"‚ö†Ô∏è  Warning: bitsandbytes install failed: {e.stderr}\")\n","        print(\"   Continuing anyway (may not be needed for CPU-only)...\")\n","\n","    os.chdir(original_dir)\n","else:\n","    print(\"‚úÖ bigcode-evaluation-harness already exists\")\n","    # Try to update to latest version (might fix task name issues)\n","    print(\"   Attempting to update to latest version...\")\n","    try:\n","        os.chdir(harness_dir)\n","        update_result = subprocess.run(\n","            [\"git\", \"pull\"],\n","            capture_output=True,\n","            text=True,\n","            timeout=30\n","        )\n","        if update_result.returncode == 0:\n","            print(\"   ‚úÖ Updated to latest version\")\n","            # Reinstall in case dependencies changed\n","            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \".\"], check=False)\n","        else:\n","            print(\"   ‚ö†Ô∏è  Update failed or already up to date\")\n","        os.chdir(original_dir)\n","    except Exception as e:\n","        print(f\"   ‚ö†Ô∏è  Could not update: {e}\")\n","        os.chdir(original_dir)\n","\n","# Save prefix to a file in bigcode-evaluation-harness directory\n","os.makedirs(f\"{harness_dir}/prompts\", exist_ok=True)\n","prefix_file = f\"{harness_dir}/prompts/mbpp_5shot.txt\"\n","with open(prefix_file, \"w\", encoding=\"utf-8\") as f:\n","    f.write(prefix_content)\n","\n","# Change to bigcode-evaluation-harness directory\n","os.chdir(harness_dir)\n","\n","# Check if main.py exists\n","if not os.path.exists(\"main.py\"):\n","    print(f\"‚ùå Error: main.py not found in {os.getcwd()}\")\n","    print(\"   Listing directory contents:\")\n","    for item in os.listdir(\".\"):\n","        print(f\"     - {item}\")\n","    os.chdir(original_dir)\n","    raise FileNotFoundError(f\"main.py not found in {harness_dir}. Please check the installation.\")\n","\n","print(f\"\\n‚úÖ Found main.py at: {os.path.join(os.getcwd(), 'main.py')}\")\n","\n","# Try to detect which C++ task name is available\n","print(\"\\nüîç Detecting available C++ task name...\")\n","for task_option in TASK_OPTIONS:\n","    try:\n","        # Quick test to see if task is valid\n","        test_result = subprocess.run(\n","            [sys.executable, \"main.py\", \"--tasks\", task_option, \"--limit\", \"1\", \"--model\", MODEL],\n","            capture_output=True,\n","            text=True,\n","            timeout=10\n","        )\n","        if \"invalid choice\" not in test_result.stderr.lower() and test_result.returncode != 2:\n","            TASK = task_option\n","            print(f\"   ‚úÖ Found working task: {TASK}\")\n","            break\n","    except:\n","        continue\n","\n","# If still not found, check help output\n","if TASK is None:\n","    try:\n","        help_result = subprocess.run(\n","            [sys.executable, \"main.py\", \"--tasks\", \"invalid_task_for_help\"],\n","            capture_output=True,\n","            text=True,\n","            timeout=5\n","        )\n","        # Look for cpp-related tasks in error message\n","        if \"multiple-cpp\" in help_result.stderr:\n","            TASK = \"multiple-cpp\"\n","            print(f\"   ‚úÖ Found task in help: {TASK}\")\n","        elif \"multiple-cljcpp\" in help_result.stderr:\n","            TASK = \"multiple-cljcpp\"\n","            print(f\"   ‚úÖ Found task in help: {TASK}\")\n","    except:\n","        pass\n","\n","if TASK is None:\n","    TASK = \"multiple-cpp\"\n","    print(f\"   ‚ö†Ô∏è  Could not auto-detect, using default: {TASK}\")\n","\n","print(f\"\\nüí° Using task: {TASK}\")\n","\n","\n","# Build the command - pass prefix content directly (not using bash $(cat))\n","cmd = [\n","    sys.executable, \"main.py\",\n","    \"--model\", MODEL,\n","    \"--tasks\", TASK,\n","    \"--top_p\", TOP_P,\n","    \"--temperature\", TEMPERATURE,\n","    \"--do_sample\", DO_SAMPLE,\n","    \"--n_samples\", N_SAMPLES,\n","    \"--batch_size\", BATCH_SIZE,\n","    \"--max_length\", MAX_LENGTH,\n","    \"--max_length_generation\", MAX_LENGTH_GENERATION,\n","    \"--allow_code_execution\",\n","    \"--save_generations\",\n","    \"--seed\", SEED\n","]\n","\n","print(f\"\\nüìù Command: python main.py --model {MODEL} --tasks {TASK} ...\")\n","print(f\"   Prefix length: {len(prefix_content)} characters\")\n","print(f\"   Working directory: {os.getcwd()}\")\n","print(\"\\n‚è≥ Starting evaluation (this will take 30-60 minutes)...\\n\")\n","\n","try:\n","    # Run the command and show output in real-time\n","    process = subprocess.Popen(\n","        cmd,\n","        stdout=subprocess.PIPE,\n","        stderr=subprocess.STDOUT,\n","        universal_newlines=True,\n","        bufsize=1\n","    )\n","\n","    # Print output line by line\n","    for line in process.stdout:\n","        print(line, end='')\n","\n","    process.wait()\n","\n","    if process.returncode == 0:\n","        print(\"\\n‚úÖ C++ evaluation completed successfully!\")\n","    else:\n","        print(f\"\\n‚ùå Evaluation failed with return code {process.returncode}\")\n","        # If task name error, show available tasks\n","        if \"invalid choice\" in str(process.returncode) or \"error\" in str(process.returncode).lower():\n","            print(\"\\nüí° Checking available tasks...\")\n","            try:\n","                help_result = subprocess.run(\n","                    [sys.executable, \"main.py\", \"--tasks\", \"invalid_task_for_help\"],\n","                    capture_output=True,\n","                    text=True,\n","                    timeout=5\n","                )\n","                # Extract task list from error message\n","                if \"choose from\" in help_result.stderr:\n","                    tasks_line = help_result.stderr.split(\"choose from\")[-1]\n","                    cpp_tasks = [t for t in tasks_line.split(\",\") if \"cpp\" in t.lower()]\n","                    if cpp_tasks:\n","                        print(f\"   Found C++ related tasks: {cpp_tasks}\")\n","                        print(f\"   Try using one of these instead of '{TASK}'\")\n","            except:\n","                pass\n","\n","except Exception as e:\n","    print(f\"\\n‚ùå Error running evaluation: {e}\")\n","    import traceback\n","    traceback.print_exc()\n","    # If it's a task name error, provide helpful message\n","    if \"invalid choice\" in str(e).lower() or \"not found\" in str(e).lower():\n","        print(\"\\nüí° Tip: The task name might be incorrect.\")\n","        print(\"   Available dataset configs include: humaneval-cpp\")\n","        print(\"   You may need to:\")\n","        print(\"   1. Update bigcode-evaluation-harness: cd bigcode-evaluation-harness && git pull\")\n","        print(\"   2. Or check available tasks: python main.py --tasks help\")\n","finally:\n","    os.chdir(original_dir)\n"],"metadata":{"id":"p9mTIAm5QCJD"},"id":"p9mTIAm5QCJD","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setup: Install Java Dependencies (Required for MultiPL-E Java evaluation)\n","# This cell installs javatuples JAR file needed for Java evaluation\n","\n","import os\n","import subprocess\n","import platform\n","\n","print(\"üîß Setting up Java dependencies for MultiPL-E evaluation...\")\n","print(f\"   Platform: {platform.system()}\")\n","\n","# Check if javatuples JAR exists\n","javatuples_path = \"/usr/multiple/javatuples-1.2.jar\"\n","javatuples_exists = os.path.exists(javatuples_path)\n","\n","if javatuples_exists:\n","    print(f\"‚úÖ javatuples JAR already exists at {javatuples_path}\")\n","else:\n","    # Install javatuples (Linux/Colab only)\n","    if platform.system() == \"Linux\" or os.path.exists(\"/etc/debian_version\"):\n","        print(\"üì¶ Installing javatuples JAR...\")\n","        try:\n","            # Create directory\n","            result = subprocess.run(\n","                [\"sudo\", \"mkdir\", \"-p\", \"/usr/multiple\"],\n","                capture_output=True,\n","                text=True,\n","                timeout=10\n","            )\n","\n","            # Download JAR\n","            result = subprocess.run(\n","                [\"sudo\", \"wget\", \"https://repo1.maven.org/maven2/org/javatuples/javatuples/1.2/javatuples-1.2.jar\",\n","                 \"-O\", \"/usr/multiple/javatuples-1.2.jar\"],\n","                capture_output=True,\n","                text=True,\n","                timeout=60\n","            )\n","\n","            if result.returncode == 0:\n","                print(\"‚úÖ javatuples JAR installed successfully\")\n","                # Verify\n","                if os.path.exists(javatuples_path):\n","                    print(f\"   Verified: {javatuples_path}\")\n","            else:\n","                print(f\"‚ö†Ô∏è  Warning: wget failed: {result.stderr}\")\n","        except (FileNotFoundError, subprocess.TimeoutExpired, subprocess.CalledProcessError) as e:\n","            print(f\"‚ö†Ô∏è  Could not install javatuples automatically: {e}\")\n","            print(\"   Please install manually:\")\n","            print(\"   sudo mkdir -p /usr/multiple\")\n","            print(\"   sudo wget https://repo1.maven.org/maven2/org/javatuples/javatuples/1.2/javatuples-1.2.jar -O /usr/multiple/javatuples-1.2.jar\")\n","    else:\n","        print(\"‚ö†Ô∏è  javatuples JAR not found\")\n","        print(\"   Please install manually for your platform\")\n","\n","if javatuples_exists or os.path.exists(javatuples_path):\n","    print(\"\\n‚úÖ Java dependencies setup complete! Ready for MultiPL-E Java evaluation.\")\n","else:\n","    print(\"\\n‚ö†Ô∏è  Warning: javatuples JAR not available. MultiPL-E Java evaluation may fail.\")\n","    print(\"   The evaluation will still attempt to run, but code execution may fail.\")\n"],"metadata":{"id":"sFWN5I8nsoTf"},"id":"sFWN5I8nsoTf","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setup: Install Node.js & TypeScript (Required for MultiPL-E JavaScript evaluation)\n","# This cell installs Node.js and TypeScript needed for JavaScript evaluation\n","\n","import os\n","import subprocess\n","import platform\n","\n","print(\"üîß Setting up Node.js and TypeScript for MultiPL-E evaluation...\")\n","print(f\"   Platform: {platform.system()}\")\n","\n","# Check if Node.js is installed\n","node_installed = False\n","node_version = None\n","\n","try:\n","    result = subprocess.run(\n","        [\"node\", \"--version\"],\n","        capture_output=True,\n","        text=True,\n","        timeout=5\n","    )\n","    if result.returncode == 0:\n","        node_installed = True\n","        node_version = result.stdout.strip()\n","        print(f\"‚úÖ Found Node.js: {node_version}\")\n","except (FileNotFoundError, subprocess.TimeoutExpired):\n","    pass\n","\n","# Check if TypeScript is installed\n","ts_installed = False\n","ts_version = None\n","\n","if node_installed:\n","    try:\n","        result = subprocess.run(\n","            [\"tsc\", \"--version\"],\n","            capture_output=True,\n","            text=True,\n","            timeout=5\n","        )\n","        if result.returncode == 0:\n","            ts_installed = True\n","            ts_version = result.stdout.strip()\n","            print(f\"‚úÖ Found TypeScript: {ts_version}\")\n","    except (FileNotFoundError, subprocess.TimeoutExpired):\n","        pass\n","\n","# Install Node.js and TypeScript if not found (Linux/Colab only)\n","if not node_installed or not ts_installed:\n","    if platform.system() == \"Linux\" or os.path.exists(\"/etc/debian_version\"):\n","        if not node_installed:\n","            print(\"üì¶ Installing Node.js...\")\n","            try:\n","                # Add NodeSource repository\n","                result = subprocess.run(\n","                    [\"bash\", \"-c\", \"curl -fsSL https://deb.nodesource.com/setup_20.x | bash -\"],\n","                    capture_output=True,\n","                    text=True,\n","                    timeout=60\n","                )\n","\n","                # Install Node.js\n","                result = subprocess.run(\n","                    [\"apt-get\", \"install\", \"-y\", \"-qq\", \"nodejs\"],\n","                    capture_output=True,\n","                    text=True,\n","                    timeout=120\n","                )\n","\n","                if result.returncode == 0:\n","                    print(\"‚úÖ Node.js installed successfully\")\n","                    # Verify\n","                    result = subprocess.run([\"node\", \"--version\"], capture_output=True, text=True, timeout=5)\n","                    if result.returncode == 0:\n","                        print(f\"   Version: {result.stdout.strip()}\")\n","                        node_installed = True\n","            except Exception as e:\n","                print(f\"‚ö†Ô∏è  Could not install Node.js automatically: {e}\")\n","\n","        if node_installed and not ts_installed:\n","            print(\"üì¶ Installing TypeScript...\")\n","            try:\n","                result = subprocess.run(\n","                    [\"npm\", \"install\", \"-g\", \"typescript\"],\n","                    capture_output=True,\n","                    text=True,\n","                    timeout=120\n","                )\n","                if result.returncode == 0:\n","                    print(\"‚úÖ TypeScript installed successfully\")\n","                    # Verify\n","                    result = subprocess.run([\"tsc\", \"--version\"], capture_output=True, text=True, timeout=5)\n","                    if result.returncode == 0:\n","                        print(f\"   Version: {result.stdout.strip()}\")\n","                        ts_installed = True\n","            except Exception as e:\n","                print(f\"‚ö†Ô∏è  Could not install TypeScript automatically: {e}\")\n","    else:\n","        print(\"‚ö†Ô∏è  Node.js/TypeScript not found\")\n","        print(\"   Please install manually:\")\n","        print(\"   - Linux: curl -fsSL https://deb.nodesource.com/setup_20.x | bash - && apt-get install -y nodejs && npm install -g typescript\")\n","        print(\"   - macOS: brew install node && npm install -g typescript\")\n","        print(\"   - Windows: Download from https://nodejs.org/\")\n","\n","if node_installed and ts_installed:\n","    print(\"\\n‚úÖ Node.js and TypeScript setup complete! Ready for MultiPL-E JavaScript evaluation.\")\n","else:\n","    print(\"\\n‚ö†Ô∏è  Warning: Node.js or TypeScript not available. MultiPL-E JavaScript evaluation may fail.\")\n","    print(\"   The evaluation will still attempt to run, but code execution may fail.\")\n"],"metadata":{"id":"7UAfpHqjGeLz"},"id":"7UAfpHqjGeLz","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# MultiPL-E Java Evaluation - Fixed Version\n","# This will automatically install bigcode-evaluation-harness and run the evaluation\n","\n","import os\n","import subprocess\n","import sys\n","\n","# Fixed parameters\n","MODEL = \"Qwen/Qwen2.5-Coder-3B-Instruct\"\n","TASK = \"multiple-java\"\n","TOP_P = \"0.95\"\n","TEMPERATURE = \"0.2\"\n","DO_SAMPLE = \"True\"\n","N_SAMPLES = \"10\"\n","BATCH_SIZE = \"10\"\n","MAX_LENGTH = \"2048\"\n","MAX_LENGTH_GENERATION = \"2048\"\n","SEED = \"11667\"\n","\n","print(\"üöÄ Evaluating MultiPL-E Java...\")\n","print(\"   This will take ~30-60 minutes...\")\n","print(\"   Using 5-shot prompt from MBPP selection\")\n","\n","# Read the 5-shot prefix\n","with open(\"prompts/mbpp_5shot.txt\", \"r\", encoding=\"utf-8\") as f:\n","    prefix_content = f.read()\n","\n","# Check and install bigcode-evaluation-harness if needed\n","original_dir = os.getcwd()\n","harness_dir = \"bigcode-evaluation-harness\"\n","\n","if not os.path.exists(harness_dir):\n","    print(f\"\\nüì¶ Installing bigcode-evaluation-harness...\")\n","    print(\"   This will take a few minutes...\")\n","    try:\n","        repo_url = \"https://github.com/arthur900530/bigcode-evaluation-harness.git\"\n","        result = subprocess.run(\n","            [\"git\", \"clone\", repo_url],\n","            capture_output=True,\n","            text=True,\n","            check=True\n","        )\n","        print(\"‚úÖ Cloned successfully\")\n","    except subprocess.CalledProcessError as e:\n","        print(f\"‚ùå Failed to clone: {e.stderr}\")\n","        raise RuntimeError(\"Failed to install bigcode-evaluation-harness\")\n","    except FileNotFoundError:\n","        print(\"‚ùå git not found. Please install git first.\")\n","        raise RuntimeError(\"git is required but not found\")\n","\n","    # Install the package\n","    os.chdir(harness_dir)\n","    try:\n","        print(\"   Installing bigcode-evaluation-harness package...\")\n","        result = subprocess.run(\n","            [sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \".\"],\n","            capture_output=True,\n","            text=True,\n","            check=True\n","        )\n","        print(\"‚úÖ Installed successfully\")\n","    except subprocess.CalledProcessError as e:\n","        print(f\"‚ö†Ô∏è  Warning: pip install failed: {e.stderr}\")\n","        print(\"   Continuing anyway...\")\n","\n","    os.chdir(original_dir)\n","else:\n","    print(\"‚úÖ bigcode-evaluation-harness already exists\")\n","\n","# Save prefix to a file in bigcode-evaluation-harness directory\n","os.makedirs(f\"{harness_dir}/prompts\", exist_ok=True)\n","prefix_file = f\"{harness_dir}/prompts/mbpp_5shot.txt\"\n","with open(prefix_file, \"w\", encoding=\"utf-8\") as f:\n","    f.write(prefix_content)\n","\n","# Change to bigcode-evaluation-harness directory\n","os.chdir(harness_dir)\n","\n","# Check if main.py exists\n","if not os.path.exists(\"main.py\"):\n","    print(f\"‚ùå Error: main.py not found in {os.getcwd()}\")\n","    os.chdir(original_dir)\n","    raise FileNotFoundError(f\"main.py not found in {harness_dir}\")\n","\n","print(f\"\\n‚úÖ Found main.py at: {os.path.join(os.getcwd(), 'main.py')}\")\n","print(f\"\\nüí° Using task: {TASK}\")\n","print(\"üí° Running evaluation command...\")\n","print(\"   This will take 30-60 minutes, please be patient...\")\n","\n","# Build the command - pass prefix content directly\n","cmd = [\n","    sys.executable, \"main.py\",\n","    \"--model\", MODEL,\n","    \"--tasks\", TASK,\n","    \"--top_p\", TOP_P,\n","    \"--temperature\", TEMPERATURE,\n","    \"--do_sample\", DO_SAMPLE,\n","    \"--n_samples\", N_SAMPLES,\n","    \"--batch_size\", BATCH_SIZE,\n","    \"--max_length\", MAX_LENGTH,\n","    \"--max_length_generation\", MAX_LENGTH_GENERATION,\n","    \"--allow_code_execution\",\n","    \"--save_generations\",\n","    \"--seed\", SEED,\n","    \"--trust_remote_code\",\n","]\n","\n","print(f\"\\nüìù Command: python main.py --model {MODEL} --tasks {TASK} ...\")\n","print(f\"   Prefix length: {len(prefix_content)} characters\")\n","print(f\"   Working directory: {os.getcwd()}\")\n","print(\"\\n‚è≥ Starting evaluation (this will take 30-60 minutes)...\\n\")\n","\n","try:\n","    # Run the command and show output in real-time\n","    process = subprocess.Popen(\n","        cmd,\n","        stdout=subprocess.PIPE,\n","        stderr=subprocess.STDOUT,\n","        universal_newlines=True,\n","        bufsize=1\n","    )\n","\n","    # Print output line by line\n","    for line in process.stdout:\n","        print(line, end='')\n","\n","    process.wait()\n","\n","    if process.returncode == 0:\n","        print(\"\\n‚úÖ Java evaluation completed successfully!\")\n","    else:\n","        print(f\"\\n‚ùå Evaluation failed with return code {process.returncode}\")\n","\n","except Exception as e:\n","    print(f\"\\n‚ùå Error running evaluation: {e}\")\n","    import traceback\n","    traceback.print_exc()\n","finally:\n","    os.chdir(original_dir)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0vmJrPi4zOJC","outputId":"3a6e2d0d-7966-4eb1-e716-352460421cdf"},"id":"0vmJrPi4zOJC","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üöÄ Evaluating MultiPL-E Java...\n","   This will take ~30-60 minutes...\n","   Using 5-shot prompt from MBPP selection\n","‚úÖ bigcode-evaluation-harness already exists\n","\n","‚úÖ Found main.py at: /content/bigcode-evaluation-harness/bigcode-evaluation-harness/main.py\n","\n","üí° Using task: multiple-java\n","üí° Running evaluation command...\n","   This will take 30-60 minutes, please be patient...\n","\n","üìù Command: python main.py --model Qwen/Qwen2.5-Coder-3B-Instruct --tasks multiple-java ...\n","   Prefix length: 896 characters\n","   Working directory: /content/bigcode-evaluation-harness/bigcode-evaluation-harness\n","\n","‚è≥ Starting evaluation (this will take 30-60 minutes)...\n","\n","2025-12-03 17:27:26.618548: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1764782846.640650   43366 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1764782846.647219   43366 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1764782846.663409   43366 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1764782846.663435   43366 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1764782846.663437   43366 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1764782846.663440   43366 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","Selected Tasks: ['multiple-java']\n","Loading model in fp32\n","\n","Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\n","Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  1.48s/it]\n","Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.21it/s]\n","Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.08it/s]\n","\n","Generating test split:   0%|          | 0/158 [00:00<?, ? examples/s]\n","Generating test split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 158/158 [00:00<00:00, 31667.23 examples/s]\n","number of problems for this task is 158\n","\n","  0%|          | 0/158 [00:00<?, ?it/s]\n","  1%|          | 1/158 [00:03<10:18,  3.94s/it]\n","  1%|‚ñè         | 2/158 [00:11<16:31,  6.35s/it]\n","  2%|‚ñè         | 3/158 [00:12<10:01,  3.88s/it]\n","  3%|‚ñé         | 4/158 [00:15<08:46,  3.42s/it]\n","  3%|‚ñé         | 5/158 [00:20<10:15,  4.02s/it]\n","  4%|‚ñç         | 6/158 [00:24<10:17,  4.06s/it]\n","  4%|‚ñç         | 7/158 [00:31<11:59,  4.76s/it]\n","  5%|‚ñå         | 8/158 [00:33<10:14,  4.10s/it]\n","  6%|‚ñå         | 9/158 [00:36<09:12,  3.71s/it]\n","  6%|‚ñã         | 10/158 [00:40<09:27,  3.83s/it]\n","  7%|‚ñã         | 11/158 [00:50<13:42,  5.59s/it]\n","  8%|‚ñä         | 12/158 [00:54<12:38,  5.20s/it]\n","  8%|‚ñä         | 13/158 [00:57<11:12,  4.64s/it]\n","  9%|‚ñâ         | 14/158 [01:00<09:25,  3.92s/it]\n","  9%|‚ñâ         | 15/158 [01:02<08:21,  3.51s/it]\n"," 10%|‚ñà         | 16/158 [01:05<07:47,  3.29s/it]\n"," 11%|‚ñà         | 17/158 [01:10<09:06,  3.88s/it]\n"," 11%|‚ñà‚ñè        | 18/158 [01:21<13:51,  5.94s/it]\n"," 12%|‚ñà‚ñè        | 19/158 [01:25<12:30,  5.40s/it]\n"," 13%|‚ñà‚ñé        | 20/158 [01:35<15:13,  6.62s/it]\n"," 13%|‚ñà‚ñé        | 21/158 [01:41<14:46,  6.47s/it]\n"," 14%|‚ñà‚ñç        | 22/158 [01:45<12:59,  5.73s/it]\n"," 15%|‚ñà‚ñç        | 23/158 [01:48<10:56,  4.86s/it]\n"," 15%|‚ñà‚ñå        | 24/158 [03:28<1:15:07, 33.64s/it]\n"," 16%|‚ñà‚ñå        | 25/158 [03:32<54:26, 24.56s/it]  \n"," 16%|‚ñà‚ñã        | 26/158 [03:36<40:36, 18.46s/it]\n"," 17%|‚ñà‚ñã        | 27/158 [03:41<31:23, 14.38s/it]\n"," 18%|‚ñà‚ñä        | 28/158 [03:45<24:20, 11.24s/it]\n"," 18%|‚ñà‚ñä        | 29/158 [03:46<17:26,  8.11s/it]\n"," 19%|‚ñà‚ñâ        | 30/158 [03:47<13:06,  6.15s/it]\n"," 20%|‚ñà‚ñâ        | 31/158 [03:49<10:22,  4.90s/it]\n"," 20%|‚ñà‚ñà        | 32/158 [03:55<10:42,  5.10s/it]\n"," 21%|‚ñà‚ñà        | 33/158 [04:02<12:18,  5.91s/it]\n"," 22%|‚ñà‚ñà‚ñè       | 34/158 [04:05<09:52,  4.78s/it]\n"," 22%|‚ñà‚ñà‚ñè       | 35/158 [04:40<28:36, 13.95s/it]\n"," 23%|‚ñà‚ñà‚ñé       | 36/158 [04:45<22:57, 11.29s/it]\n"," 23%|‚ñà‚ñà‚ñé       | 37/158 [04:52<19:51,  9.85s/it]\n"," 24%|‚ñà‚ñà‚ñç       | 38/158 [04:56<16:12,  8.11s/it]\n"," 25%|‚ñà‚ñà‚ñç       | 39/158 [05:02<15:04,  7.60s/it]\n"," 25%|‚ñà‚ñà‚ñå       | 40/158 [05:06<12:49,  6.52s/it]\n"," 26%|‚ñà‚ñà‚ñå       | 41/158 [05:09<10:24,  5.33s/it]\n"," 27%|‚ñà‚ñà‚ñã       | 42/158 [05:12<09:04,  4.69s/it]\n"," 27%|‚ñà‚ñà‚ñã       | 43/158 [05:16<08:38,  4.51s/it]\n"," 28%|‚ñà‚ñà‚ñä       | 44/158 [06:56<1:03:17, 33.32s/it]\n"," 28%|‚ñà‚ñà‚ñä       | 45/158 [07:04<48:22, 25.69s/it]  \n"," 29%|‚ñà‚ñà‚ñâ       | 46/158 [07:08<35:39, 19.10s/it]\n"," 30%|‚ñà‚ñà‚ñâ       | 47/158 [07:11<26:39, 14.41s/it]\n"," 30%|‚ñà‚ñà‚ñà       | 48/158 [08:48<1:11:42, 39.11s/it]\n"," 31%|‚ñà‚ñà‚ñà       | 49/158 [08:51<51:30, 28.36s/it]  \n"," 32%|‚ñà‚ñà‚ñà‚ñè      | 50/158 [08:53<36:43, 20.40s/it]\n"," 32%|‚ñà‚ñà‚ñà‚ñè      | 51/158 [10:33<1:18:53, 44.24s/it]\n"," 33%|‚ñà‚ñà‚ñà‚ñé      | 52/158 [10:37<56:38, 32.06s/it]  \n"," 34%|‚ñà‚ñà‚ñà‚ñé      | 53/158 [12:16<1:31:24, 52.24s/it]\n"," 34%|‚ñà‚ñà‚ñà‚ñç      | 54/158 [12:20<1:05:35, 37.84s/it]\n"," 35%|‚ñà‚ñà‚ñà‚ñç      | 55/158 [12:26<48:18, 28.14s/it]  \n"," 35%|‚ñà‚ñà‚ñà‚ñå      | 56/158 [12:30<35:20, 20.79s/it]\n"," 36%|‚ñà‚ñà‚ñà‚ñå      | 57/158 [12:35<27:13, 16.18s/it]\n"," 37%|‚ñà‚ñà‚ñà‚ñã      | 58/158 [14:12<1:07:21, 40.42s/it]\n"," 37%|‚ñà‚ñà‚ñà‚ñã      | 59/158 [14:16<48:52, 29.63s/it]  \n"," 38%|‚ñà‚ñà‚ñà‚ñä      | 60/158 [14:19<35:15, 21.59s/it]\n"," 39%|‚ñà‚ñà‚ñà‚ñä      | 61/158 [14:25<27:01, 16.71s/it]\n"," 39%|‚ñà‚ñà‚ñà‚ñâ      | 62/158 [14:30<21:31, 13.46s/it]\n"," 40%|‚ñà‚ñà‚ñà‚ñâ      | 63/158 [14:35<16:54, 10.68s/it]\n"," 41%|‚ñà‚ñà‚ñà‚ñà      | 64/158 [14:37<12:58,  8.28s/it]\n"," 41%|‚ñà‚ñà‚ñà‚ñà      | 65/158 [14:40<10:27,  6.75s/it]\n"," 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 66/158 [14:48<10:32,  6.88s/it]\n"," 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 67/158 [14:54<10:06,  6.66s/it]\n"," 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 68/158 [15:02<10:38,  7.09s/it]\n"," 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 69/158 [15:10<10:58,  7.40s/it]\n"," 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 70/158 [15:18<11:05,  7.56s/it]\n"," 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 71/158 [15:23<09:42,  6.69s/it]\n"," 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 72/158 [15:29<09:16,  6.47s/it]\n"," 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 73/158 [15:38<10:29,  7.40s/it]\n"," 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 74/158 [15:42<08:44,  6.25s/it]\n"," 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 75/158 [15:44<07:06,  5.13s/it]\n"," 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 76/158 [15:52<08:13,  6.02s/it]\n"," 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 77/158 [15:56<07:04,  5.25s/it]\n"," 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 78/158 [16:04<08:08,  6.11s/it]\n"," 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 79/158 [16:20<11:54,  9.04s/it]\n"," 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 80/158 [16:23<09:36,  7.39s/it]\n"," 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 81/158 [16:26<07:47,  6.08s/it]\n"," 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 82/158 [16:29<06:22,  5.03s/it]\n"," 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 83/158 [16:32<05:35,  4.47s/it]\n"," 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 84/158 [16:40<06:38,  5.38s/it]\n"," 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 85/158 [16:50<08:23,  6.90s/it]\n"," 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 86/158 [16:55<07:39,  6.38s/it]\n"," 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 87/158 [17:00<07:02,  5.95s/it]\n"," 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 88/158 [17:06<06:52,  5.89s/it]\n"," 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 89/158 [17:09<05:59,  5.20s/it]\n"," 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 90/158 [17:16<06:20,  5.60s/it]\n"," 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 91/158 [17:30<08:54,  7.98s/it]\n"," 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 92/158 [17:35<07:50,  7.13s/it]\n"," 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 93/158 [17:40<06:59,  6.45s/it]\n"," 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 94/158 [17:44<06:06,  5.73s/it]\n"," 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 95/158 [17:45<04:45,  4.54s/it]\n"," 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 96/158 [17:50<04:45,  4.61s/it]\n"," 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 97/158 [17:55<04:44,  4.67s/it]\n"," 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 98/158 [17:59<04:37,  4.62s/it]\n"," 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 99/158 [18:02<04:03,  4.12s/it]\n"," 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 100/158 [18:08<04:18,  4.46s/it]\n"," 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 101/158 [18:10<03:46,  3.97s/it]\n"," 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 102/158 [18:24<06:18,  6.75s/it]\n"," 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 103/158 [18:28<05:23,  5.87s/it]\n"," 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 104/158 [18:32<05:00,  5.56s/it]\n"," 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 105/158 [18:35<04:09,  4.71s/it]\n"," 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 106/158 [18:41<04:30,  5.20s/it]\n"," 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 107/158 [18:54<06:18,  7.42s/it]\n"," 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 108/158 [19:01<06:10,  7.41s/it]\n"," 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 109/158 [19:09<06:07,  7.49s/it]\n"," 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 110/158 [19:15<05:39,  7.07s/it]\n"," 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 111/158 [19:21<05:16,  6.73s/it]\n"," 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 112/158 [19:26<04:39,  6.08s/it]\n"," 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 113/158 [19:29<03:55,  5.22s/it]\n"," 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 114/158 [19:35<04:01,  5.49s/it]\n"," 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 115/158 [19:42<04:18,  6.01s/it]\n"," 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 116/158 [19:52<04:58,  7.10s/it]\n"," 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 117/158 [19:56<04:09,  6.07s/it]\n"," 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 118/158 [19:59<03:34,  5.36s/it]\n"," 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 119/158 [20:03<03:08,  4.85s/it]\n"," 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 120/158 [20:09<03:22,  5.33s/it]\n"," 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 121/158 [20:28<05:50,  9.47s/it]\n"," 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 122/158 [20:36<05:18,  8.85s/it]\n"," 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 123/158 [20:43<04:52,  8.37s/it]\n"," 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 124/158 [20:48<04:14,  7.47s/it]\n"," 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 125/158 [21:11<06:40, 12.13s/it]\n"," 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 126/158 [21:21<06:01, 11.29s/it]\n"," 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 127/158 [21:25<04:44,  9.19s/it]\n"," 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 128/158 [21:30<03:57,  7.93s/it]\n"," 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 129/158 [21:34<03:10,  6.58s/it]\n"," 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 130/158 [21:42<03:21,  7.19s/it]\n"," 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 131/158 [21:45<02:42,  6.03s/it]\n"," 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 132/158 [21:53<02:47,  6.43s/it]\n"," 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 133/158 [21:59<02:40,  6.43s/it]\n"," 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 134/158 [22:03<02:12,  5.52s/it]\n"," 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 135/158 [22:11<02:28,  6.48s/it]\n"," 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 136/158 [22:26<03:19,  9.06s/it]\n"," 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 137/158 [22:31<02:44,  7.84s/it]\n"," 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 138/158 [22:38<02:28,  7.40s/it]\n"," 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 139/158 [22:46<02:26,  7.72s/it]\n"," 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 140/158 [22:57<02:33,  8.54s/it]\n"," 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 141/158 [22:59<01:52,  6.63s/it]\n"," 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 142/158 [23:06<01:48,  6.79s/it]\n"," 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 143/158 [23:15<01:51,  7.41s/it]\n"," 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 144/158 [23:19<01:31,  6.50s/it]\n"," 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 145/158 [23:21<01:05,  5.02s/it]\n"," 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 146/158 [23:24<00:53,  4.47s/it]\n"," 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 147/158 [23:28<00:46,  4.26s/it]\n"," 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 148/158 [23:35<00:52,  5.26s/it]\n"," 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 149/158 [23:39<00:43,  4.78s/it]\n"," 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 150/158 [23:44<00:37,  4.67s/it]\n"," 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 151/158 [24:00<00:57,  8.18s/it]\n"," 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 152/158 [24:05<00:43,  7.26s/it]\n"," 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 153/158 [24:12<00:35,  7.05s/it]\n"," 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 154/158 [24:15<00:23,  5.93s/it]\n"," 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 155/158 [24:24<00:20,  6.77s/it]\n"," 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 156/158 [24:29<00:12,  6.42s/it]\n"," 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 157/158 [24:35<00:06,  6.34s/it]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 158/158 [24:43<00:00,  6.60s/it]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 158/158 [24:43<00:00,  9.39s/it]\n","generations were saved at generations_multiple-java.json\n","Evaluating generations...\n","Saved 158 problems in /tmp for evaluation, each problem has 10 completions\n","\n","  0%|          | 0/158 [00:00<?, ?it/s]\n","  1%|          | 1/158 [00:01<03:10,  1.21s/it]\n","  1%|‚ñè         | 2/158 [00:02<03:28,  1.33s/it]\n","  2%|‚ñè         | 3/158 [00:03<02:35,  1.00s/it]\n","  3%|‚ñé         | 4/158 [00:04<02:28,  1.03it/s]\n","  3%|‚ñé         | 5/158 [00:05<03:03,  1.20s/it]\n","  4%|‚ñç         | 6/158 [00:07<03:13,  1.28s/it]\n","  4%|‚ñç         | 7/158 [00:08<03:20,  1.33s/it]\n","  5%|‚ñå         | 8/158 [00:09<03:03,  1.23s/it]\n","  6%|‚ñå         | 9/158 [00:10<02:43,  1.10s/it]\n","  6%|‚ñã         | 10/158 [00:12<03:06,  1.26s/it]\n","  7%|‚ñã         | 11/158 [00:13<03:30,  1.43s/it]\n","  8%|‚ñä         | 12/158 [00:15<03:37,  1.49s/it]\n","  8%|‚ñä         | 13/158 [00:16<03:24,  1.41s/it]\n","  9%|‚ñâ         | 14/158 [00:17<02:56,  1.23s/it]\n","  9%|‚ñâ         | 15/158 [00:18<02:41,  1.13s/it]\n"," 10%|‚ñà         | 16/158 [00:19<02:44,  1.16s/it]\n"," 11%|‚ñà         | 17/158 [00:20<02:33,  1.09s/it]\n"," 11%|‚ñà‚ñè        | 18/158 [00:21<02:37,  1.13s/it]\n"," 12%|‚ñà‚ñè        | 19/158 [00:23<02:49,  1.22s/it]\n"," 13%|‚ñà‚ñé        | 20/158 [00:24<02:48,  1.22s/it]\n"," 13%|‚ñà‚ñé        | 21/158 [00:26<03:07,  1.37s/it]\n"," 14%|‚ñà‚ñç        | 22/158 [00:27<03:04,  1.36s/it]\n"," 15%|‚ñà‚ñç        | 23/158 [00:28<02:57,  1.31s/it]\n"," 15%|‚ñà‚ñå        | 24/158 [00:30<03:00,  1.35s/it]\n"," 16%|‚ñà‚ñå        | 25/158 [00:30<02:33,  1.15s/it]\n"," 16%|‚ñà‚ñã        | 26/158 [00:31<02:18,  1.05s/it]\n"," 17%|‚ñà‚ñã        | 27/158 [00:32<02:24,  1.10s/it]\n"," 18%|‚ñà‚ñä        | 28/158 [00:34<02:27,  1.14s/it]\n"," 18%|‚ñà‚ñä        | 29/158 [00:34<02:06,  1.02it/s]\n"," 19%|‚ñà‚ñâ        | 30/158 [00:35<01:54,  1.12it/s]\n"," 20%|‚ñà‚ñâ        | 31/158 [00:36<01:50,  1.15it/s]\n"," 20%|‚ñà‚ñà        | 32/158 [00:36<01:43,  1.22it/s]\n"," 21%|‚ñà‚ñà        | 33/158 [00:38<02:16,  1.09s/it]\n"," 22%|‚ñà‚ñà‚ñè       | 34/158 [00:39<02:08,  1.04s/it]\n"," 22%|‚ñà‚ñà‚ñè       | 35/158 [00:40<02:18,  1.12s/it]\n"," 23%|‚ñà‚ñà‚ñé       | 36/158 [00:42<02:31,  1.24s/it]\n"," 23%|‚ñà‚ñà‚ñé       | 37/158 [00:43<02:22,  1.17s/it]\n"," 24%|‚ñà‚ñà‚ñç       | 38/158 [00:44<02:00,  1.00s/it]\n"," 25%|‚ñà‚ñà‚ñç       | 39/158 [00:45<02:14,  1.13s/it]\n"," 25%|‚ñà‚ñà‚ñå       | 40/158 [00:46<02:09,  1.10s/it]\n"," 26%|‚ñà‚ñà‚ñå       | 41/158 [00:47<02:01,  1.04s/it]\n"," 27%|‚ñà‚ñà‚ñã       | 42/158 [00:48<01:49,  1.06it/s]\n"," 27%|‚ñà‚ñà‚ñã       | 43/158 [00:48<01:43,  1.11it/s]\n"," 28%|‚ñà‚ñà‚ñä       | 44/158 [00:50<01:50,  1.04it/s]\n"," 28%|‚ñà‚ñà‚ñä       | 45/158 [00:51<02:01,  1.07s/it]\n"," 29%|‚ñà‚ñà‚ñâ       | 46/158 [00:52<02:18,  1.24s/it]\n"," 30%|‚ñà‚ñà‚ñâ       | 47/158 [00:54<02:13,  1.20s/it]\n"," 30%|‚ñà‚ñà‚ñà       | 48/158 [00:55<02:09,  1.18s/it]\n"," 31%|‚ñà‚ñà‚ñà       | 49/158 [00:55<01:52,  1.04s/it]\n"," 32%|‚ñà‚ñà‚ñà‚ñè      | 50/158 [00:56<01:51,  1.03s/it]\n"," 32%|‚ñà‚ñà‚ñà‚ñè      | 51/158 [00:58<02:12,  1.24s/it]\n"," 33%|‚ñà‚ñà‚ñà‚ñé      | 52/158 [01:00<02:23,  1.36s/it]\n"," 34%|‚ñà‚ñà‚ñà‚ñé      | 53/158 [01:01<02:18,  1.31s/it]\n"," 34%|‚ñà‚ñà‚ñà‚ñç      | 54/158 [01:02<01:57,  1.13s/it]\n"," 35%|‚ñà‚ñà‚ñà‚ñç      | 55/158 [01:03<02:12,  1.28s/it]\n"," 35%|‚ñà‚ñà‚ñà‚ñå      | 56/158 [01:04<02:05,  1.23s/it]\n"," 36%|‚ñà‚ñà‚ñà‚ñå      | 57/158 [01:06<02:13,  1.32s/it]\n"," 37%|‚ñà‚ñà‚ñà‚ñã      | 58/158 [01:07<02:06,  1.26s/it]\n"," 37%|‚ñà‚ñà‚ñà‚ñã      | 59/158 [01:08<01:51,  1.13s/it]\n"," 38%|‚ñà‚ñà‚ñà‚ñä      | 60/158 [01:09<01:47,  1.09s/it]\n"," 39%|‚ñà‚ñà‚ñà‚ñä      | 61/158 [01:10<01:40,  1.04s/it]\n"," 39%|‚ñà‚ñà‚ñà‚ñâ      | 62/158 [01:11<01:47,  1.12s/it]\n"," 40%|‚ñà‚ñà‚ñà‚ñâ      | 63/158 [01:12<01:46,  1.12s/it]\n"," 41%|‚ñà‚ñà‚ñà‚ñà      | 64/158 [01:13<01:33,  1.00it/s]\n"," 41%|‚ñà‚ñà‚ñà‚ñà      | 65/158 [01:14<01:27,  1.06it/s]\n"," 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 66/158 [01:16<01:56,  1.27s/it]\n"," 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 67/158 [01:18<02:24,  1.59s/it]\n"," 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 68/158 [01:20<02:37,  1.75s/it]\n"," 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 69/158 [01:22<02:35,  1.75s/it]\n"," 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 70/158 [01:24<02:33,  1.74s/it]\n"," 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 71/158 [01:25<02:15,  1.55s/it]\n"," 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 72/158 [01:26<02:10,  1.51s/it]\n"," 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 73/158 [01:28<02:03,  1.46s/it]\n"," 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 74/158 [01:29<02:09,  1.54s/it]\n"," 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 75/158 [01:31<02:07,  1.54s/it]\n"," 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 76/158 [01:32<02:03,  1.50s/it]\n"," 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 77/158 [01:33<01:47,  1.33s/it]\n"," 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 78/158 [01:35<01:48,  1.35s/it]\n"," 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 79/158 [01:36<01:38,  1.25s/it]\n"," 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 80/158 [01:36<01:25,  1.09s/it]\n"," 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 81/158 [01:37<01:24,  1.10s/it]\n"," 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 82/158 [01:38<01:14,  1.02it/s]\n"," 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 83/158 [01:39<01:12,  1.04it/s]\n"," 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 84/158 [01:41<01:28,  1.19s/it]\n"," 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 85/158 [01:47<03:26,  2.82s/it]\n"," 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 86/158 [01:50<03:06,  2.59s/it]\n"," 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 87/158 [01:51<02:32,  2.15s/it]\n"," 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 88/158 [01:52<02:19,  1.99s/it]\n"," 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 89/158 [01:53<01:52,  1.64s/it]\n"," 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 90/158 [01:54<01:34,  1.39s/it]\n"," 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 91/158 [01:55<01:33,  1.40s/it]\n"," 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 92/158 [01:56<01:24,  1.28s/it]\n"," 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 93/158 [01:58<01:24,  1.30s/it]\n"," 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 94/158 [01:59<01:21,  1.27s/it]\n"," 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 95/158 [01:59<01:07,  1.07s/it]\n"," 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 96/158 [02:01<01:07,  1.09s/it]\n"," 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 97/158 [02:02<01:12,  1.19s/it]\n"," 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 98/158 [02:03<01:00,  1.01s/it]\n"," 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 99/158 [02:04<00:58,  1.02it/s]\n"," 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 100/158 [02:05<01:03,  1.09s/it]\n"," 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 101/158 [02:06<00:55,  1.03it/s]\n"," 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 102/158 [02:08<01:13,  1.32s/it]\n"," 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 103/158 [02:09<01:04,  1.17s/it]\n"," 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 104/158 [02:09<00:58,  1.09s/it]\n"," 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 105/158 [02:10<00:56,  1.07s/it]\n"," 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 106/158 [02:12<01:10,  1.36s/it]\n"," 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 107/158 [02:14<01:19,  1.56s/it]\n"," 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 108/158 [02:17<01:27,  1.76s/it]\n"," 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 109/158 [02:18<01:25,  1.75s/it]\n"," 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 110/158 [02:19<01:08,  1.44s/it]\n"," 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 111/158 [02:20<01:05,  1.40s/it]\n"," 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 112/158 [02:21<00:54,  1.19s/it]\n"," 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 113/158 [02:24<01:14,  1.66s/it]\n"," 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 114/158 [02:26<01:13,  1.68s/it]\n"," 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 115/158 [02:27<01:10,  1.63s/it]\n"," 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 116/158 [02:29<01:12,  1.72s/it]\n"," 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 117/158 [02:31<01:06,  1.63s/it]\n"," 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 118/158 [02:32<00:59,  1.48s/it]\n"," 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 119/158 [02:33<00:53,  1.37s/it]\n"," 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 120/158 [02:34<00:49,  1.29s/it]\n"," 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 121/158 [02:36<00:52,  1.43s/it]\n"," 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 122/158 [02:38<00:56,  1.58s/it]\n"," 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 123/158 [02:39<00:49,  1.41s/it]\n"," 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 124/158 [02:40<00:45,  1.35s/it]\n"," 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 125/158 [02:43<01:04,  1.94s/it]\n"," 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 126/158 [02:45<01:01,  1.91s/it]\n"," 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 127/158 [02:46<00:49,  1.58s/it]\n"," 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 128/158 [02:47<00:46,  1.57s/it]\n"," 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 129/158 [02:49<00:47,  1.64s/it]\n"," 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 130/158 [02:51<00:44,  1.58s/it]\n"," 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 131/158 [02:52<00:43,  1.62s/it]\n"," 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 132/158 [02:54<00:42,  1.62s/it]\n"," 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 133/158 [02:56<00:40,  1.62s/it]\n"," 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 134/158 [02:56<00:31,  1.32s/it]\n"," 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 135/158 [02:58<00:31,  1.35s/it]\n"," 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 136/158 [02:59<00:32,  1.49s/it]\n"," 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 137/158 [03:00<00:27,  1.29s/it]\n"," 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 138/158 [03:02<00:28,  1.42s/it]\n"," 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 139/158 [03:04<00:28,  1.48s/it]\n"," 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 140/158 [03:05<00:27,  1.53s/it]\n"," 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 141/158 [03:06<00:24,  1.43s/it]\n"," 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 142/158 [03:08<00:24,  1.52s/it]\n"," 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 143/158 [03:09<00:20,  1.40s/it]\n"," 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 144/158 [03:10<00:17,  1.25s/it]\n"," 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 145/158 [03:11<00:14,  1.15s/it]\n"," 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 146/158 [03:12<00:12,  1.02s/it]\n"," 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 147/158 [03:13<00:11,  1.05s/it]\n"," 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 148/158 [03:14<00:10,  1.04s/it]\n"," 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 149/158 [03:15<00:10,  1.15s/it]\n"," 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 150/158 [03:17<00:10,  1.29s/it]\n"," 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 151/158 [03:19<00:09,  1.42s/it]\n"," 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 152/158 [03:19<00:07,  1.21s/it]\n"," 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 153/158 [03:21<00:06,  1.30s/it]\n"," 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 154/158 [03:22<00:04,  1.15s/it]\n"," 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 155/158 [03:23<00:03,  1.24s/it]\n"," 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 156/158 [03:24<00:02,  1.11s/it]\n"," 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 157/158 [03:25<00:00,  1.01it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 158/158 [03:26<00:00,  1.24s/it]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 158/158 [03:26<00:00,  1.31s/it]\n","{\n","  \"multiple-java\": {\n","    \"pass@1\": 0.0,\n","    \"pass@10\": 0.0\n","  },\n","  \"config\": {\n","    \"prefix\": \"\",\n","    \"do_sample\": true,\n","    \"temperature\": 0.2,\n","    \"top_k\": 0,\n","    \"top_p\": 0.95,\n","    \"n_samples\": 10,\n","    \"eos\": \"<|endoftext|>\",\n","    \"seed\": 11667,\n","    \"model\": \"Qwen/Qwen2.5-Coder-3B-Instruct\",\n","    \"modeltype\": \"causal\",\n","    \"peft_model\": null,\n","    \"revision\": null,\n","    \"use_auth_token\": false,\n","    \"trust_remote_code\": false,\n","    \"tasks\": \"multiple-java\",\n","    \"instruction_tokens\": null,\n","    \"batch_size\": 10,\n","    \"max_length_generation\": 2048,\n","    \"precision\": \"fp32\",\n","    \"load_in_8bit\": false,\n","    \"load_in_4bit\": false,\n","    \"left_padding\": false,\n","    \"limit\": null,\n","    \"limit_start\": 0,\n","    \"save_every_k_tasks\": -1,\n","    \"postprocess\": true,\n","    \"allow_code_execution\": true,\n","    \"generation_only\": false,\n","    \"load_generations_path\": null,\n","    \"load_data_path\": null,\n","    \"metric_output_path\": \"evaluation_results.json\",\n","    \"save_generations\": true,\n","    \"load_generations_intermediate_paths\": null,\n","    \"save_generations_path\": \"generations.json\",\n","    \"save_references\": false,\n","    \"save_references_path\": \"references.json\",\n","    \"prompt\": \"prompt\",\n","    \"max_memory_per_gpu\": null,\n","    \"check_references\": false\n","  }\n","}\n","\n","‚úÖ Java evaluation completed successfully!\n"]}]},{"cell_type":"code","source":["# MultiPL-E JavaScript Evaluation - Fixed Version\n","# This will automatically install bigcode-evaluation-harness and run the evaluation\n","\n","import os\n","import subprocess\n","import sys\n","\n","# Fixed parameters\n","MODEL = \"Qwen/Qwen2.5-Coder-3B-Instruct\"\n","TASK = \"multiple-js\"\n","TOP_P = \"0.95\"\n","TEMPERATURE = \"0.2\"\n","DO_SAMPLE = \"True\"\n","N_SAMPLES = \"10\"\n","BATCH_SIZE = \"10\"\n","MAX_LENGTH = \"2048\"\n","MAX_LENGTH_GENERATION = \"2048\"\n","SEED = \"11667\"\n","\n","print(\"üöÄ Evaluating MultiPL-E JavaScript...\")\n","print(\"   This will take ~30-60 minutes...\")\n","print(\"   Using 5-shot prompt from MBPP selection\")\n","\n","# Read the 5-shot prefix\n","with open(\"prompts/mbpp_5shot.txt\", \"r\", encoding=\"utf-8\") as f:\n","    prefix_content = f.read()\n","\n","# Check and install bigcode-evaluation-harness if needed\n","original_dir = os.getcwd()\n","harness_dir = \"bigcode-evaluation-harness\"\n","\n","if not os.path.exists(harness_dir):\n","    print(f\"\\nüì¶ Installing bigcode-evaluation-harness...\")\n","    print(\"   This will take a few minutes...\")\n","    try:\n","        repo_url = \"https://github.com/arthur900530/bigcode-evaluation-harness.git\"\n","        result = subprocess.run(\n","            [\"git\", \"clone\", repo_url],\n","            capture_output=True,\n","            text=True,\n","            check=True\n","        )\n","        print(\"‚úÖ Cloned successfully\")\n","    except subprocess.CalledProcessError as e:\n","        print(f\"‚ùå Failed to clone: {e.stderr}\")\n","        raise RuntimeError(\"Failed to install bigcode-evaluation-harness\")\n","    except FileNotFoundError:\n","        print(\"‚ùå git not found. Please install git first.\")\n","        raise RuntimeError(\"git is required but not found\")\n","\n","    # Install the package\n","    os.chdir(harness_dir)\n","    try:\n","        print(\"   Installing bigcode-evaluation-harness package...\")\n","        result = subprocess.run(\n","            [sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \".\"],\n","            capture_output=True,\n","            text=True,\n","            check=True\n","        )\n","        print(\"‚úÖ Installed successfully\")\n","    except subprocess.CalledProcessError as e:\n","        print(f\"‚ö†Ô∏è  Warning: pip install failed: {e.stderr}\")\n","        print(\"   Continuing anyway...\")\n","\n","    os.chdir(original_dir)\n","else:\n","    print(\"‚úÖ bigcode-evaluation-harness already exists\")\n","\n","# Save prefix to a file in bigcode-evaluation-harness directory\n","os.makedirs(f\"{harness_dir}/prompts\", exist_ok=True)\n","prefix_file = f\"{harness_dir}/prompts/mbpp_5shot.txt\"\n","with open(prefix_file, \"w\", encoding=\"utf-8\") as f:\n","    f.write(prefix_content)\n","\n","# Change to bigcode-evaluation-harness directory\n","os.chdir(harness_dir)\n","\n","# Check if main.py exists\n","if not os.path.exists(\"main.py\"):\n","    print(f\"‚ùå Error: main.py not found in {os.getcwd()}\")\n","    os.chdir(original_dir)\n","    raise FileNotFoundError(f\"main.py not found in {harness_dir}\")\n","\n","print(f\"\\n‚úÖ Found main.py at: {os.path.join(os.getcwd(), 'main.py')}\")\n","print(f\"\\nüí° Using task: {TASK}\")\n","print(\"üí° Running evaluation command...\")\n","print(\"   This will take 30-60 minutes, please be patient...\")\n","\n","# Build the command - pass prefix content directly\n","cmd = [\n","    sys.executable, \"main.py\",\n","    \"--model\", MODEL,\n","    \"--tasks\", TASK,\n","    \"--top_p\", TOP_P,\n","    \"--temperature\", TEMPERATURE,\n","    \"--do_sample\", DO_SAMPLE,\n","    \"--n_samples\", N_SAMPLES,\n","    \"--batch_size\", BATCH_SIZE,\n","    \"--max_length\", MAX_LENGTH,\n","    \"--max_length_generation\", MAX_LENGTH_GENERATION,\n","    \"--allow_code_execution\",\n","    \"--save_generations\",\n","    \"--seed\", SEED\n","]\n","\n","print(f\"\\nüìù Command: python main.py --model {MODEL} --tasks {TASK} ...\")\n","print(f\"   Prefix length: {len(prefix_content)} characters\")\n","print(f\"   Working directory: {os.getcwd()}\")\n","print(\"\\n‚è≥ Starting evaluation (this will take 30-60 minutes)...\\n\")\n","\n","try:\n","    # Run the command and show output in real-time\n","    process = subprocess.Popen(\n","        cmd,\n","        stdout=subprocess.PIPE,\n","        stderr=subprocess.STDOUT,\n","        universal_newlines=True,\n","        bufsize=1\n","    )\n","\n","    # Print output line by line\n","    for line in process.stdout:\n","        print(line, end='')\n","\n","    process.wait()\n","\n","    if process.returncode == 0:\n","        print(\"\\n‚úÖ JavaScript evaluation completed successfully!\")\n","    else:\n","        print(f\"\\n‚ùå Evaluation failed with return code {process.returncode}\")\n","\n","except Exception as e:\n","    print(f\"\\n‚ùå Error running evaluation: {e}\")\n","    import traceback\n","    traceback.print_exc()\n","finally:\n","    os.chdir(original_dir)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":973},"id":"n-Ts7Tu6GgAB","outputId":"06d3f643-ce33-47f1-a18f-4b87aa962e6d"},"id":"n-Ts7Tu6GgAB","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üöÄ Evaluating MultiPL-E JavaScript...\n","   This will take ~30-60 minutes...\n","   Using 5-shot prompt from MBPP selection\n","‚úÖ bigcode-evaluation-harness already exists\n","\n","‚úÖ Found main.py at: /content/bigcode-evaluation-harness/bigcode-evaluation-harness/main.py\n","\n","üí° Using task: multiple-js\n","üí° Running evaluation command...\n","   This will take 30-60 minutes, please be patient...\n","\n","üìù Command: python main.py --model Qwen/Qwen2.5-Coder-3B-Instruct --tasks multiple-js ...\n","   Prefix length: 896 characters\n","   Working directory: /content/bigcode-evaluation-harness/bigcode-evaluation-harness\n","\n","‚è≥ Starting evaluation (this will take 30-60 minutes)...\n","\n","2025-12-03 17:56:03.948100: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1764784563.975425   73677 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1764784563.982789   73677 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1764784563.999841   73677 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1764784563.999874   73677 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1764784563.999876   73677 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1764784563.999878   73677 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","Selected Tasks: ['multiple-js']\n","Loading model in fp32\n","\n","Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\n","Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  1.50s/it]\n","Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.20it/s]\n","Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.07it/s]\n","\n","Generating test split:   0%|          | 0/161 [00:00<?, ? examples/s]\n","Generating test split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 161/161 [00:00<00:00, 29560.63 examples/s]\n","number of problems for this task is 161\n","\n","  0%|          | 0/161 [00:00<?, ?it/s]\n","  1%|          | 1/161 [00:06<17:15,  6.47s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2859986515.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;31m# Print output line by line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"ix9zaAphTV-j"},"source":["## Summary\n","\n","- **Phase 1 (MBPP)**: sweep baseline / 0 / 1 / 3 / 5-shot with **pure-code prefixes**,  \n","  avoiding Markdown so that exec-based evaluation is stable.\n","- **Phase 2 (HumanEval)**: re-use the best-shot prompt function `best_prompt_fn` from Phase 1.\n","\n","You can now:\n","1. Run the MBPP sweep cell to get the best configuration.\n","2. Uncomment the HumanEval cell and evaluate with the selected prompt.\n","3. Use the JSON files in `results/` directly in your LaTeX tables."],"id":"ix9zaAphTV-j"}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","pygments_lexer":"ipython3"},"colab":{"provenance":[],"machine_shape":"hm"},"widgets":{"application/vnd.jupyter.widget-state+json":{"6cfb2d07e807454aa85fb7fd10a5416b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9d5c504797ab45e2b5c9a70e62325024","IPY_MODEL_c088b9330f6442fd820514bbc018f1d1","IPY_MODEL_85d5d83019934fd88ced202a024a8652"],"layout":"IPY_MODEL_36eff46eda6b49e19174387df7c97699"}},"9d5c504797ab45e2b5c9a70e62325024":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_780f19308b25487d8ee0cc9bd61066a5","placeholder":"‚Äã","style":"IPY_MODEL_af8f015b7b8543fe94f55d4a0ba84a8c","value":"baseline:‚Äá100%"}},"c088b9330f6442fd820514bbc018f1d1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4c861075f7a458486a7e0c34c65b489","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5a456cc8b2f248549ba03c1d81eb3b59","value":100}},"85d5d83019934fd88ced202a024a8652":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2c5f6fedc4a4f49bf3add032581ba7d","placeholder":"‚Äã","style":"IPY_MODEL_84eb3b42b01444a68d707292b190fe75","value":"‚Äá100/100‚Äá[15:38&lt;00:00,‚Äá10.06s/it]"}},"36eff46eda6b49e19174387df7c97699":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"780f19308b25487d8ee0cc9bd61066a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af8f015b7b8543fe94f55d4a0ba84a8c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e4c861075f7a458486a7e0c34c65b489":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a456cc8b2f248549ba03c1d81eb3b59":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a2c5f6fedc4a4f49bf3add032581ba7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84eb3b42b01444a68d707292b190fe75":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"88e4d35be0ac4f6e989c02e39e66779a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a6fcb49ace1a41c1ba16ebb56f83d1f9","IPY_MODEL_3bd94718f5f8422eacccb3304f30e10e","IPY_MODEL_78e12288dbed469d80fa3f5e91112d99"],"layout":"IPY_MODEL_2017b289c6ca4e26be3e1e6dd0fc77a5"}},"a6fcb49ace1a41c1ba16ebb56f83d1f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_77feaf7395834f1caede664ab9ef4c51","placeholder":"‚Äã","style":"IPY_MODEL_6a7a925c0a8e464aae03f4df7e9829ad","value":"0shot:‚Äá100%"}},"3bd94718f5f8422eacccb3304f30e10e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c79a4fc1a934fb097a4c6cb82324f6b","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ae8ed2304f324c3c8b80379ebcf5b189","value":100}},"78e12288dbed469d80fa3f5e91112d99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_09abc65091b44febb5b098320d43d44b","placeholder":"‚Äã","style":"IPY_MODEL_4bc08140244d45a4b266b1cfa919b960","value":"‚Äá100/100‚Äá[14:57&lt;00:00,‚Äá10.23s/it]"}},"2017b289c6ca4e26be3e1e6dd0fc77a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"77feaf7395834f1caede664ab9ef4c51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a7a925c0a8e464aae03f4df7e9829ad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c79a4fc1a934fb097a4c6cb82324f6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae8ed2304f324c3c8b80379ebcf5b189":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"09abc65091b44febb5b098320d43d44b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4bc08140244d45a4b266b1cfa919b960":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2bbe892a8f3c47758931bf6d44d41988":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7c0feba307b847e3bf63702cf970c518","IPY_MODEL_30dd29628f9a486f8fdd158ec6743db1","IPY_MODEL_d8d77dad722a4d2ebb58b92d43516677"],"layout":"IPY_MODEL_f841637e8c524b338795092be212ea66"}},"7c0feba307b847e3bf63702cf970c518":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_581ca9b377ef4515b02e86af636b8321","placeholder":"‚Äã","style":"IPY_MODEL_04e2d6cbe82143b7b29975047f2afbd2","value":"1shot:‚Äá100%"}},"30dd29628f9a486f8fdd158ec6743db1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_5757200d3d1e410ab0021ff13f14cd34","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b51711041fac4271ba3d6f860c8c866e","value":100}},"d8d77dad722a4d2ebb58b92d43516677":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_89c91021e51d4866baf7d417b469e4e7","placeholder":"‚Äã","style":"IPY_MODEL_820d4a4c071d4ac8b60bdb3a595e2ea7","value":"‚Äá100/100‚Äá[15:23&lt;00:00,‚Äá‚Äá9.57s/it]"}},"f841637e8c524b338795092be212ea66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"581ca9b377ef4515b02e86af636b8321":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04e2d6cbe82143b7b29975047f2afbd2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5757200d3d1e410ab0021ff13f14cd34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b51711041fac4271ba3d6f860c8c866e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"89c91021e51d4866baf7d417b469e4e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"820d4a4c071d4ac8b60bdb3a595e2ea7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4fd09d4b029041e19104708b3d4af4f1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e350f05235ba4feb9688442128f5b909","IPY_MODEL_f853200d5af0429e9ccaea4861750f2b","IPY_MODEL_9f78b764fa2b4e93ab1cc6056c9e65da"],"layout":"IPY_MODEL_7d87637cc356432f89fc3c4305afc4c7"}},"e350f05235ba4feb9688442128f5b909":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e708f6d2b944a5bb4b8fbd0f6b92cec","placeholder":"‚Äã","style":"IPY_MODEL_8ac7d4b25f8f43d7af06d2cabcd9f78b","value":"3shot:‚Äá100%"}},"f853200d5af0429e9ccaea4861750f2b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_d87eb678f037498fbece9f8c5bb4cc02","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_afa7a234bd924d7fa0449ae70b1bf1c6","value":100}},"9f78b764fa2b4e93ab1cc6056c9e65da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea028f1a513e44a3b57b1c115b1a7bd0","placeholder":"‚Äã","style":"IPY_MODEL_83141bab00c4488098c5124c692af174","value":"‚Äá100/100‚Äá[15:14&lt;00:00,‚Äá‚Äá8.98s/it]"}},"7d87637cc356432f89fc3c4305afc4c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"9e708f6d2b944a5bb4b8fbd0f6b92cec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ac7d4b25f8f43d7af06d2cabcd9f78b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d87eb678f037498fbece9f8c5bb4cc02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afa7a234bd924d7fa0449ae70b1bf1c6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ea028f1a513e44a3b57b1c115b1a7bd0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83141bab00c4488098c5124c692af174":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"43182452ae8b486cb1a3bfaf2d0e3054":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_34399e55790444c3b87bc5985ae45f12","IPY_MODEL_08e105a87eab4aa6a183cf0370a4e1eb","IPY_MODEL_c4bb3397d01e4818ad5cfbb81e1dacd6"],"layout":"IPY_MODEL_918427fa55294d35a5e00ba2ed22ede9"}},"34399e55790444c3b87bc5985ae45f12":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7eff79f3870440679951d256b5d23a56","placeholder":"‚Äã","style":"IPY_MODEL_a603ef3a77354a3d95b7eab6cd9d1c8f","value":"5shot:‚Äá100%"}},"08e105a87eab4aa6a183cf0370a4e1eb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9caf37422af4797b7abca9628f7e471","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fc6beb0c01e14900a2408fd5fce82212","value":100}},"c4bb3397d01e4818ad5cfbb81e1dacd6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8b9faaf1f284d75bac9d94d0e535a87","placeholder":"‚Äã","style":"IPY_MODEL_b17e25cde53244c3b72b6f1f9d255958","value":"‚Äá100/100‚Äá[14:10&lt;00:00,‚Äá‚Äá8.95s/it]"}},"918427fa55294d35a5e00ba2ed22ede9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"7eff79f3870440679951d256b5d23a56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a603ef3a77354a3d95b7eab6cd9d1c8f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a9caf37422af4797b7abca9628f7e471":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc6beb0c01e14900a2408fd5fce82212":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c8b9faaf1f284d75bac9d94d0e535a87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b17e25cde53244c3b72b6f1f9d255958":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c28285cc178e4878a9a0d7ae7eaa314f":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":[],"layout":"IPY_MODEL_cc3ebbdccf874a4ab76fc4d3339ea9eb"}},"326f6c1e87cc4158a1d931ab1176e55f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_978cbcb38a0b472abede6196826bbe9c","placeholder":"‚Äã","style":"IPY_MODEL_f2bd3861f5ae49efaf13eeebd3dbc322","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"f4b8934da18249589cf24375d977ba58":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_70366e9028c14542a3bb552ccde8a68f","placeholder":"‚Äã","style":"IPY_MODEL_469dcf5abce44982bbf9328b0b87a600","value":""}},"8aac99036e1641c8892698cf5ca31e04":{"model_module":"@jupyter-widgets/controls","model_name":"CheckboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_535297623d154634838035d5853752e6","style":"IPY_MODEL_f4585c6c28a041fea79036dfcbb2ba9d","value":true}},"4cd44205ab18476b9a56bf5b76eccb67":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_431401bb96a64938b269bdbdb186e0ee","style":"IPY_MODEL_4544a010807e45e78464ac892150a50d","tooltip":""}},"dd4c8f0baef0417f9bccb0c1d2058518":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d427289c817446aa4eab7d548bd7725","placeholder":"‚Äã","style":"IPY_MODEL_cf1e4a40df344a03ad6345b735828ff3","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"cc3ebbdccf874a4ab76fc4d3339ea9eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"978cbcb38a0b472abede6196826bbe9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2bd3861f5ae49efaf13eeebd3dbc322":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70366e9028c14542a3bb552ccde8a68f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"469dcf5abce44982bbf9328b0b87a600":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"535297623d154634838035d5853752e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4585c6c28a041fea79036dfcbb2ba9d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"431401bb96a64938b269bdbdb186e0ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4544a010807e45e78464ac892150a50d":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"8d427289c817446aa4eab7d548bd7725":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf1e4a40df344a03ad6345b735828ff3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"26a62b3b6a0047b3a173dfd75e185c9b":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef6f5919177c426ebc70513179eeece6","placeholder":"‚Äã","style":"IPY_MODEL_63d82ecf96694c77bacb8bff1cac9dac","value":"Connecting..."}},"ef6f5919177c426ebc70513179eeece6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63d82ecf96694c77bacb8bff1cac9dac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"71b303e81d334239b0336a55c393e4b9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_502dbb13f2d64f58bc4a561be77155cc","IPY_MODEL_04941351275b4c75b4e5425db2e4bf02","IPY_MODEL_46cc4d9a431547c4904e13814d66145d"],"layout":"IPY_MODEL_6065731d361348279ec4b06fb0367151"}},"502dbb13f2d64f58bc4a561be77155cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a70e68e786c54ba88af3a9bc7ba54169","placeholder":"‚Äã","style":"IPY_MODEL_2e22589ba6c64c71a42a85078aabc8fd","value":"Loading‚Äácheckpoint‚Äáshards:‚Äá100%"}},"04941351275b4c75b4e5425db2e4bf02":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b0d6b9ee537454a8e1b9e95a00dfb7b","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c093ac5fc63d4c418e2552c657dc6014","value":2}},"46cc4d9a431547c4904e13814d66145d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca407868df004d2d80e48e34a8d6066a","placeholder":"‚Äã","style":"IPY_MODEL_a4db0b1c7def437e9bff8e2c97d7e78b","value":"‚Äá2/2‚Äá[00:02&lt;00:00,‚Äá‚Äá1.06it/s]"}},"6065731d361348279ec4b06fb0367151":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a70e68e786c54ba88af3a9bc7ba54169":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e22589ba6c64c71a42a85078aabc8fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b0d6b9ee537454a8e1b9e95a00dfb7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c093ac5fc63d4c418e2552c657dc6014":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ca407868df004d2d80e48e34a8d6066a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4db0b1c7def437e9bff8e2c97d7e78b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8eb3192da96140359835571899f4e95d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1803c90ea7f54523b1c4fb409da945d6","IPY_MODEL_2f274a6b2f04402992abd5de6b0bb8d9","IPY_MODEL_9ae62982eb1f492c9ab0b6d083f8016c"],"layout":"IPY_MODEL_5ded20cfe16f4abcbfc18dac0834faa7"}},"1803c90ea7f54523b1c4fb409da945d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_169864c23ace444f9ff88dd720f9051e","placeholder":"‚Äã","style":"IPY_MODEL_8497ed2228ad4b159e23c1179cecbc7e","value":"README.md:‚Äá"}},"2f274a6b2f04402992abd5de6b0bb8d9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c4ee54b54354759b94813a17a45d1ab","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e2c8967c67684fa8b0a0ecfa9dbd7c99","value":1}},"9ae62982eb1f492c9ab0b6d083f8016c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9508e514df894984a81a3b2b21a6ad14","placeholder":"‚Äã","style":"IPY_MODEL_947c4e75e1b5477e8fa4c43e9eaf2e52","value":"‚Äá9.06k/?‚Äá[00:00&lt;00:00,‚Äá1.02MB/s]"}},"5ded20cfe16f4abcbfc18dac0834faa7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"169864c23ace444f9ff88dd720f9051e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8497ed2228ad4b159e23c1179cecbc7e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1c4ee54b54354759b94813a17a45d1ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"e2c8967c67684fa8b0a0ecfa9dbd7c99":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9508e514df894984a81a3b2b21a6ad14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"947c4e75e1b5477e8fa4c43e9eaf2e52":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc8517b98aba4856944488144f121758":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6af2da7cb3a04e47ae174f33f95164da","IPY_MODEL_e1603163e8ad4d3ab16ec44b8bcd0baf","IPY_MODEL_1297aa3e248148838aa71b9e86d774e1"],"layout":"IPY_MODEL_d6898f910a6a4a9eb2f7be868010c558"}},"6af2da7cb3a04e47ae174f33f95164da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f54946eeef243238b9bb889f88c129f","placeholder":"‚Äã","style":"IPY_MODEL_257e98ae8b6f481faa291f09aababe29","value":"full/train-00000-of-00001.parquet:‚Äá100%"}},"e1603163e8ad4d3ab16ec44b8bcd0baf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d57b17003834456807da7cd477f4c09","max":87223,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9fa9921a72c24e01adb5e8365b291e92","value":87223}},"1297aa3e248148838aa71b9e86d774e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_404fb9c9c0124266a8f054174585c432","placeholder":"‚Äã","style":"IPY_MODEL_bba124162b014bd2a0ca5f4710f267ec","value":"‚Äá87.2k/87.2k‚Äá[00:00&lt;00:00,‚Äá193kB/s]"}},"d6898f910a6a4a9eb2f7be868010c558":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f54946eeef243238b9bb889f88c129f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"257e98ae8b6f481faa291f09aababe29":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8d57b17003834456807da7cd477f4c09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fa9921a72c24e01adb5e8365b291e92":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"404fb9c9c0124266a8f054174585c432":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bba124162b014bd2a0ca5f4710f267ec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8571b97c80c34809bf61001b984cb0aa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2a3cb264e9fb46f68465aa2b148e597e","IPY_MODEL_8dce0bf5e0964fa3aec0f1ba39a0441b","IPY_MODEL_12d062fde022413185e99ca3e3200ad5"],"layout":"IPY_MODEL_888cf2c2d7ca4bd3b58ded188f04738d"}},"2a3cb264e9fb46f68465aa2b148e597e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79bbd91cc32a44ed9774e1116a73f8dd","placeholder":"‚Äã","style":"IPY_MODEL_24c023c387614f87bd8fddb6b23d69d7","value":"full/test-00000-of-00001.parquet:‚Äá100%"}},"8dce0bf5e0964fa3aec0f1ba39a0441b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6945968149274cd19ce7883cc3db94d5","max":115824,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8e01d4d873cd4c1495045c614649d813","value":115824}},"12d062fde022413185e99ca3e3200ad5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_11bd8da508cf4ecb8cd695f0d5b96d10","placeholder":"‚Äã","style":"IPY_MODEL_67aeda7412114e579c51c9d92b92109c","value":"‚Äá116k/116k‚Äá[00:00&lt;00:00,‚Äá291kB/s]"}},"888cf2c2d7ca4bd3b58ded188f04738d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79bbd91cc32a44ed9774e1116a73f8dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24c023c387614f87bd8fddb6b23d69d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6945968149274cd19ce7883cc3db94d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e01d4d873cd4c1495045c614649d813":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"11bd8da508cf4ecb8cd695f0d5b96d10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67aeda7412114e579c51c9d92b92109c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"53d172f803f2435ea63331b18cf47319":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d21a9846bfe54152bc3beb8172b4ebc1","IPY_MODEL_fcb34ef344c641a69ca1e425a277a65a","IPY_MODEL_a43d05fcae864d3b972a6e0f32895c31"],"layout":"IPY_MODEL_d4441853dd984e2181979cbac3bc388c"}},"d21a9846bfe54152bc3beb8172b4ebc1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff5d2c96d8484923af583c41c86d00d2","placeholder":"‚Äã","style":"IPY_MODEL_109bbfa17b7f477faf7c6955b9800e21","value":"full/validation-00000-of-00001.parquet:‚Äá100%"}},"fcb34ef344c641a69ca1e425a277a65a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_122a313bcdec4693ab0099f1d987ace0","max":25144,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dbab3733a7ed43c0b036b947a610ba0e","value":25144}},"a43d05fcae864d3b972a6e0f32895c31":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e98c6370c18d4df79dbdf7b7f7e3e9d8","placeholder":"‚Äã","style":"IPY_MODEL_0a23082cb474402ebcf7de70759a7706","value":"‚Äá25.1k/25.1k‚Äá[00:00&lt;00:00,‚Äá106kB/s]"}},"d4441853dd984e2181979cbac3bc388c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff5d2c96d8484923af583c41c86d00d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"109bbfa17b7f477faf7c6955b9800e21":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"122a313bcdec4693ab0099f1d987ace0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbab3733a7ed43c0b036b947a610ba0e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e98c6370c18d4df79dbdf7b7f7e3e9d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a23082cb474402ebcf7de70759a7706":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a390f2be0804fabb25042bb24cd1e25":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_336a7704082f4812a25d7ccff0e0a67c","IPY_MODEL_5ef0080b1d5941f696ef1f919ee4c91c","IPY_MODEL_ba8222d3b33a4fedb37c1d6e64426cdd"],"layout":"IPY_MODEL_7f0720632cf64aa78bc5241b1c06cf3a"}},"336a7704082f4812a25d7ccff0e0a67c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ddae58a6684444d78f18148db3567d1c","placeholder":"‚Äã","style":"IPY_MODEL_4a0564c7940e4c689709c3b98fdaa0e5","value":"full/prompt-00000-of-00001.parquet:‚Äá100%"}},"5ef0080b1d5941f696ef1f919ee4c91c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbd1c2ef5b874a60aa294a35faf614d5","max":7878,"min":0,"orientation":"horizontal","style":"IPY_MODEL_439da3ebb3df447b8d95933655a8f3d9","value":7878}},"ba8222d3b33a4fedb37c1d6e64426cdd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f59432f1cae34d7bb38fff2a3d9b710e","placeholder":"‚Äã","style":"IPY_MODEL_cd7dc8f9ebfb4919bbae87a57a161aac","value":"‚Äá7.88k/7.88k‚Äá[00:00&lt;00:00,‚Äá25.3kB/s]"}},"7f0720632cf64aa78bc5241b1c06cf3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ddae58a6684444d78f18148db3567d1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a0564c7940e4c689709c3b98fdaa0e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fbd1c2ef5b874a60aa294a35faf614d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"439da3ebb3df447b8d95933655a8f3d9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f59432f1cae34d7bb38fff2a3d9b710e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd7dc8f9ebfb4919bbae87a57a161aac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e7569de931d458f9590d96e4b653f79":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1d29f75a5a134fd2ad6c32e6632d15b2","IPY_MODEL_81169fe56fac4e02974691c91ff9107e","IPY_MODEL_0695c50e36534374b82a806eadb24cc1"],"layout":"IPY_MODEL_3d338ff02cfa4142870116b2e98bc76e"}},"1d29f75a5a134fd2ad6c32e6632d15b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfe18f1bc6d04cb1ac53a2d00baa88bd","placeholder":"‚Äã","style":"IPY_MODEL_94c0b13775ee40a7bea672e292b2239c","value":"Generating‚Äátrain‚Äásplit:‚Äá100%"}},"81169fe56fac4e02974691c91ff9107e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c098effed85450aafadee64060e1c79","max":374,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e6d2b9f92d924bfb85baca93ac702538","value":374}},"0695c50e36534374b82a806eadb24cc1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4190714d7044b439e97968c4cabf57c","placeholder":"‚Äã","style":"IPY_MODEL_97dc3319d6d847a1b1d8ec3be72bc95e","value":"‚Äá374/374‚Äá[00:00&lt;00:00,‚Äá28331.19‚Äáexamples/s]"}},"3d338ff02cfa4142870116b2e98bc76e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfe18f1bc6d04cb1ac53a2d00baa88bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94c0b13775ee40a7bea672e292b2239c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c098effed85450aafadee64060e1c79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6d2b9f92d924bfb85baca93ac702538":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f4190714d7044b439e97968c4cabf57c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97dc3319d6d847a1b1d8ec3be72bc95e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"599782e809d24e589e4b3a8b54603cb7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cc5b1d45c9b4433c9c65184b7a05f4ff","IPY_MODEL_41d777c4ccc143faa3b957c181e97523","IPY_MODEL_85c29be123c643ec8cd4d0b928429231"],"layout":"IPY_MODEL_c3dcc4c93d7c481bbcd4b7600688d5c0"}},"cc5b1d45c9b4433c9c65184b7a05f4ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d07a17fbe5746d496d9e19e9cf1a1e7","placeholder":"‚Äã","style":"IPY_MODEL_25e2513947654bf8940952250574d550","value":"Generating‚Äátest‚Äásplit:‚Äá100%"}},"41d777c4ccc143faa3b957c181e97523":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6732948c7394249ba8292e4c1d38efb","max":500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_723a49be944d4a33949075c9ed171990","value":500}},"85c29be123c643ec8cd4d0b928429231":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8adeafd67704ccfbf4b86ae04747e6f","placeholder":"‚Äã","style":"IPY_MODEL_a8806232057c4e06ad0291496cad8725","value":"‚Äá500/500‚Äá[00:00&lt;00:00,‚Äá44775.54‚Äáexamples/s]"}},"c3dcc4c93d7c481bbcd4b7600688d5c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d07a17fbe5746d496d9e19e9cf1a1e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25e2513947654bf8940952250574d550":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f6732948c7394249ba8292e4c1d38efb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"723a49be944d4a33949075c9ed171990":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f8adeafd67704ccfbf4b86ae04747e6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8806232057c4e06ad0291496cad8725":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f115986dcb94f2b857d5b700c90d578":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e116f17534124278925209d4e119f1ba","IPY_MODEL_c47ca54a4575440b8130719b687621c1","IPY_MODEL_c8b9487571f2454dad8ed05205d82e26"],"layout":"IPY_MODEL_4b6e0354611749b3aeb7dd1b61fab431"}},"e116f17534124278925209d4e119f1ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_693c6db7c33d43d097f2c7f671f52644","placeholder":"‚Äã","style":"IPY_MODEL_4c8b56f191b6437295f1d29ce87d93cd","value":"Generating‚Äávalidation‚Äásplit:‚Äá100%"}},"c47ca54a4575440b8130719b687621c1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_16867d2fb935455eba3e063ff17336e2","max":90,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d3631949f6c547798ff865fff3c2b963","value":90}},"c8b9487571f2454dad8ed05205d82e26":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb3a180d3d4949ea9e3147d22e5a5c11","placeholder":"‚Äã","style":"IPY_MODEL_7a51a914caa44ec6a4880006096b72f1","value":"‚Äá90/90‚Äá[00:00&lt;00:00,‚Äá9606.25‚Äáexamples/s]"}},"4b6e0354611749b3aeb7dd1b61fab431":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"693c6db7c33d43d097f2c7f671f52644":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c8b56f191b6437295f1d29ce87d93cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"16867d2fb935455eba3e063ff17336e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3631949f6c547798ff865fff3c2b963":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bb3a180d3d4949ea9e3147d22e5a5c11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a51a914caa44ec6a4880006096b72f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1ab45fc7d964a8980ac7601ad24e6b8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_149961570e0c4ad0971cf5c17bd3cb3a","IPY_MODEL_43792da408484038ac3558221dbc7e3f","IPY_MODEL_de086d3664be4444baf6c217e78810c7"],"layout":"IPY_MODEL_6a602986fbbf4eefac8ea1c00ed96b4f"}},"149961570e0c4ad0971cf5c17bd3cb3a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f417266830d848fc8e2384b5916ce198","placeholder":"‚Äã","style":"IPY_MODEL_2192447935574202a891271720f648d3","value":"Generating‚Äáprompt‚Äásplit:‚Äá100%"}},"43792da408484038ac3558221dbc7e3f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a350d4fa4e541bf9e3cd236469302e5","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_051e0d5388144532adf996e703dc8375","value":10}},"de086d3664be4444baf6c217e78810c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_003db91e63fc46e8b4b4ca8f66a8b61f","placeholder":"‚Äã","style":"IPY_MODEL_8d1417231fbb4df59d5b927bce0381bc","value":"‚Äá10/10‚Äá[00:00&lt;00:00,‚Äá1099.71‚Äáexamples/s]"}},"6a602986fbbf4eefac8ea1c00ed96b4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f417266830d848fc8e2384b5916ce198":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2192447935574202a891271720f648d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0a350d4fa4e541bf9e3cd236469302e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"051e0d5388144532adf996e703dc8375":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"003db91e63fc46e8b4b4ca8f66a8b61f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d1417231fbb4df59d5b927bce0381bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}